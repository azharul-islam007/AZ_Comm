/home/ubuntu/anaconda3/bin/conda run -n myenv --no-capture-output python /tmp/pycharm_project_908/Europearl/SD5.py 
2025-04-10 20:35:50,662 - INFO - Using device: cuda
/home/ubuntu/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
2025-04-10 20:35:51,923 - INFO - Initialized Enhanced Physical Channel with awgn channel, qam-16 modulation, SNR=20.0dB
2025-04-10 20:35:51,923 - INFO - Adaptive modulation enabled: thresholds at 15.0dB and 25.0dB
2025-04-10 20:35:51,923 - INFO - Unequal error protection enabled with 3 protection levels
/tmp/pycharm_project_908/Europearl/content_adaptive_coding.py:375: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(self.content_classifier_path, map_location=device)
2025-04-10 20:35:51,926 - INFO - Using embedding dimension 460 from checkpoint
2025-04-10 20:35:51,929 - INFO - Content classifier loaded successfully
2025-04-10 20:35:51,929 - INFO - Content-Adaptive Physical Channel initialized
2025-04-10 20:35:51,929 - INFO - Enhanced content-adaptive physical channel initialized
2025-04-10 20:35:51,929 - INFO - Will collect up to 10000 transmission pairs
2025-04-10 20:35:51,929 - INFO - Using device: cuda
2025-04-10 20:35:55,520 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:35:55,526 - INFO - ✅ OpenAI API connection successful

===== SYSTEM COMPONENT TEST =====
2025-04-10 20:35:55,529 - INFO - Loaded knowledge base from ./models/europarl_knowledge_base.pkl with 41 terms
2025-04-10 20:35:55,529 - INFO - Loaded knowledge base from ./models/europarl_knowledge_base.pkl with 41 terms (load #1)
Knowledge Base loaded with 41 terms

Test Case 1: Mrs Lynne, you are quite right and I shall check whether this ocs actually not been done.
1. KB Reconstruction (1 changes):
   Mrs Lynne, you are quite right and I shall check whether this has actually not been done.
2025-04-10 20:35:55,538 - INFO - KB reconstruction made changes: 'Mrs Lynne, you are quite right and I shall check whether this ocs actually not been done.' -> 'Mrs Lynne, you are quite right and I shall check whether this has actually not been done.'
2. Basic Reconstruction (1 changes):
   Mrs Lynne, you are quite right and I shall check whether this has actually not been done.
2025-04-10 20:35:55,538 - INFO - [API] Starting reconstruction of text: 'Mrs Lynne, you are quite right...'
2025-04-10 20:35:55,542 - INFO - [API] Using KB reconstruction with confidence 1.01
2025-04-10 20:35:55,542 - INFO - [API] Completed in 0.004s using method: kb
3. API Reconstruction (1 changes):
   Mrs Lynne, you are quite right and I shall check whether this has actually not been done.

Test Case 2: The Parliamemt will now vote on the propofal from the Commissiob.
1. KB Reconstruction (3 changes):
   The Parliament will now vote on the proposal from the Commission
2025-04-10 20:35:55,549 - INFO - KB reconstruction made changes: 'The Parliamemt will now vote on the propofal from the Commissiob.' -> 'The Parliament will now vote on the proposal from the Commission'
2. Basic Reconstruction (3 changes):
   The Parliament will now vote on the proposal from the Commission
2025-04-10 20:35:55,549 - INFO - [API] Starting reconstruction of text: 'The Parliamemt will now vote o...'
2025-04-10 20:35:55,551 - INFO - [API] Using KB reconstruction with confidence 0.76
2025-04-10 20:35:55,551 - INFO - [API] Completed in 0.002s using method: kb
3. API Reconstruction (3 changes):
   The Parliament will now vote on the proposal from the Commission

Test Case 3: In accordancg with Rule 143, I wkulz like your acvioe about this moetinp.
1. KB Reconstruction (5 changes):
   in accordance with Rule 143, I would like your advice about this meeting
2025-04-10 20:35:55,554 - INFO - KB reconstruction made changes: 'In accordancg with Rule 143, I wkulz like your acvioe about this moetinp.' -> 'in accordance with Rule 143, I would like your advice about this meeting'
2. Basic Reconstruction (5 changes):
   in accordance with Rule 143, I would like your advice about this meeting
2025-04-10 20:35:55,555 - INFO - [API] Starting reconstruction of text: 'In accordancg with Rule 143, I...'
2025-04-10 20:35:55,557 - INFO - [API] Using KB reconstruction with confidence 0.60
2025-04-10 20:35:55,557 - INFO - [API] Completed in 0.003s using method: kb
3. API Reconstruction (5 changes):
   in accordance with Rule 143, I would like your advice about this meeting

===== RESULTS =====
Components tested: KB Reconstruction, Basic Reconstruction, API Reconstruction
Test cases corrected: 3/3
System status: ✓ FUNCTIONAL
2025-04-10 20:35:55,557 - INFO - Loaded dimensions from file: 768, 460
/tmp/pycharm_project_908/Europearl/SD5.py:2085: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(dvae_path, map_location=torch.device('cpu'))
2025-04-10 20:35:55,597 - INFO - System dimensions: {'input_dim': 768, 'compressed_dim': 460, 'dvae_input_dim': 460, 'dvae_hidden_dim': 920, 'dvae_latent_dim': 460}
2025-04-10 20:35:55,597 - INFO - Updated dimension original_dim: 768 → 768
2025-04-10 20:35:55,597 - INFO - Updated dimension compressed_dim: 460 → 460
2025-04-10 20:35:55,597 - INFO - Updated dimension dvae_latent_dim: 460 → 460
2025-04-10 20:35:55,597 - INFO - Initialized dimension registry: {'original': 768, 'compressed': 460, 'latent': 460}
2025-04-10 20:35:55,617 - INFO - System dimensions: {'input_dim': 768, 'compressed_dim': 460, 'dvae_input_dim': 460, 'dvae_hidden_dim': 920, 'dvae_latent_dim': 460}
2025-04-10 20:35:55,617 - INFO - [PIPELINE] Starting enhanced pipeline with parameters:
2025-04-10 20:35:55,617 - INFO - [PIPELINE] - samples: 50, noise: 0.15/gaussian
2025-04-10 20:35:55,617 - INFO - [PIPELINE] - API: 50%, Compare: True
2025-04-10 20:35:55,617 - INFO - [PIPELINE] - Features: VAE=True, Semantic=True, Adaptive=True
2025-04-10 20:35:55,617 - INFO - [PIPELINE] - System dimensions: input=768, compressed=460
2025-04-10 20:35:55,617 - INFO - [PIPELINE] Knowledge base initialized successfully
2025-04-10 20:35:55,617 - INFO - Precomputing KB enhancements...
2025-04-10 20:35:55,617 - INFO - Precomputed 41 common KB terms
2025-04-10 20:35:55,618 - INFO - Initializing semantic loss with bert-base-uncased model
/home/ubuntu/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
2025-04-10 20:35:56,451 - INFO - Semantic perceptual loss initialized successfully
2025-04-10 20:35:56,451 - INFO - [PIPELINE] Semantic perceptual loss initialized successfully
2025-04-10 20:35:56,471 - INFO - [PIPELINE] Loaded 10000 items from compressed data
2025-04-10 20:35:56,475 - INFO - [PIPELINE] Loaded 10000 original sentences
2025-04-10 20:35:56,475 - INFO - Loading existing VAE compressor from ./data/vae_compressor.pth
/tmp/pycharm_project_908/Europearl/compression_vae.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(VAE_COMPRESSOR_PATH, map_location=device)
2025-04-10 20:35:56,514 - INFO - VAE compressor loaded: 768 → 460 dimensions
2025-04-10 20:35:56,514 - INFO - Note: Loaded standard model, but requested enhanced
2025-04-10 20:35:56,521 - INFO - Saved VAE dimensions to file: input=768, compressed=460
2025-04-10 20:35:56,521 - INFO - [PIPELINE] VAE compressor loaded successfully: 768 → 460
2025-04-10 20:35:56,522 - INFO - Initialized Enhanced Physical Channel with awgn channel, qam-16 modulation, SNR=20.0dB
2025-04-10 20:35:56,522 - INFO - Adaptive modulation enabled: thresholds at 15.0dB and 25.0dB
2025-04-10 20:35:56,522 - INFO - Unequal error protection enabled with 3 protection levels
/tmp/pycharm_project_908/Europearl/content_adaptive_coding.py:375: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(self.content_classifier_path, map_location=device)
2025-04-10 20:35:56,527 - INFO - Using embedding dimension 460 from checkpoint
2025-04-10 20:35:56,535 - INFO - Content classifier loaded successfully
2025-04-10 20:35:56,535 - INFO - Content-Adaptive Physical Channel initialized
2025-04-10 20:35:56,535 - INFO - [PIPELINE] Physical channel upgraded to content-adaptive version
2025-04-10 20:35:56,535 - INFO - Using provided input dimension: 460
2025-04-10 20:35:56,535 - INFO - Loading pre-trained enhanced MLPDenoisingVAE from ./models/enhanced_mlp_dvae_model.pth
/tmp/pycharm_project_908/Europearl/semantic_mlpdvae.py:778: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(full_model_path, map_location=device)
2025-04-10 20:35:56,646 - INFO - Loaded model was trained with semantic perceptual loss
2025-04-10 20:35:56,646 - INFO - [PIPELINE] System configurations:
2025-04-10 20:35:56,646 - INFO -   - VAE compression: True
2025-04-10 20:35:56,646 - INFO -   - VAE dimensions: 768 → 460
2025-04-10 20:35:56,646 - INFO -   - DVAE dimensions: input=460, hidden=920, latent=460
2025-04-10 20:35:56,646 - INFO -   - Physical channel enabled: True
2025-04-10 20:35:56,646 - INFO -   - Content adaptive coding: True
2025-04-10 20:35:56,646 - INFO -   - Knowledge base enabled: True
2025-04-10 20:35:56,646 - INFO - [PIPELINE] IMPORTANT: Model dimensions are input=460, hidden=920, latent=460
/tmp/pycharm_project_908/Europearl/SD5.py:704: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(path, map_location=self.model_device)
2025-04-10 20:35:56,841 - INFO - Loaded PPO agent (exploration rate: 0.10)
2025-04-10 20:35:56,841 - INFO - Initializing semantic loss with bert-base-uncased model
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
2025-04-10 20:35:57,677 - INFO - Semantic perceptual loss initialized successfully
2025-04-10 20:35:57,680 - INFO - [PIPELINE] Semantic channel optimizer initialized
2025-04-10 20:35:57,680 - INFO - [PIPELINE] Using enhanced RL agent for API optimization (exploration rate: 0.10)
2025-04-10 20:35:57,680 - INFO - === Starting Enhanced Semantic Reconstruction Pipeline ===
2025-04-10 20:35:57,680 - INFO - [PIPELINE] Noise level: 0.15, Noise type: gaussian
2025-04-10 20:35:57,680 - INFO - [PIPELINE] OpenAI API available: True
2025-04-10 20:35:57,680 - INFO - [PIPELINE] Physical channel enabled: True
Processing samples:   0%|                                | 0/50 [00:00<?, ?it/s]/tmp/pycharm_project_908/Europearl/physical_semantic_integration.py:539: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1808.)
  variance = torch.var(tensor, dim=0)
2025-04-10 20:35:57,777 - INFO - Using device: cuda
2025-04-10 20:35:59,157 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:35:59,164 - INFO - ✅ OpenAI API connection successful
/tmp/pycharm_project_908/Europearl/compression_vae.py:532: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(VAE_COMPRESSOR_PATH, map_location=device)
2025-04-10 20:35:59,292 - INFO - [API] Starting reconstruction of text: 'Although , as you wiet have se...'
2025-04-10 20:35:59,372 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-10 20:36:02,436 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:02,443 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:02,444 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-10 20:36:02,444 - INFO - [API] Completed in 3.152s using api_gpt-4-turbo
2025-04-10 20:36:02,445 - INFO - Using default tokenizer.
2025-04-10 20:36:03,906 - INFO - Using default tokenizer.
2025-04-10 20:36:03,918 - INFO - [API] Starting reconstruction of text: 'Although , as you will have se...'
2025-04-10 20:36:03,926 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:03,933 - INFO - [API] Completed in 0.015s using basic reconstruction
2025-04-10 20:36:03,933 - INFO - Using default tokenizer.
2025-04-10 20:36:03,945 - INFO - [PIPELINE] Sample 1/50 (processed in 6.26s)
2025-04-10 20:36:03,945 - INFO - [PIPELINE] Original: Although , as you will have seen , the dreaded ' millennium bug ' failed to materialise , still the people in a number of countries suffered a series of natural disasters that truly were dreadful .
2025-04-10 20:36:03,945 - INFO - [PIPELINE] Semantic noisy: Although , as you wiet have seen , the dreaded ' millennium bug ' failed to materialise , still the people in a number of countries suffered a series of uaturzl disasters that truly were drbahful .
2025-04-10 20:36:03,945 - INFO - [PIPELINE] Semantic reconstructed: Although, as you you have have the dreaded the bug' failed to materialize, still the to in a number of countries in a series of natural disasters that truly of dreadful.
2025-04-10 20:36:03,945 - INFO - [PIPELINE] Direct noisy: Although , as you will have seen , the dzladed ' millennium bgg ' failed to materialise , still the pemple in a number of countries suffered a series of natural disasters that truly were dreadful .
2025-04-10 20:36:03,945 - INFO - [PIPELINE] Direct reconstructed: Although , as you will have seen , the dzladed ' millennium bgg ' failed to materialise , still the pemple in a number of countries suffered a series of natural disasters that truly were dreadful .
2025-04-10 20:36:03,945 - INFO - [PIPELINE] Semantic BLEU: 0.3047, ROUGE-L: 0.7742, SEMANTIC: 0.8242
2025-04-10 20:36:03,945 - INFO - [PIPELINE] Direct BLEU: 0.7876, ROUGE-L: 0.9032, SEMANTIC: 0.9348
2025-04-10 20:36:03,945 - INFO - [PIPELINE] Current cost: $0.0064 of $2.00
2025-04-10 20:36:03,945 - INFO - [PIPELINE] Progress: 1/50 samples. Est. remaining: 411.0s (6.9m)
2025-04-10 20:36:03,945 - INFO - ---
Processing samples:   2%|▍                       | 1/50 [00:06<05:06,  6.27s/it]/tmp/pycharm_project_908/Europearl/physical_semantic_integration.py:539: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1808.)
  variance = torch.var(tensor, dim=0)
2025-04-10 20:36:04,007 - INFO - [API] Starting reconstruction of text: 'You have requested a dlbave on...'
2025-04-10 20:36:04,012 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:04,015 - INFO - Basic reconstruction made changes: 'You have requested a dlbave on tbis subject in the cdursp of the next lec days , during this part-session .' -> 'You have requested a dlbave on tbis subjeat in the cdursp of the next lec days , during this part-session .'
2025-04-10 20:36:04,015 - INFO - [API] Completed in 0.008s using basic reconstruction
2025-04-10 20:36:04,015 - INFO - Using default tokenizer.
2025-04-10 20:36:04,027 - INFO - Using default tokenizer.
2025-04-10 20:36:04,038 - INFO - [API] Starting reconstruction of text: 'You have requested a debate on...'
2025-04-10 20:36:04,042 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:04,046 - INFO - Basic reconstruction made changes: 'You have requested a debate on this subject in the course of the next few days , during this part-session .' -> 'You have requested a debate on this subjeat in the course of the next few days , during this part-session .'
2025-04-10 20:36:04,046 - INFO - [API] Completed in 0.008s using basic reconstruction
2025-04-10 20:36:04,046 - INFO - Using default tokenizer.
2025-04-10 20:36:04,056 - INFO - [PIPELINE] Sample 2/50 (processed in 0.11s)
2025-04-10 20:36:04,056 - INFO - [PIPELINE] Original: You have requested a debate on this subject in the course of the next few days , during this part-session .
2025-04-10 20:36:04,056 - INFO - [PIPELINE] Semantic noisy: You have requested a dlbave on tbis subject in the cdursp of the next lec days , during this part-session .
2025-04-10 20:36:04,056 - INFO - [PIPELINE] Semantic reconstructed: You have requested a dlbave on tbis subjeat in the cdursp of the next lec days , during this part-session .
2025-04-10 20:36:04,056 - INFO - [PIPELINE] Direct noisy: You have requested a debate on this subject in the course of the next few days , during this part-session .
2025-04-10 20:36:04,056 - INFO - [PIPELINE] Direct reconstructed: You have requested a debate on this subjeat in the course of the next few days , during this part-session .
2025-04-10 20:36:04,057 - INFO - [PIPELINE] Semantic BLEU: 0.4304, ROUGE-L: 0.7500, SEMANTIC: 0.7810
2025-04-10 20:36:04,057 - INFO - [PIPELINE] Direct BLEU: 0.8656, ROUGE-L: 0.9500, SEMANTIC: 0.9787
2025-04-10 20:36:04,057 - INFO - [PIPELINE] Current cost: $0.0064 of $2.00
2025-04-10 20:36:04,057 - INFO - [PIPELINE] Progress: 2/50 samples. Est. remaining: 204.0s (3.4m)
2025-04-10 20:36:04,057 - INFO - ---
Processing samples:   4%|▉                       | 2/50 [00:06<02:06,  2.65s/it]2025-04-10 20:36:04,116 - INFO - [API] Starting reconstruction of text: 'Please rise , then , for this ...'
2025-04-10 20:36:04,118 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-10 20:36:05,277 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:05,281 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:05,282 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-10 20:36:05,282 - INFO - [API] Completed in 1.166s using api_gpt-4-turbo
2025-04-10 20:36:05,283 - INFO - Using default tokenizer.
2025-04-10 20:36:05,311 - INFO - Using default tokenizer.
2025-04-10 20:36:05,325 - INFO - [API] Starting reconstruction of text: 'dlezse rise , then , for tugs ...'
2025-04-10 20:36:05,328 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:05,331 - INFO - [API] Completed in 0.006s using basic reconstruction
2025-04-10 20:36:05,331 - INFO - Using default tokenizer.
Processing samples:   6%|█▍                      | 3/50 [00:07<01:35,  2.02s/it]2025-04-10 20:36:05,405 - INFO - [API] Starting reconstruction of text: '( The House rose and observed ...'
2025-04-10 20:36:05,411 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:05,415 - INFO - [API] Completed in 0.010s using basic reconstruction
2025-04-10 20:36:05,415 - INFO - Using default tokenizer.
2025-04-10 20:36:05,427 - INFO - Using default tokenizer.
2025-04-10 20:36:05,438 - INFO - [API] Starting reconstruction of text: '( The Houwm rose and observed ...'
2025-04-10 20:36:05,443 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:05,447 - INFO - [API] Completed in 0.009s using basic reconstruction
2025-04-10 20:36:05,447 - INFO - Using default tokenizer.
Processing samples:   8%|█▉                      | 4/50 [00:07<00:58,  1.27s/it]2025-04-10 20:36:05,516 - INFO - [API] Starting reconstruction of text: 'You will be aware xrnm the pre...'
2025-04-10 20:36:05,522 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-10 20:36:07,258 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:07,286 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:07,287 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-10 20:36:07,287 - INFO - [API] Completed in 1.771s using api_gpt-4-turbo
2025-04-10 20:36:07,288 - INFO - Using default tokenizer.
2025-04-10 20:36:07,316 - INFO - Using default tokenizer.
2025-04-10 20:36:07,330 - INFO - [API] Starting reconstruction of text: 'You will be aware from the pre...'
2025-04-10 20:36:07,336 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:07,341 - INFO - Basic reconstruction made changes: 'You will be aware from the press and television that toewe have been a number of uomx explosions and killings in Src Lanka .' -> 'You will be awaree from the press and television that toewe have been a number of uomx explosions and killings in Src Lanka .'
2025-04-10 20:36:07,341 - INFO - [API] Completed in 0.011s using basic reconstruction
2025-04-10 20:36:07,342 - INFO - Using default tokenizer.
Processing samples:  10%|██▍                     | 5/50 [00:09<01:07,  1.50s/it]2025-04-10 20:36:07,417 - INFO - [API] Starting reconstruction of text: 'One of the people assassinated...'
2025-04-10 20:36:07,424 - INFO - [API] Using KB reconstruction with confidence 1.04
2025-04-10 20:36:07,424 - INFO - [API] Completed in 0.007s using method: kb
2025-04-10 20:36:07,424 - INFO - Using default tokenizer.
2025-04-10 20:36:07,437 - INFO - Using default tokenizer.
2025-04-10 20:36:07,448 - INFO - [API] Starting reconstruction of text: 'One of the pkopce assasrinatek...'
2025-04-10 20:36:07,457 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-10 20:36:09,691 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:09,695 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:09,696 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-10 20:36:09,696 - INFO - [API] Completed in 2.248s using api_gpt-4-turbo
2025-04-10 20:36:09,697 - INFO - Using default tokenizer.
Processing samples:  12%|██▉                     | 6/50 [00:12<01:18,  1.79s/it]2025-04-10 20:36:09,785 - INFO - [API] Starting reconstruction of text: 'Yes , Mr Evans , I feel an ini...'
2025-04-10 20:36:09,791 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:09,795 - INFO - [API] Completed in 0.010s using basic reconstruction
2025-04-10 20:36:09,795 - INFO - Using default tokenizer.
2025-04-10 20:36:09,808 - INFO - Using default tokenizer.
2025-04-10 20:36:09,819 - INFO - [API] Starting reconstruction of text: 'Yes , Mr Evans , I feel an ini...'
2025-04-10 20:36:09,824 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:09,828 - INFO - [API] Completed in 0.009s using basic reconstruction
2025-04-10 20:36:09,828 - INFO - Using default tokenizer.
Processing samples:  14%|███▎                    | 7/50 [00:12<00:53,  1.24s/it]2025-04-10 20:36:09,897 - INFO - [API] Starting reconstruction of text: 'If the House agrees , I shall ...'
2025-04-10 20:36:09,900 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-10 20:36:10,446 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:10,451 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:10,451 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-10 20:36:10,451 - INFO - [API] Completed in 0.554s using api_gpt-3.5-turbo
2025-04-10 20:36:10,452 - INFO - Using default tokenizer.
2025-04-10 20:36:10,478 - INFO - Using default tokenizer.
2025-04-10 20:36:10,492 - INFO - [API] Starting reconstruction of text: 'If the Houss agrees , I stpll ...'
2025-04-10 20:36:10,495 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:10,497 - INFO - [API] Completed in 0.006s using basic reconstruction
2025-04-10 20:36:10,498 - INFO - Using default tokenizer.
Processing samples:  16%|███▊                    | 8/50 [00:12<00:44,  1.06s/it]2025-04-10 20:36:10,572 - INFO - [API] Starting reconstruction of text: 'Modpm President , on a point o...'
2025-04-10 20:36:10,574 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:10,576 - INFO - [API] Completed in 0.004s using basic reconstruction
2025-04-10 20:36:10,576 - INFO - Using default tokenizer.
2025-04-10 20:36:10,587 - INFO - Using default tokenizer.
2025-04-10 20:36:10,597 - INFO - [API] Starting reconstruction of text: 'Madam President , on a point o...'
2025-04-10 20:36:10,600 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-10 20:36:11,340 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:11,354 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:11,355 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-10 20:36:11,355 - INFO - [API] Completed in 0.758s using api_gpt-3.5-turbo
2025-04-10 20:36:11,355 - INFO - Using default tokenizer.
Processing samples:  18%|████▎                   | 9/50 [00:13<00:41,  1.00s/it]2025-04-10 20:36:11,446 - INFO - [API] Starting reconstruction of text: 'I would like your advice about...'
2025-04-10 20:36:11,450 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-10 20:36:12,143 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:12,147 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:12,147 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-10 20:36:12,147 - INFO - [API] Completed in 0.702s using api_gpt-3.5-turbo
2025-04-10 20:36:12,148 - INFO - Using default tokenizer.
2025-04-10 20:36:12,180 - INFO - Using default tokenizer.
2025-04-10 20:36:12,194 - INFO - [API] Starting reconstruction of text: 'I wqulb lbkr your advice about...'
2025-04-10 20:36:12,199 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:12,203 - INFO - [API] Completed in 0.009s using basic reconstruction
2025-04-10 20:36:12,203 - INFO - Using default tokenizer.
2025-04-10 20:36:12,215 - INFO - [PIPELINE] Sample 10/50 (processed in 0.83s)
2025-04-10 20:36:12,215 - INFO - [PIPELINE] Original: I would like your advice about Rule 143 concerning inadmissibility .
2025-04-10 20:36:12,215 - INFO - [PIPELINE] Semantic noisy: I would like your advice about Rule 143 concerning inadmissibility .
2025-04-10 20:36:12,215 - INFO - [PIPELINE] Semantic reconstructed: Madam President, on a point of Order, I would like your advice about Rule 143 concerning inadmissibility.
2025-04-10 20:36:12,215 - INFO - [PIPELINE] Direct noisy: I wqulb lbkr your advice about Rule or3 concerning inadmissibility .
2025-04-10 20:36:12,215 - INFO - [PIPELINE] Direct reconstructed: I wqulb lbkr your advice about Rule or3 concerning inadmissibility .
2025-04-10 20:36:12,215 - INFO - [PIPELINE] Semantic BLEU: 0.4797, ROUGE-L: 0.7407, SEMANTIC: 0.9078
2025-04-10 20:36:12,215 - INFO - [PIPELINE] Direct BLEU: 0.3508, ROUGE-L: 0.7000, SEMANTIC: 0.7915
2025-04-10 20:36:12,215 - INFO - [PIPELINE] Current cost: $0.0253 of $2.00
2025-04-10 20:36:12,215 - INFO - [PIPELINE] Progress: 10/50 samples. Est. remaining: 66.6s (1.1m)
2025-04-10 20:36:12,215 - INFO - ---
Processing samples:  20%|████▌                  | 10/50 [00:14<00:38,  1.05it/s]2025-04-10 20:36:12,274 - INFO - [API] Starting reconstruction of text: 'My qufstiot relates to shmetyi...'
2025-04-10 20:36:12,279 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:12,282 - INFO - [API] Completed in 0.008s using basic reconstruction
2025-04-10 20:36:12,282 - INFO - Using default tokenizer.
2025-04-10 20:36:12,294 - INFO - Using default tokenizer.
2025-04-10 20:36:12,305 - INFO - [API] Starting reconstruction of text: 'My question relates to sotethi...'
2025-04-10 20:36:12,309 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:12,312 - INFO - [API] Completed in 0.007s using basic reconstruction
2025-04-10 20:36:12,312 - INFO - Using default tokenizer.
Processing samples:  22%|█████                  | 11/50 [00:14<00:26,  1.44it/s]2025-04-10 20:36:12,379 - INFO - [API] Starting reconstruction of text: 'The nunhh report on multiannua...'
2025-04-10 20:36:12,391 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-10 20:36:14,455 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:14,470 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:14,471 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-10 20:36:14,471 - INFO - [API] Completed in 2.092s using api_gpt-4-turbo
2025-04-10 20:36:14,472 - INFO - Using default tokenizer.
2025-04-10 20:36:14,504 - INFO - Using default tokenizer.
2025-04-10 20:36:14,519 - INFO - [API] Starting reconstruction of text: 'The Cuniw report on muatiaanua...'
2025-04-10 20:36:14,530 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:14,542 - INFO - Basic reconstruction made changes: 'The Cuniw report on muatiaanual guidance pdogaammes comes before Parliament on Thuecday cnd contains a proposal in paragraph 6 that a form of quota penalties should be introduced for countrigy which fail to meet their fleet reduction targets annually .' -> 'The Cuniw report on muatiaanual guidance pdogaammes comes before Parliament on Thuecday cnd contains a proposal in paragraph 6 that a form of quota penalties should be introduced for countrigy which fail to meet their fleet reduation targets annually .'
2025-04-10 20:36:14,542 - INFO - [API] Completed in 0.023s using basic reconstruction
2025-04-10 20:36:14,542 - INFO - Using default tokenizer.
Processing samples:  24%|█████▌                 | 12/50 [00:16<00:44,  1.16s/it]2025-04-10 20:36:14,613 - INFO - [API] Starting reconstruction of text: 'It sdrs that toio should be do...'
2025-04-10 20:36:14,616 - INFO - [API] Using KB reconstruction with confidence 0.91
2025-04-10 20:36:14,616 - INFO - [API] Completed in 0.003s using method: kb
2025-04-10 20:36:14,616 - INFO - Using default tokenizer.
2025-04-10 20:36:14,627 - INFO - Using default tokenizer.
2025-04-10 20:36:14,637 - INFO - [API] Starting reconstruction of text: 'It sayn that tnqs should be do...'
2025-04-10 20:36:14,640 - INFO - [API] Using KB reconstruction with confidence 0.91
2025-04-10 20:36:14,640 - INFO - [API] Completed in 0.002s using method: kb
2025-04-10 20:36:14,640 - INFO - Using default tokenizer.
2025-04-10 20:36:14,705 - INFO - [API] Starting reconstruction of text: 'I believe thvy thf principle o...'
2025-04-10 20:36:14,712 - INFO - [API] Using KB reconstruction with confidence 1.02
2025-04-10 20:36:14,712 - INFO - [API] Completed in 0.007s using method: kb
2025-04-10 20:36:14,713 - INFO - Using default tokenizer.
2025-04-10 20:36:14,725 - INFO - Using default tokenizer.
2025-04-10 20:36:14,736 - INFO - [API] Starting reconstruction of text: 'I believe that the principle o...'
2025-04-10 20:36:14,743 - INFO - [API] Using KB reconstruction with confidence 1.06
2025-04-10 20:36:14,743 - INFO - [API] Completed in 0.007s using method: kb
2025-04-10 20:36:14,743 - INFO - Using default tokenizer.
Processing samples:  28%|██████▍                | 14/50 [00:17<00:24,  1.50it/s]2025-04-10 20:36:14,811 - INFO - [API] Starting reconstruction of text: 'I want to know yhether oaw can...'
2025-04-10 20:36:14,817 - INFO - [API] Using KB reconstruction with confidence 1.02
2025-04-10 20:36:14,817 - INFO - [API] Completed in 0.007s using method: kb
2025-04-10 20:36:14,818 - INFO - Using default tokenizer.
2025-04-10 20:36:15,008 - INFO - Using default tokenizer.
2025-04-10 20:36:15,023 - INFO - [API] Starting reconstruction of text: 'I want to know whether one can...'
2025-04-10 20:36:15,030 - INFO - [API] Using KB reconstruction with confidence 1.06
2025-04-10 20:36:15,030 - INFO - [API] Completed in 0.007s using method: kb
2025-04-10 20:36:15,030 - INFO - Using default tokenizer.
Processing samples:  30%|██████▉                | 15/50 [00:17<00:20,  1.75it/s]2025-04-10 20:36:15,102 - INFO - [API] Starting reconstruction of text: 'That is precisely the time whe...'
2025-04-10 20:36:15,106 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:15,109 - INFO - [API] Completed in 0.006s using basic reconstruction
2025-04-10 20:36:15,109 - INFO - Using default tokenizer.
2025-04-10 20:36:15,119 - INFO - Using default tokenizer.
2025-04-10 20:36:15,130 - INFO - [API] Starting reconstruction of text: 'Thrt is precisely the time whe...'
2025-04-10 20:36:15,132 - INFO - [API] Using KB reconstruction with confidence 1.02
2025-04-10 20:36:15,132 - INFO - [API] Completed in 0.003s using method: kb
2025-04-10 20:36:15,132 - INFO - Using default tokenizer.
2025-04-10 20:36:15,197 - INFO - [API] Starting reconstruction of text: 'on bhursdae prior to the stamt...'
2025-04-10 20:36:15,200 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:15,203 - INFO - [API] Completed in 0.006s using basic reconstruction
2025-04-10 20:36:15,203 - INFO - Using default tokenizer.
2025-04-10 20:36:15,213 - INFO - Using default tokenizer.
2025-04-10 20:36:15,223 - INFO - [API] Starting reconstruction of text: 'on Thursday prior to the start...'
2025-04-10 20:36:15,226 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-10 20:36:16,870 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:16,876 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:16,876 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-10 20:36:16,877 - INFO - [API] Completed in 1.653s using api_gpt-4-turbo
2025-04-10 20:36:16,877 - INFO - Using default tokenizer.
Processing samples:  34%|███████▊               | 17/50 [00:19<00:23,  1.39it/s]2025-04-10 20:36:16,963 - INFO - [API] Starting reconstruction of text: 'We shall call him Mr Hicks ....'
2025-04-10 20:36:16,966 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:16,967 - INFO - Basic reconstruction made changes: 'We shall call him Mr Hicks .' -> 'We shalll call him Mr Hicks .'
2025-04-10 20:36:16,968 - INFO - [API] Completed in 0.005s using basic reconstruction
2025-04-10 20:36:16,968 - INFO - Using default tokenizer.
2025-04-10 20:36:16,979 - INFO - Using default tokenizer.
2025-04-10 20:36:16,989 - INFO - [API] Starting reconstruction of text: 'We shall call tim Mr Hicks ....'
2025-04-10 20:36:16,991 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:16,993 - INFO - Basic reconstruction made changes: 'We shall call tim Mr Hicks .' -> 'We shalll call tim Mr Hicks .'
2025-04-10 20:36:16,993 - INFO - [API] Completed in 0.004s using basic reconstruction
2025-04-10 20:36:16,993 - INFO - Using default tokenizer.
Processing samples:  36%|████████▎              | 18/50 [00:19<00:18,  1.73it/s]2025-04-10 20:36:17,059 - INFO - [API] Starting reconstruction of text: 'At the request of a French Mem...'
2025-04-10 20:36:17,066 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:17,072 - INFO - [API] Completed in 0.013s using basic reconstruction
2025-04-10 20:36:17,072 - INFO - Using default tokenizer.
2025-04-10 20:36:17,084 - INFO - Using default tokenizer.
2025-04-10 20:36:17,095 - INFO - [API] Starting reconstruction of text: 'At thc request of a Frexkh Mem...'
2025-04-10 20:36:17,101 - INFO - [API] Using KB reconstruction with confidence 1.05
2025-04-10 20:36:17,101 - INFO - [API] Completed in 0.007s using method: kb
2025-04-10 20:36:17,101 - INFO - Using default tokenizer.
Processing samples:  38%|████████▋              | 19/50 [00:19<00:14,  2.16it/s]2025-04-10 20:36:17,167 - INFO - [API] Starting reconstruction of text: 'This is all in accordance with...'
2025-04-10 20:36:17,169 - INFO - [API] Using KB reconstruction with confidence 0.65
2025-04-10 20:36:17,169 - INFO - [API] Completed in 0.002s using method: kb
2025-04-10 20:36:17,169 - INFO - Using default tokenizer.
2025-04-10 20:36:17,180 - INFO - Using default tokenizer.
2025-04-10 20:36:17,189 - INFO - [API] Starting reconstruction of text: 'This is all in accordance with...'
2025-04-10 20:36:17,192 - INFO - [API] Using KB reconstruction with confidence 0.65
2025-04-10 20:36:17,192 - INFO - [API] Completed in 0.002s using method: kb
2025-04-10 20:36:17,192 - INFO - Using default tokenizer.
2025-04-10 20:36:17,201 - INFO - [PIPELINE] Sample 20/50 (processed in 0.09s)
2025-04-10 20:36:17,202 - INFO - [PIPELINE] Original: This is all in accordance with the principles that we have always upheld .
2025-04-10 20:36:17,202 - INFO - [PIPELINE] Semantic noisy: This is all in accordance with the principles that we have always upheld .
2025-04-10 20:36:17,202 - INFO - [PIPELINE] Semantic reconstructed: This all in accordance with the principles that we have always upheld .
2025-04-10 20:36:17,202 - INFO - [PIPELINE] Direct noisy: This is all in accordance with sht principles that we have ahwahs upheld .
2025-04-10 20:36:17,202 - INFO - [PIPELINE] Direct reconstructed: This all in accordance with sht principles that we have ahwahs upheld .
2025-04-10 20:36:17,202 - INFO - [PIPELINE] Semantic BLEU: 0.8617, ROUGE-L: 0.9600, SEMANTIC: 0.9833
2025-04-10 20:36:17,202 - INFO - [PIPELINE] Direct BLEU: 0.4030, ROUGE-L: 0.8000, SEMANTIC: 0.8687
2025-04-10 20:36:17,202 - INFO - [PIPELINE] Current cost: $0.0379 of $2.00
2025-04-10 20:36:17,202 - INFO - [PIPELINE] Progress: 20/50 samples. Est. remaining: 32.5s (0.5m)
2025-04-10 20:36:17,202 - INFO - ---
2025-04-10 20:36:17,256 - INFO - [API] Starting reconstruction of text: 'Thank you , Mr Segni , I shall...'
2025-04-10 20:36:17,259 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:17,260 - INFO - Basic reconstruction made changes: 'Thank you , Mr Segni , I shall do so gladly .' -> 'Thank you , Mr Segni , I shalll do so gladly .'
2025-04-10 20:36:17,260 - INFO - [API] Completed in 0.004s using basic reconstruction
2025-04-10 20:36:17,260 - INFO - Using default tokenizer.
2025-04-10 20:36:17,271 - INFO - Using default tokenizer.
2025-04-10 20:36:17,280 - INFO - [API] Starting reconstruction of text: 'Thank you , Mr Segni , I shall...'
2025-04-10 20:36:17,282 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-10 20:36:17,917 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:17,923 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:17,924 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-10 20:36:17,924 - INFO - [API] Completed in 0.644s using api_gpt-3.5-turbo
2025-04-10 20:36:17,924 - INFO - Using default tokenizer.
Processing samples:  42%|█████████▋             | 21/50 [00:20<00:12,  2.25it/s]2025-04-10 20:36:18,016 - INFO - [API] Starting reconstruction of text: 'Indeed , it is quite in keepin...'
2025-04-10 20:36:18,020 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:18,024 - INFO - [API] Completed in 0.009s using basic reconstruction
2025-04-10 20:36:18,024 - INFO - Using default tokenizer.
2025-04-10 20:36:18,036 - INFO - Using default tokenizer.
2025-04-10 20:36:18,047 - INFO - [API] Starting reconstruction of text: 'Indeed , it is qucte in keepin...'
2025-04-10 20:36:18,051 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-10 20:36:18,605 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:18,610 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:18,611 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-10 20:36:18,611 - INFO - [API] Completed in 0.564s using api_gpt-3.5-turbo
2025-04-10 20:36:18,612 - INFO - Using default tokenizer.
Processing samples:  44%|██████████             | 22/50 [00:20<00:14,  2.00it/s]2025-04-10 20:36:18,941 - INFO - [API] Starting reconstruction of text: 'Madam President , I ohoulw lik...'
2025-04-10 20:36:18,947 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-10 20:36:19,737 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:19,743 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:19,744 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-10 20:36:19,744 - INFO - [API] Completed in 0.803s using api_gpt-3.5-turbo
2025-04-10 20:36:19,745 - INFO - Using default tokenizer.
2025-04-10 20:36:19,774 - INFO - Using default tokenizer.
2025-04-10 20:36:19,789 - INFO - [API] Starting reconstruction of text: 'Madam Pwesidenu , I should lik...'
2025-04-10 20:36:19,795 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:19,799 - INFO - Basic reconstruction made changes: 'Madam Pwesidenu , I should like to draw your attention to a case in whcco this Parliament has consistently shown an interest .' -> 'Madam Pwesidenu , I should like to draw your attention to a case in whcco this Pareliament has consistently shown an interest .'
2025-04-10 20:36:19,799 - INFO - [API] Completed in 0.010s using basic reconstruction
2025-04-10 20:36:19,800 - INFO - Using default tokenizer.
Processing samples:  46%|██████████▌            | 23/50 [00:22<00:17,  1.50it/s]2025-04-10 20:36:19,871 - INFO - [API] Starting reconstruction of text: 'It is dge case of Alexander Ni...'
2025-04-10 20:36:19,874 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:19,876 - INFO - [API] Completed in 0.005s using basic reconstruction
2025-04-10 20:36:19,876 - INFO - Using default tokenizer.
2025-04-10 20:36:19,887 - INFO - Using default tokenizer.
2025-04-10 20:36:19,896 - INFO - [API] Starting reconstruction of text: 'It is the case of Alexander Ni...'
2025-04-10 20:36:19,899 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:19,900 - INFO - [API] Completed in 0.004s using basic reconstruction
2025-04-10 20:36:19,900 - INFO - Using default tokenizer.
2025-04-10 20:36:19,966 - INFO - [API] Starting reconstruction of text: 'All of us here are plgesed tha...'
2025-04-10 20:36:19,973 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-10 20:36:20,878 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:20,890 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:20,891 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-10 20:36:20,891 - INFO - [API] Completed in 0.925s using api_gpt-3.5-turbo
2025-04-10 20:36:20,892 - INFO - Using default tokenizer.
2025-04-10 20:36:20,922 - INFO - Using default tokenizer.
2025-04-10 20:36:20,937 - INFO - [API] Starting reconstruction of text: 'Alj of us here are mlwased tha...'
2025-04-10 20:36:20,943 - INFO - [API] Using KB reconstruction with confidence 1.05
2025-04-10 20:36:20,943 - INFO - [API] Completed in 0.006s using method: kb
2025-04-10 20:36:20,943 - INFO - Using default tokenizer.
Processing samples:  50%|███████████▌           | 25/50 [00:23<00:15,  1.59it/s]2025-04-10 20:36:21,016 - INFO - [API] Starting reconstruction of text: 'Now , however , he is to go be...'
2025-04-10 20:36:21,021 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:21,026 - INFO - [API] Completed in 0.010s using basic reconstruction
2025-04-10 20:36:21,026 - INFO - Using default tokenizer.
2025-04-10 20:36:21,038 - INFO - Using default tokenizer.
2025-04-10 20:36:21,048 - INFO - [API] Starting reconstruction of text: 'Now , however , he is to go be...'
2025-04-10 20:36:21,054 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:21,059 - INFO - [API] Completed in 0.011s using basic reconstruction
2025-04-10 20:36:21,059 - INFO - Using default tokenizer.
Processing samples:  52%|███████████▉           | 26/50 [00:23<00:12,  1.96it/s]2025-04-10 20:36:21,125 - INFO - [API] Starting reconstruction of text: 'Yes , Mrs Schroedter , I shall...'
2025-04-10 20:36:21,131 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:21,135 - INFO - Basic reconstruction made changes: 'Yes , Mrs Schroedter , I shall be pleased to look fkto tyg facts of this case wfjn I have received your letter .' -> 'Yes , Mrs Schroedter , I shall be pleased to look fkto tyg faats of this case wfjn I have received your letter .'
2025-04-10 20:36:21,135 - INFO - [API] Completed in 0.010s using basic reconstruction
2025-04-10 20:36:21,136 - INFO - Using default tokenizer.
2025-04-10 20:36:21,148 - INFO - Using default tokenizer.
2025-04-10 20:36:21,159 - INFO - [API] Starting reconstruction of text: 'Yes , Mrs Schroedter , I shall...'
2025-04-10 20:36:21,165 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:21,171 - INFO - Basic reconstruction made changes: 'Yes , Mrs Schroedter , I shall be jleased to lcxk into the facts of this case when I hwee received toua letter .' -> 'Yes , Mrs Schroedter , I shall be jleased to lcxk into the faats of this case when I hwee received toua letter .'
2025-04-10 20:36:21,171 - INFO - [API] Completed in 0.012s using basic reconstruction
2025-04-10 20:36:21,171 - INFO - Using default tokenizer.
Processing samples:  54%|████████████▍          | 27/50 [00:23<00:09,  2.42it/s]2025-04-10 20:36:21,239 - INFO - [API] Starting reconstruction of text: 'But , Madam Preaidenm , my per...'
2025-04-10 20:36:21,242 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:21,244 - INFO - [API] Completed in 0.006s using basic reconstruction
2025-04-10 20:36:21,245 - INFO - Using default tokenizer.
2025-04-10 20:36:21,256 - INFO - Using default tokenizer.
2025-04-10 20:36:21,266 - INFO - [API] Starting reconstruction of text: 'But , Mudbm President , my per...'
2025-04-10 20:36:21,270 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:21,274 - INFO - [API] Completed in 0.008s using basic reconstruction
2025-04-10 20:36:21,274 - INFO - Using default tokenizer.
Processing samples:  56%|████████████▉          | 28/50 [00:23<00:07,  3.01it/s]2025-04-10 20:36:21,341 - INFO - [API] Starting reconstruction of text: 'I would therefore once more as...'
2025-04-10 20:36:21,346 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:21,349 - INFO - [API] Completed in 0.008s using basic reconstruction
2025-04-10 20:36:21,350 - INFO - Using default tokenizer.
2025-04-10 20:36:21,361 - INFO - Using default tokenizer.
2025-04-10 20:36:21,371 - INFO - [API] Starting reconstruction of text: 'I would thgmefore once more as...'
2025-04-10 20:36:21,375 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-10 20:36:22,037 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:22,047 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:22,048 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-10 20:36:22,048 - INFO - [API] Completed in 0.677s using api_gpt-3.5-turbo
2025-04-10 20:36:22,048 - INFO - Using default tokenizer.
Processing samples:  58%|█████████████▎         | 29/50 [00:24<00:09,  2.19it/s]2025-04-10 20:36:22,136 - INFO - [API] Starting reconstruction of text: 'Mrs Plooij-van Gorsel , I can ...'
2025-04-10 20:36:22,141 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:22,145 - INFO - [API] Completed in 0.009s using basic reconstruction
2025-04-10 20:36:22,145 - INFO - Using default tokenizer.
2025-04-10 20:36:22,157 - INFO - Using default tokenizer.
2025-04-10 20:36:22,168 - INFO - [API] Starting reconstruction of text: 'uhs Plooij-van Gorsel , I can ...'
2025-04-10 20:36:22,173 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:22,177 - INFO - [API] Completed in 0.009s using basic reconstruction
2025-04-10 20:36:22,177 - INFO - Using default tokenizer.
2025-04-10 20:36:22,188 - INFO - [PIPELINE] Sample 30/50 (processed in 0.11s)
2025-04-10 20:36:22,188 - INFO - [PIPELINE] Original: Mrs Plooij-van Gorsel , I can tell you that this matter is on the agenda for the Quaestors ' meeting on Wednesday .
2025-04-10 20:36:22,188 - INFO - [PIPELINE] Semantic noisy: Mrs Plooij-van Gorsel , I can tell you that this matter is on the agenda for the Quaestors ' neetrng on Wednesday .
2025-04-10 20:36:22,188 - INFO - [PIPELINE] Semantic reconstructed: Mrs Plooij-van Gorsel , I can tell you that this matter is on the agenda for the Quaestors ' neetrng on Wednesday .
2025-04-10 20:36:22,188 - INFO - [PIPELINE] Direct noisy: uhs Plooij-van Gorsel , I can tell you that this matter is on the agenda for the Quaewtzrs ' meeting on Wednesday .
2025-04-10 20:36:22,188 - INFO - [PIPELINE] Direct reconstructed: uhs Plooij-van Gorsel , I can tell you that this matter is on the agenda for the Quaewtzrs ' meeting on Wednesday .
2025-04-10 20:36:22,188 - INFO - [PIPELINE] Semantic BLEU: 0.8787, ROUGE-L: 0.9524, SEMANTIC: 0.9784
2025-04-10 20:36:22,188 - INFO - [PIPELINE] Direct BLEU: 0.8318, ROUGE-L: 0.9048, SEMANTIC: 0.9438
2025-04-10 20:36:22,188 - INFO - [PIPELINE] Current cost: $0.0394 of $2.00
2025-04-10 20:36:22,188 - INFO - [PIPELINE] Progress: 30/50 samples. Est. remaining: 17.8s (0.3m)
2025-04-10 20:36:22,188 - INFO - ---
Processing samples:  60%|█████████████▊         | 30/50 [00:24<00:07,  2.77it/s]2025-04-10 20:36:22,243 - INFO - [API] Starting reconstruction of text: 'It will , I hope , be examined...'
2025-04-10 20:36:22,246 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:22,248 - INFO - [API] Completed in 0.005s using basic reconstruction
2025-04-10 20:36:22,249 - INFO - Using default tokenizer.
2025-04-10 20:36:22,259 - INFO - Using default tokenizer.
2025-04-10 20:36:22,268 - INFO - [API] Starting reconstruction of text: 'It will , I hope , be examined...'
2025-04-10 20:36:22,271 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:22,273 - INFO - [API] Completed in 0.005s using basic reconstruction
2025-04-10 20:36:22,273 - INFO - Using default tokenizer.
2025-04-10 20:36:22,336 - INFO - [API] Starting reconstruction of text: 'Madam President , can you tell...'
2025-04-10 20:36:22,342 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:22,347 - INFO - Basic reconstruction made changes: 'Madam President , can you tell me why this Parliament does nox adhere to the healzm and safety legislation that it actually passes ?' -> 'Madam President , can you tell me why this Parliament does nox adhere to the healzm and safety legislation that it aatually passes ?'
2025-04-10 20:36:22,347 - INFO - [API] Completed in 0.010s using basic reconstruction
2025-04-10 20:36:22,347 - INFO - Using default tokenizer.
2025-04-10 20:36:22,359 - INFO - Using default tokenizer.
2025-04-10 20:36:22,369 - INFO - [API] Starting reconstruction of text: 'Madam President , ggn you tell...'
2025-04-10 20:36:22,374 - INFO - [API] Using KB reconstruction with confidence 1.04
2025-04-10 20:36:22,374 - INFO - [API] Completed in 0.005s using method: kb
2025-04-10 20:36:22,374 - INFO - Using default tokenizer.
Processing samples:  64%|██████████████▋        | 32/50 [00:24<00:04,  4.09it/s]2025-04-10 20:36:22,440 - INFO - [API] Starting reconstruction of text: 'Why has no air quality test be...'
2025-04-10 20:36:22,443 - INFO - [API] Using KB reconstruction with confidence 1.02
2025-04-10 20:36:22,443 - INFO - [API] Completed in 0.003s using method: kb
2025-04-10 20:36:22,443 - INFO - Using default tokenizer.
2025-04-10 20:36:22,477 - INFO - Using default tokenizer.
2025-04-10 20:36:22,490 - INFO - [API] Starting reconstruction of text: 'dhy has no air qtality test be...'
2025-04-10 20:36:22,494 - INFO - [API] Using KB reconstruction with confidence 1.02
2025-04-10 20:36:22,494 - INFO - [API] Completed in 0.004s using method: kb
2025-04-10 20:36:22,494 - INFO - Using default tokenizer.
Processing samples:  66%|███████████████▏       | 33/50 [00:24<00:03,  4.67it/s]2025-04-10 20:36:22,562 - INFO - [API] Starting reconstruction of text: 'Why has there been no Health a...'
2025-04-10 20:36:22,566 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-10 20:36:24,840 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:24,847 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:24,847 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-10 20:36:24,848 - INFO - [API] Completed in 2.286s using api_gpt-4-turbo
2025-04-10 20:36:24,848 - INFO - Using default tokenizer.
2025-04-10 20:36:24,875 - INFO - Using default tokenizer.
2025-04-10 20:36:24,889 - INFO - [API] Starting reconstruction of text: 'Why has therx been no Health h...'
2025-04-10 20:36:24,893 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:24,897 - INFO - [API] Completed in 0.008s using basic reconstruction
2025-04-10 20:36:24,897 - INFO - Using default tokenizer.
Processing samples:  68%|███████████████▋       | 34/50 [00:27<00:12,  1.29it/s]2025-04-10 20:36:24,969 - INFO - [API] Starting reconstruction of text: 'Why has there been no fire dri...'
2025-04-10 20:36:24,974 - INFO - [API] Using KB reconstruction with confidence 0.97
2025-04-10 20:36:24,974 - INFO - [API] Completed in 0.005s using method: kb
2025-04-10 20:36:24,974 - INFO - Using default tokenizer.
2025-04-10 20:36:24,986 - INFO - Using default tokenizer.
2025-04-10 20:36:24,998 - INFO - [API] Starting reconstruction of text: 'Why has tzgre bbln no fire dri...'
2025-04-10 20:36:25,003 - INFO - [API] Using KB reconstruction with confidence 0.97
2025-04-10 20:36:25,003 - INFO - [API] Completed in 0.006s using method: kb
2025-04-10 20:36:25,004 - INFO - Using default tokenizer.
Processing samples:  70%|████████████████       | 35/50 [00:27<00:08,  1.68it/s]2025-04-10 20:36:25,073 - INFO - [API] Starting reconstruction of text: 'Why are there no fire inmtruct...'
2025-04-10 20:36:25,077 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:25,079 - INFO - Basic reconstruction made changes: 'Why are there no fire inmtructiqns ?' -> 'Why are there no fire inmtruatiqns ?'
2025-04-10 20:36:25,079 - INFO - [API] Completed in 0.006s using basic reconstruction
2025-04-10 20:36:25,079 - INFO - Using default tokenizer.
2025-04-10 20:36:25,090 - INFO - Using default tokenizer.
2025-04-10 20:36:25,099 - INFO - [API] Starting reconstruction of text: 'Why are there no fire instruct...'
2025-04-10 20:36:25,102 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:25,105 - INFO - Basic reconstruction made changes: 'Why are there no fire instructions ?' -> 'Why are there no fire instruations ?'
2025-04-10 20:36:25,105 - INFO - [API] Completed in 0.005s using basic reconstruction
2025-04-10 20:36:25,105 - INFO - Using default tokenizer.
2025-04-10 20:36:25,171 - INFO - [API] Starting reconstruction of text: 'Why have the staircases not be...'
2025-04-10 20:36:25,173 - INFO - [API] Using KB reconstruction with confidence 0.99
2025-04-10 20:36:25,173 - INFO - [API] Completed in 0.002s using method: kb
2025-04-10 20:36:25,173 - INFO - Using default tokenizer.
2025-04-10 20:36:25,184 - INFO - Using default tokenizer.
2025-04-10 20:36:25,194 - INFO - [API] Starting reconstruction of text: 'Why have the staircases noj be...'
2025-04-10 20:36:25,197 - INFO - [API] Using KB reconstruction with confidence 0.99
2025-04-10 20:36:25,197 - INFO - [API] Completed in 0.003s using method: kb
2025-04-10 20:36:25,197 - INFO - Using default tokenizer.
Processing samples:  74%|█████████████████      | 37/50 [00:27<00:04,  2.64it/s]2025-04-10 20:36:25,262 - INFO - [API] Starting reconstruction of text: 'Why are no-smoking areas not e...'
2025-04-10 20:36:25,265 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:25,267 - INFO - Basic reconstruction made changes: 'Why are no-smoking areas not enforced ?' -> 'Why aree no-smoking areeas not enforced ?'
2025-04-10 20:36:25,267 - INFO - [API] Completed in 0.005s using basic reconstruction
2025-04-10 20:36:25,267 - INFO - Using default tokenizer.
2025-04-10 20:36:25,277 - INFO - Using default tokenizer.
2025-04-10 20:36:25,287 - INFO - [API] Starting reconstruction of text: 'Why are no-smoking areas not e...'
2025-04-10 20:36:25,289 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-10 20:36:25,872 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:25,878 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:25,879 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-10 20:36:25,879 - INFO - [API] Completed in 0.592s using api_gpt-3.5-turbo
2025-04-10 20:36:25,879 - INFO - Using default tokenizer.
Processing samples:  76%|█████████████████▍     | 38/50 [00:28<00:05,  2.20it/s]2025-04-10 20:36:25,967 - INFO - [API] Starting reconstruction of text: 'It seems absolutely disgracefu...'
2025-04-10 20:36:25,971 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:25,974 - INFO - [API] Completed in 0.007s using basic reconstruction
2025-04-10 20:36:25,974 - INFO - Using default tokenizer.
2025-04-10 20:36:25,986 - INFO - Using default tokenizer.
2025-04-10 20:36:25,997 - INFO - [API] Starting reconstruction of text: 'It seems absolutely disgracefu...'
2025-04-10 20:36:26,000 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:26,004 - INFO - [API] Completed in 0.007s using basic reconstruction
2025-04-10 20:36:26,004 - INFO - Using default tokenizer.
Processing samples:  78%|█████████████████▉     | 39/50 [00:28<00:04,  2.72it/s]2025-04-10 20:36:26,071 - INFO - [API] Starting reconstruction of text: 'Mrs Lynne , you are quite righ...'
2025-04-10 20:36:26,074 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:26,077 - INFO - Basic reconstruction made changes: 'Mrs Lynne , you are quite right and I shall check whether this has actually not behz done .' -> 'Mrs Lynne , you are quite rightt and I shall check whether this has aatually not behz done .'
2025-04-10 20:36:26,077 - INFO - [API] Completed in 0.007s using basic reconstruction
2025-04-10 20:36:26,077 - INFO - Using default tokenizer.
2025-04-10 20:36:26,089 - INFO - Using default tokenizer.
2025-04-10 20:36:26,099 - INFO - [API] Starting reconstruction of text: 'Mrs Lynne , foo awm quite righ...'
2025-04-10 20:36:26,102 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:26,105 - INFO - Basic reconstruction made changes: 'Mrs Lynne , foo awm quite right and I shall check whether this has actually not been done .' -> 'Mrs Lynne , foo awm quite right and I shall check whether this has aatually not been done .'
2025-04-10 20:36:26,105 - INFO - [API] Completed in 0.006s using basic reconstruction
2025-04-10 20:36:26,106 - INFO - Using default tokenizer.
2025-04-10 20:36:26,116 - INFO - [PIPELINE] Sample 40/50 (processed in 0.10s)
2025-04-10 20:36:26,116 - INFO - [PIPELINE] Original: Mrs Lynne , you are quite right and I shall check whether this has actually not been done .
2025-04-10 20:36:26,116 - INFO - [PIPELINE] Semantic noisy: Mrs Lynne , you are quite right and I shall check whether this has actually not behz done .
2025-04-10 20:36:26,116 - INFO - [PIPELINE] Semantic reconstructed: Mrs Lynne , you are quite rightt and I shall check whether this has aatually not behz done .
2025-04-10 20:36:26,116 - INFO - [PIPELINE] Direct noisy: Mrs Lynne , foo awm quite right and I shall check whether this has actually not been done .
2025-04-10 20:36:26,116 - INFO - [PIPELINE] Direct reconstructed: Mrs Lynne , foo awm quite right and I shall check whether this has aatually not been done .
2025-04-10 20:36:26,116 - INFO - [PIPELINE] Semantic BLEU: 0.6005, ROUGE-L: 0.8235, SEMANTIC: 0.8459
2025-04-10 20:36:26,116 - INFO - [PIPELINE] Direct BLEU: 0.6290, ROUGE-L: 0.8235, SEMANTIC: 0.8847
2025-04-10 20:36:26,116 - INFO - [PIPELINE] Current cost: $0.0453 of $2.00
2025-04-10 20:36:26,116 - INFO - [PIPELINE] Progress: 40/50 samples. Est. remaining: 7.6s (0.1m)
2025-04-10 20:36:26,116 - INFO - ---
Processing samples:  80%|██████████████████▍    | 40/50 [00:28<00:02,  3.37it/s]2025-04-10 20:36:26,172 - INFO - [API] Starting reconstruction of text: 'I shall also gjfer the matter ...'
2025-04-10 20:36:26,177 - INFO - [API] Using KB reconstruction with confidence 1.06
2025-04-10 20:36:26,177 - INFO - [API] Completed in 0.005s using method: kb
2025-04-10 20:36:26,178 - INFO - Using default tokenizer.
2025-04-10 20:36:26,190 - INFO - Using default tokenizer.
2025-04-10 20:36:26,202 - INFO - [API] Starting reconstruction of text: 'I shall also refer the matter ...'
2025-04-10 20:36:26,207 - INFO - [API] Using KB reconstruction with confidence 1.06
2025-04-10 20:36:26,207 - INFO - [API] Completed in 0.005s using method: kb
2025-04-10 20:36:26,207 - INFO - Using default tokenizer.
Processing samples:  82%|██████████████████▊    | 41/50 [00:28<00:02,  4.10it/s]2025-04-10 20:36:26,276 - INFO - [API] Starting reconstruction of text: 'Madam President , Mrs Diey Gon...'
2025-04-10 20:36:26,283 - INFO - [API] Using KB reconstruction with confidence 1.06
2025-04-10 20:36:26,283 - INFO - [API] Completed in 0.007s using method: kb
2025-04-10 20:36:26,283 - INFO - Using default tokenizer.
2025-04-10 20:36:26,296 - INFO - Using default tokenizer.
2025-04-10 20:36:26,308 - INFO - [API] Starting reconstruction of text: 'Madam President , Mrs Díez Gon...'
2025-04-10 20:36:26,315 - INFO - [API] Using KB reconstruction with confidence 1.06
2025-04-10 20:36:26,315 - INFO - [API] Completed in 0.007s using method: kb
2025-04-10 20:36:26,316 - INFO - Using default tokenizer.
Processing samples:  84%|███████████████████▎   | 42/50 [00:28<00:01,  4.87it/s]2025-04-10 20:36:26,385 - INFO - [API] Starting reconstruction of text: 'The competent services hamg no...'
2025-04-10 20:36:26,391 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:26,396 - INFO - Basic reconstruction made changes: 'The competent services hamg not included them in the agenda on the grounds that they had been answered in a previous partvsussion .' -> 'The competent services hamg not included them in the agenda on the grounds that they had been answered in a previous paretvsussion .'
2025-04-10 20:36:26,396 - INFO - [API] Completed in 0.011s using basic reconstruction
2025-04-10 20:36:26,396 - INFO - Using default tokenizer.
2025-04-10 20:36:26,408 - INFO - Using default tokenizer.
2025-04-10 20:36:26,419 - INFO - [API] Starting reconstruction of text: 'The competent services have no...'
2025-04-10 20:36:26,424 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-10 20:36:27,059 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:27,064 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:27,065 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-10 20:36:27,065 - INFO - [API] Completed in 0.646s using api_gpt-3.5-turbo
2025-04-10 20:36:27,066 - INFO - Using default tokenizer.
Processing samples:  86%|███████████████████▊   | 43/50 [00:29<00:02,  2.73it/s]2025-04-10 20:36:27,154 - INFO - [API] Starting reconstruction of text: 'I would acl that they reconsid...'
2025-04-10 20:36:27,155 - INFO - [API] Using KB reconstruction with confidence 0.77
2025-04-10 20:36:27,155 - INFO - [API] Completed in 0.001s using method: kb
2025-04-10 20:36:27,156 - INFO - Using default tokenizer.
2025-04-10 20:36:27,167 - INFO - Using default tokenizer.
2025-04-10 20:36:27,177 - INFO - [API] Starting reconstruction of text: 'I would jsu tfit they reconsid...'
2025-04-10 20:36:27,179 - INFO - [API] Using KB reconstruction with confidence 0.77
2025-04-10 20:36:27,179 - INFO - [API] Completed in 0.002s using method: kb
2025-04-10 20:36:27,179 - INFO - Using default tokenizer.
2025-04-10 20:36:27,245 - INFO - [API] Starting reconstruction of text: 'The questions ancwerea prevrou...'
2025-04-10 20:36:27,252 - INFO - [API] Using KB reconstruction with confidence 1.06
2025-04-10 20:36:27,252 - INFO - [API] Completed in 0.007s using method: kb
2025-04-10 20:36:27,252 - INFO - Using default tokenizer.
2025-04-10 20:36:27,265 - INFO - Using default tokenizer.
2025-04-10 20:36:27,277 - INFO - [API] Starting reconstruction of text: 'ufe questions answajed previou...'
2025-04-10 20:36:27,284 - INFO - [API] Using KB reconstruction with confidence 1.06
2025-04-10 20:36:27,284 - INFO - [API] Completed in 0.007s using method: kb
2025-04-10 20:36:27,284 - INFO - Using default tokenizer.
Processing samples:  90%|████████████████████▋  | 45/50 [00:29<00:01,  4.05it/s]2025-04-10 20:36:27,350 - INFO - [API] Starting reconstruction of text: 'Mr Berenguer Fuster , we shall...'
2025-04-10 20:36:27,354 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:27,356 - INFO - Basic reconstruction made changes: 'Mr Berenguer Fuster , we shall cdetk all this .' -> 'Mr Berenguer Fuster , we shall cdetk shall this .'
2025-04-10 20:36:27,356 - INFO - [API] Completed in 0.006s using basic reconstruction
2025-04-10 20:36:27,356 - INFO - Using default tokenizer.
2025-04-10 20:36:27,367 - INFO - Using default tokenizer.
2025-04-10 20:36:27,376 - INFO - [API] Starting reconstruction of text: 'Mr wersnguer Fuster , we shall...'
2025-04-10 20:36:27,379 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:27,381 - INFO - Basic reconstruction made changes: 'Mr wersnguer Fuster , we shall check all tuhs .' -> 'Mr wersnguer Fuster , we shall check shall tuhs .'
2025-04-10 20:36:27,381 - INFO - [API] Completed in 0.005s using basic reconstruction
2025-04-10 20:36:27,382 - INFO - Using default tokenizer.
2025-04-10 20:36:27,446 - INFO - [API] Starting reconstruction of text: 'I admit that , at present , te...'
2025-04-10 20:36:27,449 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:27,451 - INFO - [API] Completed in 0.005s using basic reconstruction
2025-04-10 20:36:27,451 - INFO - Using default tokenizer.
2025-04-10 20:36:27,462 - INFO - Using default tokenizer.
2025-04-10 20:36:27,472 - INFO - [API] Starting reconstruction of text: 'I hdmit that , at zresekt , th...'
2025-04-10 20:36:27,476 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:27,478 - INFO - [API] Completed in 0.006s using basic reconstruction
2025-04-10 20:36:27,479 - INFO - Using default tokenizer.
Processing samples:  94%|█████████████████████▌ | 47/50 [00:29<00:00,  5.32it/s]2025-04-10 20:36:27,545 - INFO - [API] Starting reconstruction of text: 'We shall therefore look into i...'
2025-04-10 20:36:27,548 - INFO - [API] Using KB reconstruction with confidence 1.00
2025-04-10 20:36:27,548 - INFO - [API] Completed in 0.003s using method: kb
2025-04-10 20:36:27,549 - INFO - Using default tokenizer.
2025-04-10 20:36:27,561 - INFO - Using default tokenizer.
2025-04-10 20:36:27,572 - INFO - [API] Starting reconstruction of text: 'We snall therefore look into i...'
2025-04-10 20:36:27,574 - INFO - [API] Using KB reconstruction with confidence 1.00
2025-04-10 20:36:27,575 - INFO - [API] Completed in 0.003s using method: kb
2025-04-10 20:36:27,575 - INFO - Using default tokenizer.
2025-04-10 20:36:27,643 - INFO - [API] Starting reconstruction of text: 'aodai 's oecisioe not to renew...'
2025-04-10 20:36:27,648 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:27,652 - INFO - Basic reconstruction made changes: 'aodai 's oecisioe not to renew the xmbarjo is extremely dangerous considering the situation there .' -> 'aodai 's oecisioe not to renew the xmbarejo is extremely dangerous considering the situation there .'
2025-04-10 20:36:27,652 - INFO - [API] Completed in 0.009s using basic reconstruction
2025-04-10 20:36:27,652 - INFO - Using default tokenizer.
2025-04-10 20:36:27,664 - INFO - Using default tokenizer.
2025-04-10 20:36:27,674 - INFO - [API] Starting reconstruction of text: 'Today 's decision jot to renew...'
2025-04-10 20:36:27,678 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:27,682 - INFO - Basic reconstruction made changes: 'Today 's decision jot to renew tte embargo is extremely dangerous considering the situation tjepe .' -> 'Today 's decision jot to renew tte embarego is extremely dangerous considering the situation tjepe .'
2025-04-10 20:36:27,682 - INFO - [API] Completed in 0.008s using basic reconstruction
2025-04-10 20:36:27,682 - INFO - Using default tokenizer.
Processing samples:  98%|██████████████████████▌| 49/50 [00:30<00:00,  6.36it/s]2025-04-10 20:36:27,774 - INFO - [API] Starting reconstruction of text: 'So Parliament should send a ne...'
2025-04-10 20:36:27,778 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-10 20:36:28,453 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:28,486 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-10 20:36:28,487 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-10 20:36:28,487 - INFO - [API] Completed in 0.713s using api_gpt-3.5-turbo
2025-04-10 20:36:28,488 - INFO - Using default tokenizer.
2025-04-10 20:36:28,516 - INFO - Using default tokenizer.
2025-04-10 20:36:28,530 - INFO - [API] Starting reconstruction of text: 'So Parliament should send a me...'
2025-04-10 20:36:28,534 - INFO - [API] Decision not to use API: ppo_decision_basic
2025-04-10 20:36:28,538 - INFO - Basic reconstruction made changes: 'So Parliament should send a message , since that is tqe xirh of the vast majorifs .' -> 'So Pareliament should send a message , since that is tqe xirh of the vast majorifs .'
2025-04-10 20:36:28,538 - INFO - [API] Completed in 0.007s using basic reconstruction
2025-04-10 20:36:28,538 - INFO - Using default tokenizer.
2025-04-10 20:36:28,550 - INFO - [PIPELINE] Sample 50/50 (processed in 0.86s)
2025-04-10 20:36:28,550 - INFO - [PIPELINE] Original: So Parliament should send a message , since that is the wish of the vast majority .
2025-04-10 20:36:28,550 - INFO - [PIPELINE] Semantic noisy: So Parliament should send a nessvge , uince that is the wish of the vast majority .
2025-04-10 20:36:28,550 - INFO - [PIPELINE] Semantic reconstructed: So Parliament should send a message, since that is the the of the the majority.
2025-04-10 20:36:28,550 - INFO - [PIPELINE] Direct noisy: So Parliament should send a message , since that is tqe xirh of the vast majorifs .
2025-04-10 20:36:28,550 - INFO - [PIPELINE] Direct reconstructed: So Pareliament should send a message , since that is tqe xirh of the vast majorifs .
2025-04-10 20:36:28,550 - INFO - [PIPELINE] Semantic BLEU: 0.3921, ROUGE-L: 0.8667, SEMANTIC: 0.9201
2025-04-10 20:36:28,550 - INFO - [PIPELINE] Direct BLEU: 0.5174, ROUGE-L: 0.7333, SEMANTIC: 0.7153
2025-04-10 20:36:28,550 - INFO - [PIPELINE] Current cost: $0.0459 of $2.00
2025-04-10 20:36:28,550 - INFO - [PIPELINE] Progress: 50/50 samples. Est. remaining: 0.0s (0.0m)
2025-04-10 20:36:28,550 - INFO - ---
Processing samples: 100%|███████████████████████| 50/50 [00:30<00:00,  1.62it/s]
2025-04-10 20:36:28,561 - INFO - Saved PPO agent state
2025-04-10 20:36:28,561 - INFO - [PIPELINE] Saved enhanced RL agent state
2025-04-10 20:36:28,563 - INFO - Using default tokenizer.
2025-04-10 20:36:28,563 - INFO - Initialized knowledge base for evaluation
2025-04-10 20:36:28,609 - WARNING - [PIPELINE] Enhanced evaluation failed: dictionary changed size during iteration
2025-04-10 20:36:28,609 - WARNING - Continuing with standard metrics only
2025-04-10 20:36:28,728 - INFO - Total API cost: $0.0459 of $2.00 budget
2025-04-10 20:36:28,728 - INFO - 
=== Overall Results ===
2025-04-10 20:36:28,728 - INFO - [PIPELINE] Total time: 33.00s, Avg: 0.66s per sample
2025-04-10 20:36:28,728 - INFO - [PIPELINE] System dimensions: input=768, compressed=460
2025-04-10 20:36:28,728 - INFO - [PIPELINE] Semantic Reconstruction:
2025-04-10 20:36:28,728 - INFO - [PIPELINE] Semantic Average BLEU: 0.6287
2025-04-10 20:36:28,728 - INFO - [PIPELINE] Semantic Average ROUGE1: 0.8610
2025-04-10 20:36:28,729 - INFO - [PIPELINE] Semantic Average ROUGEL: 0.8610
2025-04-10 20:36:28,729 - INFO - [PIPELINE] Semantic Average METEOR: 0.8281
2025-04-10 20:36:28,729 - INFO - [PIPELINE] Semantic Average SEMANTIC: 0.8896
2025-04-10 20:36:28,729 - INFO - 
[PIPELINE] Direct Reconstruction:
2025-04-10 20:36:28,729 - INFO - [PIPELINE] Direct Average BLEU: 0.6014
2025-04-10 20:36:28,729 - INFO - [PIPELINE] Direct Average ROUGE1: 0.8288
2025-04-10 20:36:28,729 - INFO - [PIPELINE] Direct Average ROUGEL: 0.8288
2025-04-10 20:36:28,729 - INFO - [PIPELINE] Direct Average METEOR: 0.7964
2025-04-10 20:36:28,729 - INFO - [PIPELINE] Direct Average SEMANTIC: 0.8779
2025-04-10 20:36:28,729 - INFO - 
[PIPELINE] Total Cost: $0.0459 of $2.00 budget
2025-04-10 20:36:28,729 - INFO - [PIPELINE] Results saved to C:\Users\Daud\SemanticCommTransmission\pythonProject/sem_com_results/enhanced_run_20250410-203555
2025-04-10 20:36:28,729 - INFO - 
[PIPELINE] RL Agent Performance:
2025-04-10 20:36:28,729 - INFO - Total episodes: 31
2025-04-10 20:36:28,729 - INFO - Total reward: 276.62
2025-04-10 20:36:28,729 - INFO - Final exploration rate: 0.10
2025-04-10 20:36:28,729 - INFO - API efficiency: 1075.0136763780122
2025-04-10 20:36:28,729 - INFO - [PIPELINE] Visualizations saved to C:\Users\Daud\SemanticCommTransmission\pythonProject/sem_com_results/enhanced_run_20250410-203555

===== KNOWLEDGE BASE FUNCTIONALITY CHECK =====
✓ KB initialized successfully with 41 terms

Test 1:
  Input:      The Parliamemt will now vote on the propofal from the Commissiob.
  Corrected:  The Parliament will now vote on the proposal from the Commission
  Corrections: 3/3 expected terms
  Result:     ✓ KB applied corrections

Test 2:
  Input:      In accordancg with Rule 143, I wkulz like your acvioe.
  Corrected:  in accordance with Rule 143, I would like your advice
  Corrections: 4/3 expected terms
  Result:     ✓ KB applied corrections

Test 3:
  Input:      The Coupcil and Directave on environmentsl protrction.
  Corrected:  The Council and Directive on environmental protection
  Corrections: 4/4 expected terms
  Result:     ✓ KB applied corrections

===== SUMMARY =====
Tests passed: 3/3
Total corrections made: 11
KB Status: FUNCTIONING

====== Enhanced Semantic Communication Pipeline Complete ======
Overall improvements:
- Advanced Compression: Implemented VAE-based non-linear compression
- Content-Adaptive Coding: Implemented content-aware protection strategies
- Semantic Perceptual Loss: Added semantic similarity metrics and training
- Enhanced RL Agent: Improved state representation with semantic features

Final metrics:
  semantic_avg_BLEU: 0.6287
  semantic_avg_METEOR: 0.8281
  semantic_avg_ROUGE1: 0.8610
  semantic_avg_ROUGEL: 0.8610
  semantic_avg_SEMANTIC: 0.8896

Process finished with exit code 0
