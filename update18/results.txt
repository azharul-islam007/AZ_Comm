/home/ubuntu/anaconda3/bin/conda run -n myenv --no-capture-output python /tmp/pycharm_project_908/Europearl/SD5.py 
2025-04-15 15:16:17,169 - INFO - Using device: cuda
/home/ubuntu/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
2025-04-15 15:16:18,485 - INFO - Initialized Enhanced Physical Channel with frequency_selective channel, ofdm-16 modulation, SNR=18.0dB
2025-04-15 15:16:18,485 - INFO - Adaptive modulation enabled: thresholds at 15.0dB and 25.0dB
2025-04-15 15:16:18,485 - INFO - Unequal error protection enabled with 3 protection levels
  checkpoint = torch.load(self.content_classifier_path, map_location=device)
2025-04-15 15:16:18,489 - INFO - Using embedding dimension 460 from checkpoint
2025-04-15 15:16:18,493 - INFO - Content classifier loaded with strict parameter matching
2025-04-15 15:16:18,493 - INFO - Content-Adaptive Physical Channel initialized
2025-04-15 15:16:18,493 - INFO - Enhanced content-adaptive physical channel initialized
2025-04-15 15:16:18,493 - INFO - Will collect up to 10000 transmission pairs
2025-04-15 15:16:18,493 - INFO - Using device: cuda
2025-04-15 15:16:20,067 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:16:20,076 - INFO - ✅ OpenAI API connection successful

===== SYSTEM COMPONENT TEST =====
2025-04-15 15:16:20,079 - INFO - Loaded knowledge base from ./models/europarl_knowledge_base.pkl with 41 terms
2025-04-15 15:16:20,079 - INFO - Loaded knowledge base from ./models/europarl_knowledge_base.pkl with 41 terms (load #1)
Knowledge Base loaded with 41 terms

Test Case 1: Mrs Lynne, you are quite right and I shall check whether this ocs actually not been done.
1. KB Reconstruction (1 changes):
   Mrs Lynne, you are quite right and I shall check whether this has actually not been done.
2025-04-15 15:16:20,090 - INFO - KB reconstruction made changes: 'Mrs Lynne, you are quite right and I shall check whether this ocs actually not been done.' -> 'Mrs Lynne, you are quite right and I shall check whether this has actually not been done.'
2. Basic Reconstruction (1 changes):
   Mrs Lynne, you are quite right and I shall check whether this has actually not been done.
2025-04-15 15:16:20,090 - INFO - [API] Starting reconstruction of text: 'Mrs Lynne, you are quite right...'
2025-04-15 15:16:20,090 - INFO - [API] Important parliamentary term 'Lynne' present, increasing quality threshold
2025-04-15 15:16:20,094 - INFO - [API] KB made changes but quality score 0.00 below threshold 0.90
2025-04-15 15:16:20,098 - INFO - KB reconstruction made changes: 'Mrs Lynne, you are quite right and I shall check whether this ocs actually not been done.' -> 'Mrs Lynne, you are quite right and I shall check whether this has actually not been done.'
2025-04-15 15:16:20,098 - INFO - [API] Basic made changes but quality score 0.00 below threshold 0.90
2025-04-15 15:16:20,098 - INFO - [API] Selected GPT-4 Turbo for critical case
2025-04-15 15:16:20,098 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-15 15:16:21,118 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:16:21,126 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:16:21,127 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-15 15:16:21,127 - INFO - [API] Completed in 1.037s using api_gpt-4-turbo
3. API Reconstruction (3 changes):
   Mrs Lynne, you are quite rightt and I shall check whether this has aatually not been done.

Test Case 2: The Parliamemt will now vote on the propofal from the Commissiob.
1. KB Reconstruction (3 changes):
   The Parliament will now vote on the proposal from the Commission
2025-04-15 15:16:21,136 - INFO - KB reconstruction made changes: 'The Parliamemt will now vote on the propofal from the Commissiob.' -> 'The Parliament will now vote on the proposal from the Commission'
2. Basic Reconstruction (3 changes):
   The Parliament will now vote on the proposal from the Commission
2025-04-15 15:16:21,136 - INFO - [API] Starting reconstruction of text: 'The Parliamemt will now vote o...'
2025-04-15 15:16:21,140 - INFO - [API] KB made changes but quality score 0.67 below threshold 0.80
2025-04-15 15:16:21,144 - INFO - KB reconstruction made changes: 'The Parliamemt will now vote on the propofal from the Commissiob.' -> 'The Parliament will now vote on the proposal from the Commission'
2025-04-15 15:16:21,144 - INFO - [API] Basic made changes but quality score 0.67 below threshold 0.80
2025-04-15 15:16:21,144 - INFO - [API] Selected GPT-4 Turbo (sufficient budget)
2025-04-15 15:16:21,144 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-15 15:16:21,987 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:16:21,994 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:16:21,994 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-15 15:16:21,994 - INFO - [API] Completed in 0.858s using api_gpt-4-turbo
3. API Reconstruction (3 changes):
   The Parliament will now vote on the proposal from the Commission.

Test Case 3: In accordancg with Rule 143, I wkulz like your acvioe about this moetinp.
1. KB Reconstruction (4 changes):
   in accordance with Rule 143, I would like your advice about this moetinp.
2025-04-15 15:16:22,006 - INFO - KB reconstruction made changes: 'In accordancg with Rule 143, I wkulz like your acvioe about this moetinp.' -> 'in accordance with Rule 143, I would like your advice about this moetinp.'
2. Basic Reconstruction (4 changes):
   in accordance with Rule 143, I would like your advice about this moetinp.
2025-04-15 15:16:22,006 - INFO - [API] Starting reconstruction of text: 'In accordancg with Rule 143, I...'
2025-04-15 15:16:22,006 - INFO - [API] Important parliamentary term 'Rule' present, increasing quality threshold
2025-04-15 15:16:22,009 - INFO - [API] KB made changes but quality score 0.25 below threshold 0.90
2025-04-15 15:16:22,013 - INFO - KB reconstruction made changes: 'In accordancg with Rule 143, I wkulz like your acvioe about this moetinp.' -> 'in accordance with Rule 143, I would like your advice about this moetinp.'
2025-04-15 15:16:22,013 - INFO - [API] Basic made changes but quality score 0.25 below threshold 0.90
2025-04-15 15:16:22,013 - INFO - [API] Selected GPT-4 Turbo for critical case
2025-04-15 15:16:22,013 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-15 15:16:23,153 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:16:23,157 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:16:23,157 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-15 15:16:23,158 - INFO - [API] Completed in 1.152s using api_gpt-4-turbo
3. API Reconstruction (4 changes):
   In accordance with Rule 143, I would like your advice about this meeting.

===== RESULTS =====
Components tested: KB Reconstruction, Basic Reconstruction, API Reconstruction
Test cases corrected: 3/3
System status: ✓ FUNCTIONAL
2025-04-15 15:16:23,158 - INFO - Loaded dimensions from file: 768, 460
  checkpoint = torch.load(dvae_path, map_location=torch.device('cpu'))
2025-04-15 15:16:23,203 - INFO - System dimensions: {'input_dim': 768, 'compressed_dim': 460, 'dvae_input_dim': 460, 'dvae_hidden_dim': 920, 'dvae_latent_dim': 460}
2025-04-15 15:16:23,203 - INFO - Updated dimension original_dim: 768 → 768
2025-04-15 15:16:23,203 - INFO - Updated dimension compressed_dim: 460 → 460
2025-04-15 15:16:23,203 - INFO - Updated dimension dvae_latent_dim: 460 → 460
2025-04-15 15:16:23,203 - INFO - Initialized dimension registry: {'original': 768, 'compressed': 460, 'latent': 460}
2025-04-15 15:16:23,221 - INFO - System dimensions: {'input_dim': 768, 'compressed_dim': 460, 'dvae_input_dim': 460, 'dvae_hidden_dim': 920, 'dvae_latent_dim': 460}
2025-04-15 15:16:23,222 - INFO - [PIPELINE] Starting enhanced pipeline with parameters:
2025-04-15 15:16:23,222 - INFO - [PIPELINE] - samples: 50, noise: 0.15/gaussian
2025-04-15 15:16:23,222 - INFO - [PIPELINE] - API: 50%, Compare: True
2025-04-15 15:16:23,222 - INFO - [PIPELINE] - Features: VAE=True, Semantic=True, Adaptive=True
2025-04-15 15:16:23,222 - INFO - [PIPELINE] - System dimensions: input=768, compressed=460
2025-04-15 15:16:23,222 - INFO - [PIPELINE] Knowledge base initialized successfully
2025-04-15 15:16:23,222 - INFO - Precomputing KB enhancements...
2025-04-15 15:16:23,222 - INFO - Precomputed 41 common KB terms
2025-04-15 15:16:23,222 - INFO - Initializing semantic loss with bert-base-uncased model
/home/ubuntu/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
2025-04-15 15:16:24,045 - INFO - Semantic perceptual loss initialized successfully
2025-04-15 15:16:24,046 - INFO - [PIPELINE] Semantic perceptual loss initialized successfully
2025-04-15 15:16:24,063 - INFO - [PIPELINE] Loaded 10000 items from compressed data
2025-04-15 15:16:24,067 - INFO - [PIPELINE] Loaded 10000 original sentences
2025-04-15 15:16:24,067 - INFO - Loading existing VAE compressor from ./data/vae_compressor.pth
  checkpoint = torch.load(VAE_COMPRESSOR_PATH, map_location=device)
2025-04-15 15:16:24,108 - INFO - VAE compressor loaded: 768 → 460 dimensions
2025-04-15 15:16:24,109 - INFO - Note: Loaded standard model, but requested enhanced
2025-04-15 15:16:24,115 - INFO - Saved VAE dimensions to file: input=768, compressed=460
2025-04-15 15:16:24,116 - INFO - [PIPELINE] VAE compressor loaded successfully: 768 → 460
2025-04-15 15:16:24,116 - INFO - Initialized Enhanced Physical Channel with frequency_selective channel, ofdm-16 modulation, SNR=18.0dB
2025-04-15 15:16:24,116 - INFO - Adaptive modulation enabled: thresholds at 15.0dB and 25.0dB
2025-04-15 15:16:24,117 - INFO - Unequal error protection enabled with 3 protection levels
  checkpoint = torch.load(self.content_classifier_path, map_location=device)
2025-04-15 15:16:24,124 - INFO - Using embedding dimension 460 from checkpoint
2025-04-15 15:16:24,133 - INFO - Content classifier loaded with strict parameter matching
2025-04-15 15:16:24,133 - INFO - Content-Adaptive Physical Channel initialized
2025-04-15 15:16:24,133 - INFO - [PIPELINE] Physical channel upgraded to content-adaptive version
2025-04-15 15:16:24,134 - INFO - Using provided input dimension: 460
2025-04-15 15:16:24,134 - INFO - Loading pre-trained enhanced MLPDenoisingVAE from ./models/enhanced_mlp_dvae_model.pth
  checkpoint = torch.load(full_model_path, map_location=device)
2025-04-15 15:16:24,227 - INFO - Loaded model was trained with semantic perceptual loss
2025-04-15 15:16:24,227 - INFO - [PIPELINE] System configurations:
2025-04-15 15:16:24,227 - INFO -   - VAE compression: True
2025-04-15 15:16:24,227 - INFO -   - VAE dimensions: 768 → 460
2025-04-15 15:16:24,227 - INFO -   - DVAE dimensions: input=460, hidden=920, latent=460
2025-04-15 15:16:24,227 - INFO -   - Physical channel enabled: True
2025-04-15 15:16:24,227 - INFO -   - Content adaptive coding: True
2025-04-15 15:16:24,227 - INFO -   - Knowledge base enabled: True
2025-04-15 15:16:24,227 - INFO - [PIPELINE] IMPORTANT: Model dimensions are input=460, hidden=920, latent=460
  checkpoint = torch.load(path, map_location=self.model_device)
2025-04-15 15:16:24,425 - INFO - Loaded PPO agent (exploration rate: 0.08)
2025-04-15 15:16:24,426 - INFO - Initializing semantic loss with bert-base-uncased model
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
2025-04-15 15:16:25,275 - INFO - Semantic perceptual loss initialized successfully
2025-04-15 15:16:25,277 - INFO - [PIPELINE] Semantic channel optimizer initialized
2025-04-15 15:16:25,277 - INFO - [PIPELINE] Using enhanced RL agent for API optimization (exploration rate: 0.08)
2025-04-15 15:16:25,277 - INFO - === Starting Enhanced Semantic Reconstruction Pipeline ===
2025-04-15 15:16:25,277 - INFO - [PIPELINE] Noise level: 0.15, Noise type: gaussian
2025-04-15 15:16:25,277 - INFO - [PIPELINE] OpenAI API available: True
2025-04-15 15:16:25,277 - INFO - [PIPELINE] Physical channel enabled: True
Processing samples:   0%|                                | 0/50 [00:00<?, ?it/s]/tmp/pycharm_project_908/Europearl/physical_semantic_integration.py:539: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1808.)
  variance = torch.var(tensor, dim=0)
2025-04-15 15:16:25,367 - INFO - Using device: cuda
2025-04-15 15:16:25,891 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:16:25,897 - INFO - ✅ OpenAI API connection successful
  checkpoint = torch.load(VAE_COMPRESSOR_PATH, map_location=device)
2025-04-15 15:16:25,997 - INFO - [API] Starting reconstruction of text: 'Although , as you will hazf se...'
2025-04-15 15:16:26,015 - INFO - [API] Selected GPT-4 Turbo (sufficient budget)
2025-04-15 15:16:26,088 - INFO - [API] RL agent selected GPT-3.5 Turbo
2025-04-15 15:16:26,088 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-15 15:16:27,154 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:16:27,165 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:16:27,169 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-15 15:16:27,169 - INFO - [API] Completed in 1.172s using api_gpt-3.5-turbo
2025-04-15 15:16:27,171 - INFO - Using default tokenizer.
2025-04-15 15:16:28,642 - INFO - Using default tokenizer.
2025-04-15 15:16:28,654 - INFO - [API] Starting reconstruction of text: 'Although , as xot will have se...'
2025-04-15 15:16:28,670 - INFO - [API] Selected GPT-4 Turbo (sufficient budget)
2025-04-15 15:16:28,672 - INFO - [API] RL agent recommended non-API but overridden for quality
2025-04-15 15:16:28,672 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-15 15:16:30,259 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:16:30,275 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:16:30,278 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-15 15:16:30,278 - INFO - [API] Completed in 1.624s using api_gpt-4-turbo
2025-04-15 15:16:30,279 - INFO - Using default tokenizer.
2025-04-15 15:16:30,308 - INFO - [PIPELINE] Sample 1/50 (processed in 5.03s)
2025-04-15 15:16:30,308 - INFO - [PIPELINE] Original: Although , as you will have seen , the dreaded ' millennium bug ' failed to materialise , still the people in a number of countries suffered a series of natural disasters that truly were dreadful .
2025-04-15 15:16:30,308 - INFO - [PIPELINE] Semantic noisy: Although , as you will hazf seen , uht dreaded ' millennium bug ' failed to materiamise , still the ploxle in a number of countries suffered a series of natural disasters that truly were dreadful .
2025-04-15 15:16:30,308 - INFO - [PIPELINE] Semantic reconstructed: Although, as you will have seen, the dreaded 'millennium bug' failed to materialize, still the to in a number of countries in a series of natural disasters that truly of dreadful.
2025-04-15 15:16:30,308 - INFO - [PIPELINE] Direct noisy: Although , as xot will have seen , the dreaded ' millennium lbg ' failed to matjrialise , still the people in a number of countries suffered a series of natural diaaspers that truly were dreadful .
2025-04-15 15:16:30,308 - INFO - [PIPELINE] Direct reconstructed: Although, as you will have seen the dreaded the bug' failed to materialize, still the to in a number of countries in a series of natural disasters that truly of dreadful.
2025-04-15 15:16:30,308 - INFO - [PIPELINE] Semantic BLEU: 0.3502, ROUGE-L: 0.8710, SEMANTIC: 0.9298
2025-04-15 15:16:30,308 - INFO - [PIPELINE] Direct BLEU: 0.3807, ROUGE-L: 0.8387, SEMANTIC: 0.8538
2025-04-15 15:16:30,308 - INFO - [PIPELINE] Current cost: $0.0250 of $2.00
2025-04-15 15:16:30,308 - INFO - [PIPELINE] Progress: 1/50 samples. Est. remaining: 350.3s (5.8m)
2025-04-15 15:16:30,308 - INFO - ---
Processing samples:   2%|▍                       | 1/50 [00:05<04:06,  5.03s/it]/tmp/pycharm_project_908/Europearl/physical_semantic_integration.py:539: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1808.)
  variance = torch.var(tensor, dim=0)
2025-04-15 15:16:30,382 - INFO - [API] Starting reconstruction of text: 'You have requested a debate on...'
2025-04-15 15:16:30,390 - INFO - Basic reconstruction made changes: 'You have requested a debate on this smbdect in the course of the next few days , during this part-session .' -> 'You have requested a debate on this smbdeat in the course of the next few days , during this part-session .'
2025-04-15 15:16:30,390 - INFO - [API] Using high-quality basic reconstruction
2025-04-15 15:16:30,390 - INFO - [API] Completed in 0.008s using basic reconstruction
2025-04-15 15:16:30,390 - INFO - Using default tokenizer.
2025-04-15 15:16:30,404 - INFO - Using default tokenizer.
2025-04-15 15:16:30,415 - INFO - [API] Starting reconstruction of text: 'You have requested a debate on...'
2025-04-15 15:16:30,423 - INFO - Basic reconstruction made changes: 'You have requested a debate on this subject in the course of the nejh few days , during this part-session .' -> 'You have requested a debate on this subjeat in the course of the nejh few days , during this part-session .'
2025-04-15 15:16:30,423 - INFO - [API] Using high-quality basic reconstruction
2025-04-15 15:16:30,423 - INFO - [API] Completed in 0.008s using basic reconstruction
2025-04-15 15:16:30,423 - INFO - Using default tokenizer.
2025-04-15 15:16:30,435 - INFO - [PIPELINE] Sample 2/50 (processed in 0.13s)
2025-04-15 15:16:30,435 - INFO - [PIPELINE] Original: You have requested a debate on this subject in the course of the next few days , during this part-session .
2025-04-15 15:16:30,435 - INFO - [PIPELINE] Semantic noisy: You have requested a debate on this smbdect in the course of the next few days , during this part-session .
2025-04-15 15:16:30,435 - INFO - [PIPELINE] Semantic reconstructed: You have requested a debate on this smbdeat in the course of the next few days , during this part-session .
2025-04-15 15:16:30,435 - INFO - [PIPELINE] Direct noisy: You have requested a debate on this subject in the course of the nejh few days , during this part-session .
2025-04-15 15:16:30,435 - INFO - [PIPELINE] Direct reconstructed: You have requested a debate on this subjeat in the course of the nejh few days , during this part-session .
2025-04-15 15:16:30,435 - INFO - [PIPELINE] Semantic BLEU: 0.8656, ROUGE-L: 0.9500, SEMANTIC: 0.9742
2025-04-15 15:16:30,435 - INFO - [PIPELINE] Direct BLEU: 0.7242, ROUGE-L: 0.9000, SEMANTIC: 0.8958
2025-04-15 15:16:30,435 - INFO - [PIPELINE] Current cost: $0.0250 of $2.00
2025-04-15 15:16:30,435 - INFO - [PIPELINE] Progress: 2/50 samples. Est. remaining: 174.6s (2.9m)
2025-04-15 15:16:30,435 - INFO - ---
2025-04-15 15:16:41,920 - INFO - Using default tokenizer.
Processing samples:  18%|████▎                   | 9/50 [00:16<01:12,  1.77s/it]2025-04-15 15:16:42,013 - INFO - [API] Starting reconstruction of text: 'I would vgke your advice gbopt...'
2025-04-15 15:16:42,016 - INFO - [API] Using high-quality KB reconstruction
2025-04-15 15:16:42,017 - INFO - [API] Completed in 0.004s using method: kb
2025-04-15 15:16:42,017 - INFO - Using default tokenizer.
2025-04-15 15:16:42,029 - INFO - Using default tokenizer.
2025-04-15 15:16:42,041 - INFO - [API] Starting reconstruction of text: 'I would like youp ydvice about...'
2025-04-15 15:16:42,048 - INFO - [API] Selected GPT-4 Turbo (sufficient budget)
2025-04-15 15:16:42,049 - INFO - [API] RL agent selected GPT-3.5 Turbo
2025-04-15 15:16:42,049 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-15 15:16:42,613 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:16:42,617 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:16:42,618 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-15 15:16:42,618 - INFO - [API] Completed in 0.577s using api_gpt-3.5-turbo
2025-04-15 15:16:42,619 - INFO - Using default tokenizer.
2025-04-15 15:16:42,643 - INFO - [PIPELINE] Sample 10/50 (processed in 0.70s)
2025-04-15 15:16:42,643 - INFO - [PIPELINE] Original: I would like your advice about Rule 143 concerning inadmissibility .
2025-04-15 15:16:42,643 - INFO - [PIPELINE] Semantic noisy: I would vgke your advice gbopt Ruwe 143 concerning inadmissibility .
2025-04-15 15:16:42,643 - INFO - [PIPELINE] Semantic reconstructed: I would vgke your advice gbopt Rule 143 concerning inadmissibility .
2025-04-15 15:16:42,643 - INFO - [PIPELINE] Direct noisy: I would like youp ydvice about rsle se3 concerning inadmissibility .
2025-04-15 15:16:42,643 - INFO - [PIPELINE] Direct reconstructed: I would like your advice about Rule 3 concerning inadmissibility.
2025-04-15 15:16:42,643 - INFO - [PIPELINE] Semantic BLEU: 0.4497, ROUGE-L: 0.8000, SEMANTIC: 0.8142
2025-04-15 15:16:42,643 - INFO - [PIPELINE] Direct BLEU: 0.5978, ROUGE-L: 0.9000, SEMANTIC: 0.9916
2025-04-15 15:16:42,643 - INFO - [PIPELINE] Current cost: $0.0696 of $2.00
2025-04-15 15:16:42,643 - INFO - [PIPELINE] Progress: 10/50 samples. Est. remaining: 77.9s (1.3m)
2025-04-15 15:17:35,855 - INFO - Using default tokenizer.
Processing samples:  92%|█████████████████████▏ | 46/50 [01:10<00:04,  1.16s/it]2025-04-15 15:17:35,945 - INFO - [API] Starting reconstruction of text: 'I admit that , at present , th...'
2025-04-15 15:17:35,950 - INFO - [API] Selected GPT-4 Turbo (sufficient budget)
2025-04-15 15:17:35,952 - INFO - [API] RL agent recommended non-API but overridden for quality
2025-04-15 15:17:35,952 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-15 15:17:36,895 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:17:36,899 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:17:36,900 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-15 15:17:36,900 - INFO - [API] Completed in 0.955s using api_gpt-4-turbo
2025-04-15 15:17:36,901 - INFO - Using default tokenizer.
2025-04-15 15:17:36,928 - INFO - Using default tokenizer.
2025-04-15 15:17:36,942 - INFO - [API] Starting reconstruction of text: 'I cdmnt that , at vressnt , th...'
2025-04-15 15:17:36,947 - INFO - [API] Selected GPT-4 Turbo (sufficient budget)
2025-04-15 15:17:36,949 - INFO - [API] RL agent selected GPT-3.5 Turbo
2025-04-15 15:17:36,949 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-15 15:17:37,575 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:17:37,585 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:17:37,586 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-15 15:17:37,586 - INFO - [API] Completed in 0.645s using api_gpt-3.5-turbo
2025-04-15 15:17:37,587 - INFO - Using default tokenizer.
Processing samples:  94%|█████████████████████▌ | 47/50 [01:12<00:04,  1.33s/it]2025-04-15 15:17:37,681 - INFO - [API] Starting reconstruction of text: 'We shall therefore lock into i...'
2025-04-15 15:17:37,684 - INFO - [API] KB made changes but quality score 0.00 below threshold 0.80
2025-04-15 15:17:37,686 - INFO - KB reconstruction made changes: 'We shall therefore lock into it prcperty to ensure that everything is as it shouad be .' -> 'We shall therefore lock into it prcperty to ensure that meeting is as it shouad be .'
2025-04-15 15:17:37,687 - INFO - [API] Basic made changes but quality score 0.00 below threshold 0.80
2025-04-15 15:17:37,687 - INFO - [API] Selected GPT-4 Turbo (sufficient budget)
2025-04-15 15:17:37,688 - INFO - [API] RL agent selected GPT-3.5 Turbo
2025-04-15 15:17:37,688 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-15 15:17:38,313 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:17:38,319 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:17:38,320 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-15 15:17:38,320 - INFO - [API] Completed in 0.639s using api_gpt-3.5-turbo
2025-04-15 15:17:38,321 - INFO - Using default tokenizer.
2025-04-15 15:17:38,348 - INFO - Using default tokenizer.
2025-04-15 15:17:38,363 - INFO - [API] Starting reconstruction of text: 'We shall therefore lmof into i...'
2025-04-15 15:17:38,366 - INFO - [API] KB made changes but quality score 0.00 below threshold 0.80
2025-04-15 15:17:38,368 - INFO - KB reconstruction made changes: 'We shall therefore lmof into it properly to ensure trlt everything is as it should be .' -> 'We shall therefore lmof into it properly to ensure trlt meeting is as it should be .'
2025-04-15 15:17:38,368 - INFO - [API] Basic made changes but quality score 0.00 below threshold 0.80
2025-04-15 15:17:38,369 - INFO - [API] Selected GPT-4 Turbo (sufficient budget)
2025-04-15 15:17:38,370 - INFO - [API] RL agent selected GPT-3.5 Turbo
2025-04-15 15:17:38,370 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-15 15:17:38,940 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:17:38,944 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:17:38,945 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-15 15:17:38,945 - INFO - [API] Completed in 0.582s using api_gpt-3.5-turbo
2025-04-15 15:17:38,946 - INFO - Using default tokenizer.
2025-04-15 15:17:39,083 - INFO - Using default tokenizer.
Processing samples:  98%|██████████████████████▌| 49/50 [01:13<00:00,  1.03it/s]2025-04-15 15:17:39,177 - INFO - [API] Starting reconstruction of text: 'So Parliament should send a me...'
2025-04-15 15:17:39,177 - INFO - [API] Important parliamentary term 'Parliament' present, increasing quality threshold
2025-04-15 15:17:39,183 - INFO - Basic reconstruction made changes: 'So Parliament should send a message , sinmv that is the wish of the vast majority .' -> 'So Pareliament should send a message , sinmv that is the wish of the vast majority .'
2025-04-15 15:17:39,183 - INFO - [API] Basic made changes but quality score 0.00 below threshold 0.90
2025-04-15 15:17:39,183 - INFO - [API] Selected GPT-4 Turbo for critical case
2025-04-15 15:17:39,183 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-15 15:17:39,940 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:17:39,943 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:17:39,944 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-15 15:17:39,944 - INFO - [API] Completed in 0.767s using api_gpt-4-turbo
2025-04-15 15:17:39,945 - INFO - Using default tokenizer.
2025-04-15 15:17:39,973 - INFO - Using default tokenizer.
2025-04-15 15:17:39,987 - INFO - [API] Starting reconstruction of text: 'So Parliament should send a me...'
2025-04-15 15:17:39,987 - INFO - [API] Important parliamentary term 'Parliament' present, increasing quality threshold
2025-04-15 15:17:39,993 - INFO - Basic reconstruction made changes: 'So Parliament should send a message , since that is the ciqh of the vast majority .' -> 'So Pareliament should send a message , since that is the ciqh of the vast majority .'
2025-04-15 15:17:39,993 - INFO - [API] Basic made changes but quality score 0.00 below threshold 0.90
2025-04-15 15:17:39,993 - INFO - [API] Selected GPT-4 Turbo for critical case
2025-04-15 15:17:39,993 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-15 15:17:40,721 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:17:40,725 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 15:17:40,726 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-15 15:17:40,726 - INFO - [API] Completed in 0.739s using api_gpt-4-turbo
2025-04-15 15:17:40,727 - INFO - Using default tokenizer.
2025-04-15 15:17:40,754 - INFO - [PIPELINE] Sample 50/50 (processed in 1.66s)
2025-04-15 15:17:40,754 - INFO - [PIPELINE] Original: So Parliament should send a message , since that is the wish of the vast majority .
2025-04-15 15:17:40,754 - INFO - [PIPELINE] Semantic noisy: So Parliament should send a message , sinmv that is the wish of the vast majority .
2025-04-15 15:17:40,754 - INFO - [PIPELINE] Semantic reconstructed: So Parliament should send a message, saying that is the wish of the vast majority.
2025-04-15 15:17:40,754 - INFO - [PIPELINE] Direct noisy: So Parliament should send a message , since that is the ciqh of the vast majority .
2025-04-15 15:17:40,754 - INFO - [PIPELINE] Direct reconstructed: So Parliament should send a message, since that is the ciqh of the vast majority.
2025-04-15 15:17:40,755 - INFO - [PIPELINE] Semantic BLEU: 0.5667, ROUGE-L: 0.9333, SEMANTIC: 0.9743
2025-04-15 15:17:40,755 - INFO - [PIPELINE] Direct BLEU: 0.4319, ROUGE-L: 0.9333, SEMANTIC: 0.9434
2025-04-15 15:17:40,755 - INFO - [PIPELINE] Current cost: $0.2531 of $2.00
2025-04-15 15:17:40,755 - INFO - [PIPELINE] Progress: 50/50 samples. Est. remaining: 0.0s (0.0m)
2025-04-15 15:17:40,755 - INFO - ---
Processing samples: 100%|███████████████████████| 50/50 [01:15<00:00,  1.51s/it]
2025-04-15 15:17:40,767 - INFO - Saved PPO agent state
2025-04-15 15:17:40,767 - INFO - [PIPELINE] Saved enhanced RL agent state
2025-04-15 15:17:40,768 - INFO - Using default tokenizer.
2025-04-15 15:17:40,768 - INFO - Initialized knowledge base for evaluation
2025-04-15 15:17:41,314 - INFO - 
=== Enhanced Evaluation Results ===
2025-04-15 15:17:41,314 - INFO - Overall Score: 0.8463
2025-04-15 15:17:41,314 - INFO - Semantic Fidelity: 0.8889
2025-04-15 15:17:41,314 - INFO - Linguistic Quality: 0.7437
2025-04-15 15:17:41,314 - INFO - Domain Relevance: 0.9289
2025-04-15 15:17:41,314 - INFO - Information Preservation: 0.8181
2025-04-15 15:17:41,437 - INFO - Total API cost: $0.2531 of $2.00 budget
2025-04-15 15:17:41,437 - INFO - 
=== Overall Results ===
2025-04-15 15:17:41,437 - INFO - [PIPELINE] Total time: 77.61s, Avg: 1.55s per sample
2025-04-15 15:17:41,437 - INFO - [PIPELINE] System dimensions: input=768, compressed=460
2025-04-15 15:17:41,437 - INFO - [PIPELINE] Semantic Reconstruction:
2025-04-15 15:17:41,438 - INFO - [PIPELINE] Semantic Average BLEU: 0.5734
2025-04-15 15:17:41,438 - INFO - [PIPELINE] Semantic Average ROUGE1: 0.9139
2025-04-15 15:17:41,438 - INFO - [PIPELINE] Semantic Average ROUGEL: 0.9139
2025-04-15 15:17:41,438 - INFO - [PIPELINE] Semantic Average METEOR: 0.7439
2025-04-15 15:17:41,438 - INFO - [PIPELINE] Semantic Average SEMANTIC: 0.9354
2025-04-15 15:17:41,438 - INFO - 
[PIPELINE] Direct Reconstruction:
2025-04-15 15:17:41,438 - INFO - [PIPELINE] Direct Average BLEU: 0.5507
2025-04-15 15:17:41,438 - INFO - [PIPELINE] Direct Average ROUGE1: 0.9066
2025-04-15 15:17:41,438 - INFO - [PIPELINE] Direct Average ROUGEL: 0.9066
2025-04-15 15:17:41,438 - INFO - [PIPELINE] Direct Average METEOR: 0.7371
2025-04-15 15:17:41,438 - INFO - [PIPELINE] Direct Average SEMANTIC: 0.9355
2025-04-15 15:17:41,438 - INFO - 
[PIPELINE] Total Cost: $0.2531 of $2.00 budget
2025-04-15 15:17:41,438 - INFO - [PIPELINE] Results saved to C:\Users\Daud\SemanticCommTransmission\pythonProject/sem_com_results/enhanced_run_20250415-151623
2025-04-15 15:17:41,438 - INFO - 
[PIPELINE] RL Agent Performance:
2025-04-15 15:17:41,438 - INFO - Total episodes: 504
2025-04-15 15:17:41,438 - INFO - Total reward: 1443.21
2025-04-15 15:17:41,438 - INFO - Final exploration rate: 0.07
2025-04-15 15:17:41,438 - INFO - API efficiency: 1616.5925198523032
2025-04-15 15:17:41,438 - INFO - [PIPELINE] Visualizations saved to C:\Users\Daud\SemanticCommTransmission\pythonProject/sem_com_results/enhanced_run_20250415-151623

===== KNOWLEDGE BASE FUNCTIONALITY CHECK =====
✓ KB initialized successfully with 41 terms

Test 1:
  Input:      The Parliamemt will now vote on the propofal from the Commissiob.
  Corrected:  The Parliament will now vote on the proposal from the Commission
  Corrections: 3/3 expected terms
  Result:     ✓ KB applied corrections

Test 2:
  Input:      In accordancg with Rule 143, I wkulz like your acvioe.
  Corrected:  in accordance with Rule 143, I would like your advice
  Corrections: 4/3 expected terms
  Result:     ✓ KB applied corrections

Test 3:
  Input:      The Coupcil and Directave on environmentsl protrction.
  Corrected:  The Council and Directive on environmental protection
  Corrections: 4/4 expected terms
  Result:     ✓ KB applied corrections

===== SUMMARY =====
Tests passed: 3/3
Total corrections made: 11
KB Status: FUNCTIONING

====== Enhanced Semantic Communication Pipeline Complete ======
Overall improvements:
- Advanced Compression: Implemented VAE-based non-linear compression
- Content-Adaptive Coding: Implemented content-aware protection strategies
- Semantic Perceptual Loss: Added semantic similarity metrics and training
- Enhanced RL Agent: Improved state representation with semantic features

Final metrics:
  semantic_avg_BLEU: 0.5734
  semantic_avg_METEOR: 0.7439
  semantic_avg_ROUGE1: 0.9139
  semantic_avg_ROUGEL: 0.9139
  semantic_avg_SEMANTIC: 0.9354

Process finished with exit code 0
