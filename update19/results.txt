/home/ubuntu/anaconda3/bin/conda run -n myenv --no-capture-output python /tmp/pycharm_project_908/Europearl/SD5.py 
2025-04-15 20:17:27,303 - INFO - Using device: cuda
/home/ubuntu/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
2025-04-15 20:17:28,732 - INFO - Initialized Enhanced Physical Channel with frequency_selective channel, ofdm-16 modulation, SNR=18.0dB
2025-04-15 20:17:28,732 - INFO - Adaptive modulation enabled: thresholds at 15.0dB and 25.0dB
2025-04-15 20:17:28,732 - INFO - Unequal error protection enabled with 3 protection levels
/tmp/pycharm_project_908/Europearl/content_adaptive_coding.py:406: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(self.content_classifier_path, map_location=device)
2025-04-15 20:17:28,774 - INFO - Using embedding dimension 460 from checkpoint
2025-04-15 20:17:28,805 - INFO - Content classifier loaded with strict parameter matching
2025-04-15 20:17:28,805 - INFO - Content-Adaptive Physical Channel initialized
2025-04-15 20:17:28,805 - INFO - Enhanced content-adaptive physical channel initialized
2025-04-15 20:17:28,805 - INFO - Will collect up to 10000 transmission pairs
2025-04-15 20:17:28,805 - INFO - Using device: cuda
2025-04-15 20:17:30,389 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:30,397 - INFO - ✅ OpenAI API connection successful

===== SYSTEM COMPONENT TEST =====
2025-04-15 20:17:30,400 - INFO - Loaded knowledge base from ./models/europarl_knowledge_base.pkl with 41 terms
2025-04-15 20:17:30,400 - INFO - Loaded knowledge base from ./models/europarl_knowledge_base.pkl with 41 terms (load #1)
Knowledge Base loaded with 41 terms

Test Case 1: Mrs Lynne, you are quite right and I shall check whether this ocs actually not been done.
1. KB Reconstruction (1 changes):
   Mrs Lynne, you are quite right and I shall check whether this has actually not been done.
2025-04-15 20:17:30,412 - INFO - KB reconstruction made changes: 'Mrs Lynne, you are quite right and I shall check whether this ocs actually not been done.' -> 'Mrs Lynne, you are quite right and I shall check whether this has actually not been done.'
2. Basic Reconstruction (1 changes):
   Mrs Lynne, you are quite right and I shall check whether this has actually not been done.
2025-04-15 20:17:30,412 - INFO - [API] Starting reconstruction of text: 'Mrs Lynne, you are quite right...'
2025-04-15 20:17:30,412 - INFO - [API] Important parliamentary term 'Lynne' present, increasing quality threshold
2025-04-15 20:17:30,416 - INFO - [API] KB made changes but quality score 0.00 below threshold 0.75
2025-04-15 20:17:30,420 - INFO - KB reconstruction made changes: 'Mrs Lynne, you are quite right and I shall check whether this ocs actually not been done.' -> 'Mrs Lynne, you are quite right and I shall check whether this has actually not been done.'
2025-04-15 20:17:30,420 - INFO - [API] Basic made changes but quality score 0.00 below threshold 0.75
2025-04-15 20:17:30,420 - INFO - [API] Selected GPT-4 Turbo for critical case
2025-04-15 20:17:30,420 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-15 20:17:31,636 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:31,640 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:31,642 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-15 20:17:31,642 - INFO - [API] Completed in 1.230s using api_gpt-4-turbo
3. API Reconstruction (3 changes):
   Mrs Lynne, you are quite rightt and I shall check whether this has aatually not been done.

Test Case 2: The Parliamemt will now vote on the propofal from the Commissiob.
1. KB Reconstruction (3 changes):
   The Parliament will now vote on the proposal from the Commission
2025-04-15 20:17:31,654 - INFO - KB reconstruction made changes: 'The Parliamemt will now vote on the propofal from the Commissiob.' -> 'The Parliament will now vote on the proposal from the Commission'
2. Basic Reconstruction (3 changes):
   The Parliament will now vote on the proposal from the Commission
2025-04-15 20:17:31,654 - INFO - [API] Starting reconstruction of text: 'The Parliamemt will now vote o...'
2025-04-15 20:17:31,659 - INFO - [API] Using high-quality KB reconstruction
2025-04-15 20:17:31,659 - INFO - [API] Completed in 0.005s using method: kb
3. API Reconstruction (3 changes):
   The Parliament will now vote on the proposal from the Commission

Test Case 3: In accordancg with Rule 143, I wkulz like your acvioe about this moetinp.
1. KB Reconstruction (4 changes):
   In accordance with Rule 143, I would like your advice about this meeting
2025-04-15 20:17:31,664 - INFO - KB reconstruction made changes: 'In accordancg with Rule 143, I wkulz like your acvioe about this moetinp.' -> 'In accordance with Rule 143, I would like your advice about this meeting'
2. Basic Reconstruction (4 changes):
   In accordance with Rule 143, I would like your advice about this meeting
2025-04-15 20:17:31,664 - INFO - [API] Starting reconstruction of text: 'In accordancg with Rule 143, I...'
2025-04-15 20:17:31,664 - INFO - [API] Important parliamentary term 'Rule' present, increasing quality threshold
2025-04-15 20:17:31,666 - INFO - [API] KB made changes but quality score 0.25 below threshold 0.75
2025-04-15 20:17:31,668 - INFO - KB reconstruction made changes: 'In accordancg with Rule 143, I wkulz like your acvioe about this moetinp.' -> 'In accordance with Rule 143, I would like your advice about this meeting'
2025-04-15 20:17:31,668 - INFO - [API] Basic made changes but quality score 0.25 below threshold 0.75
2025-04-15 20:17:31,668 - INFO - [API] Selected GPT-4 Turbo for critical case
2025-04-15 20:17:31,668 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-15 20:17:32,929 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:32,933 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:32,934 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-15 20:17:32,934 - INFO - [API] Completed in 1.271s using api_gpt-4-turbo
3. API Reconstruction (4 changes):
   In accordance with Rule 143, I would like your advice about this meeting.

===== RESULTS =====
Components tested: KB Reconstruction, Basic Reconstruction, API Reconstruction
Test cases corrected: 3/3
System status: ✓ FUNCTIONAL
2025-04-15 20:17:32,935 - INFO - Loaded dimensions from file: 768, 460
/tmp/pycharm_project_908/Europearl/SD5.py:2553: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(dvae_path, map_location=torch.device('cpu'))
2025-04-15 20:17:32,980 - INFO - System dimensions: {'input_dim': 768, 'compressed_dim': 460, 'dvae_input_dim': 460, 'dvae_hidden_dim': 920, 'dvae_latent_dim': 460}
2025-04-15 20:17:32,980 - INFO - Updated dimension original_dim: 768 → 768
2025-04-15 20:17:32,980 - INFO - Updated dimension compressed_dim: 460 → 460
2025-04-15 20:17:32,980 - INFO - Updated dimension dvae_latent_dim: 460 → 460
2025-04-15 20:17:32,980 - INFO - Initialized dimension registry: {'original': 768, 'compressed': 460, 'latent': 460}
2025-04-15 20:17:32,996 - INFO - System dimensions: {'input_dim': 768, 'compressed_dim': 460, 'dvae_input_dim': 460, 'dvae_hidden_dim': 920, 'dvae_latent_dim': 460}
2025-04-15 20:17:32,996 - INFO - [PIPELINE] Starting enhanced pipeline with parameters:
2025-04-15 20:17:32,997 - INFO - [PIPELINE] - samples: 50, noise: 0.15/gaussian
2025-04-15 20:17:32,997 - INFO - [PIPELINE] - API: 50%, Compare: True
2025-04-15 20:17:32,997 - INFO - [PIPELINE] - Features: VAE=True, Semantic=True, Adaptive=True
2025-04-15 20:17:32,997 - INFO - [PIPELINE] - System dimensions: input=768, compressed=460
2025-04-15 20:17:32,997 - INFO - [PIPELINE] Knowledge base initialized successfully
2025-04-15 20:17:32,997 - INFO - Precomputing KB enhancements...
2025-04-15 20:17:32,997 - INFO - Precomputed 41 common KB terms
2025-04-15 20:17:32,997 - INFO - Initializing semantic loss with bert-base-uncased model
/home/ubuntu/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
2025-04-15 20:17:33,911 - INFO - Semantic perceptual loss initialized successfully
2025-04-15 20:17:33,911 - INFO - [PIPELINE] Semantic perceptual loss initialized successfully
2025-04-15 20:17:33,930 - INFO - [PIPELINE] Loaded 10000 items from compressed data
2025-04-15 20:17:33,934 - INFO - [PIPELINE] Loaded 10000 original sentences
2025-04-15 20:17:33,934 - INFO - Loading existing VAE compressor from ./data/vae_compressor.pth
/tmp/pycharm_project_908/Europearl/compression_vae.py:727: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(VAE_COMPRESSOR_PATH, map_location=device)
2025-04-15 20:17:34,017 - INFO - VAE compressor loaded: 768 → 460 dimensions
2025-04-15 20:17:34,017 - INFO - Note: Loaded standard model, but requested enhanced
2025-04-15 20:17:34,018 - INFO - Saved VAE dimensions to file: input=768, compressed=460
2025-04-15 20:17:34,018 - INFO - [PIPELINE] VAE compressor loaded successfully: 768 → 460
2025-04-15 20:17:34,018 - INFO - Initialized Enhanced Physical Channel with frequency_selective channel, ofdm-16 modulation, SNR=18.0dB
2025-04-15 20:17:34,018 - INFO - Adaptive modulation enabled: thresholds at 15.0dB and 25.0dB
2025-04-15 20:17:34,018 - INFO - Unequal error protection enabled with 3 protection levels
/tmp/pycharm_project_908/Europearl/content_adaptive_coding.py:406: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(self.content_classifier_path, map_location=device)
2025-04-15 20:17:34,031 - INFO - Using embedding dimension 460 from checkpoint
2025-04-15 20:17:34,040 - INFO - Content classifier loaded with strict parameter matching
2025-04-15 20:17:34,040 - INFO - Content-Adaptive Physical Channel initialized
2025-04-15 20:17:34,040 - INFO - [PIPELINE] Physical channel upgraded to content-adaptive version
2025-04-15 20:17:34,040 - INFO - Using provided input dimension: 460
2025-04-15 20:17:34,040 - INFO - Loading pre-trained enhanced MLPDenoisingVAE from ./models/enhanced_mlp_dvae_model.pth
/tmp/pycharm_project_908/Europearl/semantic_mlpdvae.py:909: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(full_model_path, map_location=device)
2025-04-15 20:17:34,263 - INFO - Loaded model was trained with semantic perceptual loss
2025-04-15 20:17:34,264 - INFO - [PIPELINE] System configurations:
2025-04-15 20:17:34,264 - INFO -   - VAE compression: True
2025-04-15 20:17:34,264 - INFO -   - VAE dimensions: 768 → 460
2025-04-15 20:17:34,264 - INFO -   - DVAE dimensions: input=460, hidden=920, latent=460
2025-04-15 20:17:34,264 - INFO -   - Physical channel enabled: True
2025-04-15 20:17:34,264 - INFO -   - Content adaptive coding: True
2025-04-15 20:17:34,264 - INFO -   - Knowledge base enabled: True
2025-04-15 20:17:34,264 - INFO - [PIPELINE] IMPORTANT: Model dimensions are input=460, hidden=920, latent=460
/tmp/pycharm_project_908/Europearl/SD5.py:922: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(path, map_location=self.model_device)
2025-04-15 20:17:34,556 - INFO - Loaded PPO agent (exploration rate: 0.07)
2025-04-15 20:17:34,556 - INFO - Initializing semantic loss with bert-base-uncased model
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.

2025-04-15 20:17:35,451 - INFO - Semantic perceptual loss initialized successfully
2025-04-15 20:17:35,458 - INFO - [PIPELINE] Semantic channel optimizer initialized
2025-04-15 20:17:35,458 - INFO - [PIPELINE] Using enhanced RL agent for API optimization (exploration rate: 0.07)
2025-04-15 20:17:35,458 - INFO - === Starting Enhanced Semantic Reconstruction Pipeline ===
2025-04-15 20:17:35,458 - INFO - [PIPELINE] Noise level: 0.15, Noise type: gaussian
2025-04-15 20:17:35,458 - INFO - [PIPELINE] OpenAI API available: True
2025-04-15 20:17:35,458 - INFO - [PIPELINE] Physical channel enabled: True
Processing samples:   0%|                                | 0/50 [00:00<?, ?it/s]/tmp/pycharm_project_908/Europearl/physical_semantic_integration.py:539: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1808.)
  variance = torch.var(tensor, dim=0)
2025-04-15 20:17:35,571 - INFO - Using device: cuda
2025-04-15 20:17:36,129 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:36,135 - INFO - ✅ OpenAI API connection successful
/tmp/pycharm_project_908/Europearl/compression_vae.py:676: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(VAE_COMPRESSOR_PATH, map_location=device)
2025-04-15 20:17:36,335 - INFO - [API] Starting reconstruction of text: 'Although , as dou will havo se...'
2025-04-15 20:17:36,335 - INFO - [API] CRITICAL ERROR PATTERN 'havo' detected, forcing API usage
2025-04-15 20:17:36,335 - INFO - [API] Selected GPT-4 Turbo for critical case with sufficient budget
2025-04-15 20:17:36,335 - INFO - [API] Selected GPT-4 Turbo for critical case
2025-04-15 20:17:36,335 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-15 20:17:38,316 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:38,325 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:38,328 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-15 20:17:38,328 - INFO - [API] Completed in 1.993s using api_gpt-4-turbo
2025-04-15 20:17:38,330 - INFO - Using default tokenizer.
2025-04-15 20:17:39,791 - INFO - Using default tokenizer.
2025-04-15 20:17:39,805 - INFO - [API] Starting reconstruction of text: 'Although , as you will have se...'
2025-04-15 20:17:39,812 - INFO - [API] KB made changes but quality score 0.07 below threshold 0.65
2025-04-15 20:17:39,819 - INFO - KB reconstruction rejected due to 2 questionable changes
2025-04-15 20:17:39,820 - INFO - [API] Selected GPT-4 Turbo (sufficient budget)
2025-04-15 20:17:39,878 - INFO - [API] RL agent selected GPT-3.5 Turbo
2025-04-15 20:17:39,878 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-15 20:17:40,666 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:40,675 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:40,679 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-15 20:17:40,679 - INFO - [API] Completed in 0.875s using api_gpt-3.5-turbo
2025-04-15 20:17:40,680 - INFO - Using default tokenizer.
2025-04-15 20:17:40,704 - INFO - [PIPELINE] Sample 1/50 (processed in 5.25s)
2025-04-15 20:17:40,704 - INFO - [PIPELINE] Original: Although , as you will have seen , the dreaded ' millennium bug ' failed to materialise , still the people in a number of countries suffered a series of natural disasters that truly were dreadful .
2025-04-15 20:17:40,704 - INFO - [PIPELINE] Semantic noisy: Although , as dou will havo seen , the dreaded ' millennium bug ' failed to materialise , still the people in a number of countries suffered a series of natural qisasrers tzbt orull were dreadful .
2025-04-15 20:17:40,704 - INFO - [PIPELINE] Semantic reconstructed: Although, as you will have seen, the dreaded the bug' failed to materialize, still the to in a number of countries in a series of natural disasters that truly of dreadful.
2025-04-15 20:17:40,704 - INFO - [PIPELINE] Direct noisy: Although , as you will have seen , ohe dreaded ' millennium bug ' failed to materialise , still the people in a number of hountries suffered a series of natural disasters that truly were dreadful .
2025-04-15 20:17:40,704 - INFO - [PIPELINE] Direct reconstructed: Although, as you will have seen the dreaded 'millennium bug' failed to the still the to in a number of countries in a series of natural disasters that truly of dreadful.
2025-04-15 20:17:40,704 - INFO - [PIPELINE] Semantic BLEU: 0.3502, ROUGE-L: 0.8387, SEMANTIC: 0.8763
2025-04-15 20:17:40,704 - INFO - [PIPELINE] Direct BLEU: 0.3807, ROUGE-L: 0.8710, SEMANTIC: 0.8664
2025-04-15 20:17:40,704 - INFO - [PIPELINE] Current cost: $0.0279 of $2.00
2025-04-15 20:17:40,704 - INFO - [PIPELINE] Progress: 1/50 samples. Est. remaining: 380.7s (6.3m)
2025-04-15 20:17:40,704 - INFO - ---
Processing samples:   2%|▍                       | 1/50 [00:05<04:17,  5.25s/it]/tmp/pycharm_project_908/Europearl/physical_semantic_integration.py:539: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1808.)
  variance = torch.var(tensor, dim=0)
2025-04-15 20:17:40,774 - INFO - [API] Starting reconstruction of text: 'You have requested a debate on...'
2025-04-15 20:17:40,778 - INFO - [API] KB made changes but quality score 0.25 below threshold 0.65
2025-04-15 20:17:40,782 - INFO - KB reconstruction rejected due to 1 questionable changes
2025-04-15 20:17:40,782 - INFO - Basic reconstruction made changes: 'You have requested a debate on this subject in the gourse of xhh next few days , during this part-session .' -> 'You have requested a debate on this subjeat in the gourse of xhh next few days , during this part-session .'
2025-04-15 20:17:40,782 - INFO - [API] Using high-quality basic reconstruction
2025-04-15 20:17:40,782 - INFO - [API] Completed in 0.008s using basic reconstruction
2025-04-15 20:17:40,783 - INFO - Using default tokenizer.
2025-04-15 20:17:40,796 - INFO - Using default tokenizer.
2025-04-15 20:17:40,808 - INFO - [API] Starting reconstruction of text: 'qdu have requested a debate on...'
2025-04-15 20:17:40,812 - INFO - [API] KB made changes but quality score 0.25 below threshold 0.65
2025-04-15 20:17:40,815 - INFO - KB reconstruction rejected due to 1 questionable changes
2025-04-15 20:17:40,816 - INFO - Basic reconstruction made changes: 'qdu have requested a debate on thgq subject in the course of the nwxt few days , dsrxng this part-session .' -> 'qdu have requested a debate on thgq subjeat in the course of the nwxt few days , dsrxng this part-session .'
2025-04-15 20:17:40,816 - INFO - [API] Using high-quality basic reconstruction
2025-04-15 20:17:40,816 - INFO - [API] Completed in 0.007s using basic reconstruction
2025-04-15 20:17:40,816 - INFO - Using default tokenizer.
2025-04-15 20:17:40,844 - INFO - [PIPELINE] Sample 2/50 (processed in 0.14s)
2025-04-15 20:17:40,844 - INFO - [PIPELINE] Original: You have requested a debate on this subject in the course of the next few days , during this part-session .
2025-04-15 20:17:40,844 - INFO - [PIPELINE] Semantic noisy: You have requested a debate on this subject in the gourse of xhh next few days , during this part-session .
2025-04-15 20:17:40,844 - INFO - [PIPELINE] Semantic reconstructed: You have requested a debate on this subjeat in the gourse of xhh next few days , during this part-session .
2025-04-15 20:17:40,844 - INFO - [PIPELINE] Direct noisy: qdu have requested a debate on thgq subject in the course of the nwxt few days , dsrxng this part-session .
2025-04-15 20:17:40,844 - INFO - [PIPELINE] Direct reconstructed: qdu have requested a debate on thgq subjeat in the course of the nwxt few days , dsrxng this part-session .
2025-04-15 20:17:40,844 - INFO - [PIPELINE] Semantic BLEU: 0.6456, ROUGE-L: 0.8500, SEMANTIC: 0.8933
2025-04-15 20:17:40,844 - INFO - [PIPELINE] Direct BLEU: 0.4548, ROUGE-L: 0.7500, SEMANTIC: 0.7590
2025-04-15 20:17:40,844 - INFO - [PIPELINE] Current cost: $0.0279 of $2.00
2025-04-15 20:17:40,844 - INFO - [PIPELINE] Progress: 2/50 samples. Est. remaining: 189.8s (3.2m)
2025-04-15 20:17:40,844 - INFO - ---
Processing samples:   4%|▉                       | 2/50 [00:05<01:47,  2.24s/it]2025-04-15 20:17:40,924 - INFO - [API] Starting reconstruction of text: 'Pyeale rise , then , fop this ...'
2025-04-15 20:17:40,926 - INFO - [API] KB made changes but quality score 0.17 below threshold 0.65
2025-04-15 20:17:40,927 - INFO - KB reconstruction rejected due to 1 questionable changes
2025-04-15 20:17:40,928 - INFO - [API] Selected GPT-4 Turbo (sufficient budget)
2025-04-15 20:17:40,929 - INFO - [API] RL agent selected GPT-3.5 Turbo
2025-04-15 20:17:40,929 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-15 20:17:41,615 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:41,630 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:41,631 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-15 20:17:41,631 - INFO - [API] Completed in 0.707s using api_gpt-3.5-turbo
2025-04-15 20:17:41,631 - INFO - Using default tokenizer.
2025-04-15 20:17:41,658 - INFO - Using default tokenizer.
2025-04-15 20:17:41,672 - INFO - [API] Starting reconstruction of text: 'Please zioe , tdln , for this ...'
2025-04-15 20:17:41,673 - INFO - [API] KB made changes but quality score 0.33 below threshold 0.65
2025-04-15 20:17:41,675 - INFO - KB reconstruction rejected due to 1 questionable changes
2025-04-15 20:17:41,676 - INFO - [API] Selected GPT-4 Turbo (sufficient budget)
2025-04-15 20:17:41,677 - INFO - [API] RL agent selected GPT-3.5 Turbo
2025-04-15 20:17:41,678 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-15 20:17:42,286 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:42,290 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:42,291 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-15 20:17:42,291 - INFO - [API] Completed in 0.619s using api_gpt-3.5-turbo
2025-04-15 20:17:42,291 - INFO - Using default tokenizer.
Processing samples:   6%|█▍                      | 3/50 [00:06<01:28,  1.89s/it]2025-04-15 20:17:42,381 - INFO - [API] Starting reconstruction of text: '( The House rose and oxservej ...'
2025-04-15 20:17:42,381 - INFO - [API] Important parliamentary term 'President' present, increasing quality threshold
2025-04-15 20:17:42,384 - INFO - [API] KB made changes but quality score 0.07 below threshold 0.75
2025-04-15 20:17:42,388 - INFO - KB reconstruction rejected due to 2 questionable changes
2025-04-15 20:17:42,388 - INFO - [API] Selected GPT-4 Turbo for critical case
2025-04-15 20:17:42,388 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-15 20:17:43,681 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:43,690 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:43,691 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-15 20:17:43,691 - INFO - [API] Completed in 1.310s using api_gpt-4-turbo
2025-04-15 20:17:43,692 - INFO - Using default tokenizer.
2025-04-15 20:17:43,720 - INFO - Using default tokenizer.
2025-04-15 20:17:43,734 - INFO - [API] Starting reconstruction of text: '( The vouke rose and observed ...'
2025-04-15 20:17:43,738 - INFO - [API] KB made changes but quality score 0.07 below threshold 0.65
2025-04-15 20:17:43,741 - INFO - KB reconstruction rejected due to 2 questionable changes
2025-04-15 20:17:43,742 - INFO - [API] Selected GPT-4 Turbo (sufficient budget)
2025-04-15 20:17:43,744 - INFO - [API] RL agent selected GPT-3.5 Turbo
2025-04-15 20:17:43,744 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-15 20:17:44,564 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:44,567 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:44,569 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-15 20:17:44,569 - INFO - [API] Completed in 0.835s using api_gpt-3.5-turbo
2025-04-15 20:17:44,569 - INFO - Using default tokenizer.
Processing samples:   8%|█▉                      | 4/50 [00:09<01:33,  2.04s/it]2025-04-15 20:17:44,688 - INFO - [API] Starting reconstruction of text: 'Yox dijl be aware from the prw...'
2025-04-15 20:17:44,693 - INFO - [API] KB made changes but quality score 0.00 below threshold 0.65
2025-04-15 20:17:44,697 - INFO - KB reconstruction made changes: 'Yox dijl be aware from the prwrs and television that there have bynn a number of bomb explosions and kivlibgs in Srh Lanka .' -> 'Yox dijl be aware from the prwrs and television that there have bynn a number of bomb explosions and kivlibgs in Srh Lanka.'
2025-04-15 20:17:44,697 - INFO - [API] Basic made changes but quality score 0.00 below threshold 0.65
2025-04-15 20:17:44,697 - INFO - [API] Selected GPT-4 Turbo (sufficient budget)
2025-04-15 20:17:44,699 - INFO - [API] RL agent selected GPT-3.5 Turbo
2025-04-15 20:17:44,699 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-15 20:17:45,427 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:45,438 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:45,440 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-15 20:17:45,440 - INFO - [API] Completed in 0.752s using api_gpt-3.5-turbo
2025-04-15 20:17:45,440 - INFO - Using default tokenizer.
2025-04-15 20:17:45,475 - INFO - Using default tokenizer.
2025-04-15 20:17:45,492 - INFO - [API] Starting reconstruction of text: 'You wdll be aware from the pre...'
2025-04-15 20:17:45,497 - INFO - [API] KB made changes but quality score 0.00 below threshold 0.65
2025-04-15 20:17:45,502 - INFO - KB reconstruction made changes: 'You wdll be aware from the press and television that there have been a number of bomb expaosionz and killings in Sri Lanka .' -> 'You wdll be aware from the press and television that there have been a number of bomb expaosionz and killings in Sri Lanka.'
2025-04-15 20:17:45,502 - INFO - [API] Basic made changes but quality score 0.00 below threshold 0.65
2025-04-15 20:17:45,502 - INFO - [API] Selected GPT-4 Turbo (sufficient budget)
2025-04-15 20:17:45,504 - INFO - [API] RL agent selected GPT-3.5 Turbo
2025-04-15 20:17:45,504 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-15 20:17:46,223 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:46,227 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:46,228 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-15 20:17:46,228 - INFO - [API] Completed in 0.736s using api_gpt-3.5-turbo
2025-04-15 20:17:46,229 - INFO - Using default tokenizer.
Processing samples:  10%|██▍                     | 5/50 [00:10<01:25,  1.91s/it]2025-04-15 20:17:46,335 - INFO - [API] Starting reconstruction of text: 'One of the people assassinated...'
2025-04-15 20:17:46,336 - INFO - [API] Important parliamentary term 'Parliament' present, increasing quality threshold
2025-04-15 20:17:46,342 - INFO - [API] KB made changes but quality score 0.08 below threshold 0.75
2025-04-15 20:17:46,348 - INFO - KB reconstruction rejected due to 1 questionable changes
2025-04-15 20:17:46,349 - INFO - Basic reconstruction made changes: 'One of the people assassinated very recently in Sri Lqnta was Mr Kumar Ponnambalam , who had visited the European Parliament just a few months ago .' -> 'One of the people assassinated very recently in Sri Lqnta was Mr Kumare Ponnambalam , who had visited the European Pareliament just a few months ago .'
2025-04-15 20:17:46,349 - INFO - [API] Basic made changes but quality score 0.00 below threshold 0.75
2025-04-15 20:17:46,349 - INFO - [API] Selected GPT-4 Turbo for critical case
2025-04-15 20:17:46,349 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-15 20:17:47,733 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:47,740 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:47,743 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-15 20:17:47,743 - INFO - [API] Completed in 1.407s using api_gpt-4-turbo
2025-04-15 20:17:47,743 - INFO - Using default tokenizer.
2025-04-15 20:17:47,770 - INFO - Using default tokenizer.
2025-04-15 20:17:47,784 - INFO - [API] Starting reconstruction of text: 'One of the people assassinated...'
2025-04-15 20:17:47,784 - INFO - [API] Important parliamentary term 'Parliament' present, increasing quality threshold
2025-04-15 20:17:47,791 - INFO - [API] KB made changes but quality score 0.08 below threshold 0.75
2025-04-15 20:17:47,797 - INFO - KB reconstruction rejected due to 1 questionable changes
2025-04-15 20:17:47,798 - INFO - Basic reconstruction made changes: 'One of the people assassinated very recently in Sri Lanka was Mr Kumar Ponnambalam , who had visited the European Parliament just a few months ago .' -> 'One of the people assassinated very recently in Sri Lanka was Mr Kumare Ponnambalam , who had visited the European Pareliament just a few months ago .'
2025-04-15 20:17:47,798 - INFO - [API] Basic made changes but quality score 0.00 below threshold 0.75
2025-04-15 20:17:47,798 - INFO - [API] Selected GPT-4 Turbo for critical case
2025-04-15 20:17:47,798 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-15 20:17:49,228 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:49,247 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:17:49,250 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-15 20:17:49,250 - INFO - [API] Completed in 1.465s using api_gpt-4-turbo
2025-04-15 20:17:49,251 - INFO - Using default tokenizer.

2025-04-15 20:19:10,235 - INFO - Using default tokenizer.
Processing samples:  98%|██████████████████████▌| 49/50 [01:34<00:03,  3.06s/it]2025-04-15 20:19:10,348 - INFO - [API] Starting reconstruction of text: 'So Parliament should znnd a me...'
2025-04-15 20:19:10,348 - INFO - [API] Important parliamentary term 'Parliament' present, increasing quality threshold
2025-04-15 20:19:10,351 - INFO - [API] KB made changes but quality score 0.30 below threshold 0.75
2025-04-15 20:19:10,353 - INFO - KB reconstruction rejected due to 4 questionable changes
2025-04-15 20:19:10,354 - INFO - Basic reconstruction made changes: 'So Parliament should znnd a message , since that is the wish of the vast majority .' -> 'So Pareliament should znnd a message , since that is the wish of the vast majority .'
2025-04-15 20:19:10,354 - INFO - [API] Basic made changes but quality score 0.00 below threshold 0.75
2025-04-15 20:19:10,354 - INFO - [API] Selected GPT-4 Turbo for critical case
2025-04-15 20:19:10,354 - INFO - [API] Making API call with model gpt-4-turbo...
2025-04-15 20:19:11,379 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:19:11,383 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-15 20:19:11,385 - INFO - [API] API reconstruction successful using model gpt-4-turbo
2025-04-15 20:19:11,385 - INFO - [API] Completed in 1.037s using api_gpt-4-turbo
2025-04-15 20:19:11,385 - INFO - Using default tokenizer.
2025-04-15 20:19:11,415 - INFO - Using default tokenizer.
2025-04-15 20:19:11,430 - INFO - [API] Starting reconstruction of text: 'So Parjiamunt should send a me...'
2025-04-15 20:19:11,432 - INFO - [API] KB made changes but quality score 0.30 below threshold 0.65
2025-04-15 20:19:11,434 - INFO - KB reconstruction rejected due to 4 questionable changes
2025-04-15 20:19:11,435 - INFO - Basic reconstruction made changes: 'So Parjiamunt should send a message , sinoo that is the wish of the vast majjrity .' -> 'So Parliament should send a message , sinoo that is the wish of the vast majjrity .'
2025-04-15 20:19:11,435 - INFO - [API] Using high-quality basic reconstruction
2025-04-15 20:19:11,435 - INFO - [API] Completed in 0.005s using basic reconstruction
2025-04-15 20:19:11,435 - INFO - Using default tokenizer.
2025-04-15 20:19:11,447 - INFO - [PIPELINE] Sample 50/50 (processed in 1.19s)
2025-04-15 20:19:11,448 - INFO - [PIPELINE] Original: So Parliament should send a message , since that is the wish of the vast majority .
2025-04-15 20:19:11,448 - INFO - [PIPELINE] Semantic noisy: So Parliament should znnd a message , since that is the wish of the vast majority .
2025-04-15 20:19:11,448 - INFO - [PIPELINE] Semantic reconstructed: So Parliament should send a message, since that is the wish of the vast majority.
2025-04-15 20:19:11,448 - INFO - [PIPELINE] Direct noisy: So Parjiamunt should send a message , sinoo that is the wish of the vast majjrity .
2025-04-15 20:19:11,448 - INFO - [PIPELINE] Direct reconstructed: So Parliament should send a message , sinoo that is the wish of the vast majjrity .
2025-04-15 20:19:11,448 - INFO - [PIPELINE] Semantic BLEU: 0.6338, ROUGE-L: 1.0000, SEMANTIC: 1.0000
2025-04-15 20:19:11,448 - INFO - [PIPELINE] Direct BLEU: 0.7086, ROUGE-L: 0.8667, SEMANTIC: 0.8264
2025-04-15 20:19:11,448 - INFO - [PIPELINE] Current cost: $0.3271 of $2.00
2025-04-15 20:19:11,448 - INFO - [PIPELINE] Progress: 50/50 samples. Est. remaining: 0.0s (0.0m)
2025-04-15 20:19:11,448 - INFO - ---
Processing samples: 100%|███████████████████████| 50/50 [01:35<00:00,  1.92s/it]
2025-04-15 20:19:11,459 - INFO - Saved PPO agent state
2025-04-15 20:19:11,459 - INFO - [PIPELINE] Saved enhanced RL agent state
2025-04-15 20:19:11,460 - INFO - Using default tokenizer.
2025-04-15 20:19:11,460 - INFO - Initialized knowledge base for evaluation
2025-04-15 20:19:12,110 - INFO - 
=== Enhanced Evaluation Results ===
2025-04-15 20:19:12,110 - INFO - Overall Score: 0.8322
2025-04-15 20:19:12,110 - INFO - Semantic Fidelity: 0.8765
2025-04-15 20:19:12,110 - INFO - Linguistic Quality: 0.7162
2025-04-15 20:19:12,110 - INFO - Domain Relevance: 0.9294
2025-04-15 20:19:12,110 - INFO - Information Preservation: 0.8085
2025-04-15 20:19:12,237 - INFO - Total API cost: $0.3271 of $2.00 budget
2025-04-15 20:19:12,237 - INFO - 
=== Overall Results ===
2025-04-15 20:19:12,237 - INFO - [PIPELINE] Total time: 98.52s, Avg: 1.97s per sample
2025-04-15 20:19:12,237 - INFO - [PIPELINE] System dimensions: input=768, compressed=460
2025-04-15 20:19:12,237 - INFO - [PIPELINE] Semantic Reconstruction:
2025-04-15 20:19:12,237 - INFO - [PIPELINE] Semantic Average BLEU: 0.5336
2025-04-15 20:19:12,237 - INFO - [PIPELINE] Semantic Average ROUGE1: 0.9108
2025-04-15 20:19:12,237 - INFO - [PIPELINE] Semantic Average ROUGEL: 0.9078
2025-04-15 20:19:12,237 - INFO - [PIPELINE] Semantic Average METEOR: 0.7094
2025-04-15 20:19:12,237 - INFO - [PIPELINE] Semantic Average SEMANTIC: 0.9337
2025-04-15 20:19:12,237 - INFO - 
[PIPELINE] Direct Reconstruction:
2025-04-15 20:19:12,237 - INFO - [PIPELINE] Direct Average BLEU: 0.5634
2025-04-15 20:19:12,237 - INFO - [PIPELINE] Direct Average ROUGE1: 0.9158
2025-04-15 20:19:12,237 - INFO - [PIPELINE] Direct Average ROUGEL: 0.9127
2025-04-15 20:19:12,237 - INFO - [PIPELINE] Direct Average METEOR: 0.7270
2025-04-15 20:19:12,237 - INFO - [PIPELINE] Direct Average SEMANTIC: 0.9340
2025-04-15 20:19:12,237 - INFO - 
[PIPELINE] Total Cost: $0.3271 of $2.00 budget
2025-04-15 20:19:12,237 - INFO - [PIPELINE] Results saved to C:\Users\Daud\SemanticCommTransmission\pythonProject/sem_com_results/enhanced_run_20250415-201732
2025-04-15 20:19:12,237 - INFO - 
[PIPELINE] RL Agent Performance:
2025-04-15 20:19:12,237 - INFO - Total episodes: 636
2025-04-15 20:19:12,237 - INFO - Total reward: 1705.47
2025-04-15 20:19:12,237 - INFO - Final exploration rate: 0.07
2025-04-15 20:19:12,237 - INFO - API efficiency: 1414.4553332542714
2025-04-15 20:19:12,237 - INFO - [PIPELINE] Visualizations saved to C:\Users\Daud\SemanticCommTransmission\pythonProject/sem_com_results/enhanced_run_20250415-201732

===== KNOWLEDGE BASE FUNCTIONALITY CHECK =====
✓ KB initialized successfully with 41 terms

Test 1:
  Input:      The Parliamemt will now vote on the propofal from the Commissiob.
  Corrected:  The Parliament will now vote on the proposal from the Commission
  Corrections: 3/3 expected terms
  Result:     ✓ KB applied corrections

Test 2:
  Input:      In accordancg with Rule 143, I wkulz like your acvioe.
  Corrected:  In accordance with Rule 143, I would like your advice
  Corrections: 3/3 expected terms
  Result:     ✓ KB applied corrections

Test 3:
  Input:      The Coupcil and Directave on environmentsl protrction.
  Corrected:  The Council and Directive on environmental protection
  Corrections: 4/4 expected terms
  Result:     ✓ KB applied corrections

===== SUMMARY =====
Tests passed: 3/3
Total corrections made: 10
KB Status: FUNCTIONING

====== Enhanced Semantic Communication Pipeline Complete ======
Overall improvements:
- Advanced Compression: Implemented VAE-based non-linear compression
- Content-Adaptive Coding: Implemented content-aware protection strategies
- Semantic Perceptual Loss: Added semantic similarity metrics and training
- Enhanced RL Agent: Improved state representation with semantic features

Final metrics:
  semantic_avg_BLEU: 0.5336
  semantic_avg_METEOR: 0.7094
  semantic_avg_ROUGE1: 0.9108
  semantic_avg_ROUGEL: 0.9078
  semantic_avg_SEMANTIC: 0.9337

Process finished with exit code 0
