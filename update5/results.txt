/home/ubuntu/anaconda3/bin/conda run -n myenv --no-capture-output python /tmp/pycharm_project_908/Europearl/SD5.py 
2025-04-06 12:28:52,153 - INFO - Using device: cuda
/home/ubuntu/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
2025-04-06 12:28:53,947 - INFO - Initialized Enhanced Physical Channel with awgn channel, qam-16 modulation, SNR=20.0dB
2025-04-06 12:28:53,947 - INFO - Adaptive modulation enabled: thresholds at 15.0dB and 25.0dB
2025-04-06 12:28:53,947 - INFO - Unequal error protection enabled with 3 protection levels
/tmp/pycharm_project_908/Europearl/content_adaptive_coding.py:369: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(self.content_classifier_path, map_location=device)
2025-04-06 12:28:53,954 - WARNING - Error loading classifier weights: Expected state_dict to be dict-like, got <class 'NoneType'>.
2025-04-06 12:28:53,954 - INFO - Content-Adaptive Physical Channel initialized
2025-04-06 12:28:53,954 - INFO - Enhanced content-adaptive physical channel initialized
2025-04-06 12:28:53,954 - INFO - Will collect up to 10000 transmission pairs
2025-04-06 12:28:53,955 - INFO - Using device: cuda
2025-04-06 12:28:54,968 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:28:54,974 - INFO - ✅ OpenAI API connection successful

===== SYSTEM COMPONENT TEST =====
2025-04-06 12:28:54,975 - INFO - Loaded knowledge base from ./models/europarl_knowledge_base.pkl with 41 terms
2025-04-06 12:28:54,975 - INFO - Loaded knowledge base from ./models/europarl_knowledge_base.pkl with 41 terms (load #1)
Knowledge Base loaded with 41 terms

Test Case 1: Mrs Lynne, you are quite right and I shall check whether this ocs actually not been done.
1. KB Reconstruction (1 changes):
   Mrs Lynne, you are quite right and I shall check whether this has actually not been done.
2025-04-06 12:28:54,993 - INFO - KB reconstruction made changes: 'Mrs Lynne, you are quite right and I shall check whether this ocs actually not been done.' -> 'Mrs Lynne, you are quite right and I shall check whether this has actually not been done.'
2. Basic Reconstruction (1 changes):
   Mrs Lynne, you are quite right and I shall check whether this has actually not been done.
2025-04-06 12:28:54,993 - INFO - [API] Starting reconstruction of text: 'Mrs Lynne, you are quite right...'
2025-04-06 12:28:54,999 - INFO - [API] Using KB reconstruction with confidence 0.92
2025-04-06 12:28:54,999 - INFO - [API] Completed in 0.006s using method: kb
3. API Reconstruction (1 changes):
   Mrs Lynne, you are quite right and I shall check whether this has actually not been done.

Test Case 2: The Parliamemt will now vote on the propofal from the Commissiob.
1. KB Reconstruction (3 changes):
   The Parliament will now vote on the proposal from the Commission
2025-04-06 12:28:55,005 - INFO - KB reconstruction made changes: 'The Parliamemt will now vote on the propofal from the Commissiob.' -> 'The Parliament will now vote on the proposal from the Commission'
2. Basic Reconstruction (3 changes):
   The Parliament will now vote on the proposal from the Commission
2025-04-06 12:28:55,005 - INFO - [API] Starting reconstruction of text: 'The Parliamemt will now vote o...'
2025-04-06 12:28:55,008 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:28:55,549 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:28:55,552 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:28:55,553 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:28:55,553 - INFO - [API] Completed in 0.547s using api_gpt-3.5-turbo
3. API Reconstruction (3 changes):
   The Parliament will now vote on the proposal from the Commission.

Test Case 3: In accordancg with Rule 143, I wkulz like your acvioe about this moetinp.
1. KB Reconstruction (4 changes):
   In accordance with Rule 143, I would like your advice about this meeting
2025-04-06 12:28:55,564 - INFO - KB reconstruction made changes: 'In accordancg with Rule 143, I wkulz like your acvioe about this moetinp.' -> 'In accordance with Rule 143, I would like your advice about this meeting'
2. Basic Reconstruction (4 changes):
   In accordance with Rule 143, I would like your advice about this meeting
2025-04-06 12:28:55,565 - INFO - [API] Starting reconstruction of text: 'In accordancg with Rule 143, I...'
2025-04-06 12:28:55,570 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:28:56,151 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:28:56,154 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:28:56,155 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:28:56,155 - INFO - [API] Completed in 0.590s using api_gpt-3.5-turbo
3. API Reconstruction (4 changes):
   In accordance with Rule 143, I would like your advice about this meeting.

===== RESULTS =====
Components tested: KB Reconstruction, Basic Reconstruction, API Reconstruction
Test cases corrected: 3/3
System status: ✓ FUNCTIONAL
/tmp/pycharm_project_908/Europearl/SD5.py:1269: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(dvae_path, map_location=torch.device('cpu'))
2025-04-06 12:28:56,200 - INFO - System dimensions: {'input_dim': 768, 'compressed_dim': 460, 'dvae_input_dim': 460, 'dvae_hidden_dim': 920, 'dvae_latent_dim': 460}
2025-04-06 12:28:56,201 - INFO - [PIPELINE] Starting enhanced pipeline with parameters:
2025-04-06 12:28:56,201 - INFO - [PIPELINE] - samples: 50, noise: 0.15/gaussian
2025-04-06 12:28:56,201 - INFO - [PIPELINE] - API: 50%, Compare: True
2025-04-06 12:28:56,201 - INFO - [PIPELINE] - Features: VAE=True, Semantic=True, Adaptive=True
2025-04-06 12:28:56,201 - INFO - [PIPELINE] - System dimensions: input=768, compressed=460
2025-04-06 12:28:56,201 - INFO - [PIPELINE] Knowledge base initialized successfully
2025-04-06 12:28:56,201 - INFO - Initializing semantic loss with bert-base-uncased model
/home/ubuntu/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
2025-04-06 12:28:57,095 - INFO - Semantic perceptual loss initialized successfully
2025-04-06 12:28:57,095 - INFO - [PIPELINE] Semantic perceptual loss initialized successfully
2025-04-06 12:28:57,113 - INFO - [PIPELINE] Loaded 10000 items from compressed data
2025-04-06 12:28:57,117 - INFO - [PIPELINE] Loaded 10000 original sentences
2025-04-06 12:28:57,117 - INFO - Loading existing VAE compressor from ./data/vae_compressor.pth
/tmp/pycharm_project_908/Europearl/compression_vae.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(VAE_COMPRESSOR_PATH, map_location=device)
2025-04-06 12:28:57,159 - INFO - VAE compressor loaded: 768 → 460 dimensions
2025-04-06 12:28:57,159 - INFO - Note: Loaded standard model, but requested enhanced
2025-04-06 12:28:57,166 - INFO - Saved VAE dimensions to file: input=768, compressed=460
2025-04-06 12:28:57,166 - INFO - [PIPELINE] VAE compressor loaded successfully: 768 → 460
2025-04-06 12:28:57,167 - INFO - Initialized Enhanced Physical Channel with awgn channel, qam-16 modulation, SNR=20.0dB
2025-04-06 12:28:57,167 - INFO - Adaptive modulation enabled: thresholds at 15.0dB and 25.0dB
2025-04-06 12:28:57,167 - INFO - Unequal error protection enabled with 3 protection levels
/tmp/pycharm_project_908/Europearl/content_adaptive_coding.py:369: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(self.content_classifier_path, map_location=device)
2025-04-06 12:28:57,172 - WARNING - Error loading classifier weights: Expected state_dict to be dict-like, got <class 'NoneType'>.
2025-04-06 12:28:57,172 - INFO - Content-Adaptive Physical Channel initialized
2025-04-06 12:28:57,173 - INFO - [PIPELINE] Physical channel upgraded to content-adaptive version
2025-04-06 12:28:57,173 - INFO - Using provided input dimension: 460
2025-04-06 12:28:57,173 - INFO - Loading pre-trained enhanced MLPDenoisingVAE from ./models/enhanced_mlp_dvae_model.pth
/tmp/pycharm_project_908/Europearl/semantic_mlpdvae.py:702: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(full_model_path, map_location=device)
2025-04-06 12:28:57,264 - INFO - Loaded model was trained with semantic perceptual loss
2025-04-06 12:28:57,265 - INFO - [PIPELINE] System configurations:
2025-04-06 12:28:57,265 - INFO -   - VAE compression: True
2025-04-06 12:28:57,265 - INFO -   - VAE dimensions: 768 → 460
2025-04-06 12:28:57,265 - INFO -   - DVAE dimensions: input=460, hidden=920, latent=460
2025-04-06 12:28:57,265 - INFO -   - Physical channel enabled: True
2025-04-06 12:28:57,265 - INFO -   - Content adaptive coding: True
2025-04-06 12:28:57,265 - INFO -   - Knowledge base enabled: True
2025-04-06 12:28:57,265 - INFO - [PIPELINE] IMPORTANT: Model dimensions are input=460, hidden=920, latent=460
/tmp/pycharm_project_908/Europearl/SD5.py:438: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(path, map_location=torch.device('cpu'))
2025-04-06 12:28:57,467 - INFO - Loaded advanced RL agent (exploration rate: 0.10)
2025-04-06 12:28:57,467 - INFO - Initializing semantic loss with bert-base-uncased model
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.
A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.
2025-04-06 12:28:58,363 - INFO - Semantic perceptual loss initialized successfully
2025-04-06 12:28:58,365 - INFO - [PIPELINE] Semantic channel optimizer initialized
2025-04-06 12:28:58,365 - INFO - [PIPELINE] Using enhanced RL agent for API optimization (exploration rate: 0.10)
2025-04-06 12:28:58,365 - INFO - === Starting Enhanced Semantic Reconstruction Pipeline ===
2025-04-06 12:28:58,365 - INFO - [PIPELINE] Noise level: 0.15, Noise type: gaussian
2025-04-06 12:28:58,365 - INFO - [PIPELINE] OpenAI API available: True
2025-04-06 12:28:58,365 - INFO - [PIPELINE] Physical channel enabled: True
Processing samples:   0%|                                | 0/50 [00:00<?, ?it/s]/tmp/pycharm_project_908/Europearl/physical_semantic_integration.py:590: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1808.)
  variance = torch.var(tensor, dim=0)
/tmp/pycharm_project_908/Europearl/compression_vae.py:532: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(VAE_COMPRESSOR_PATH, map_location=device)
2025-04-06 12:28:58,546 - INFO - [API] Starting reconstruction of text: 'Although , as you will have se...'
2025-04-06 12:28:58,554 - INFO - [API] Using KB reconstruction with confidence 0.97
2025-04-06 12:28:58,554 - INFO - [API] Completed in 0.008s using method: kb
2025-04-06 12:28:58,555 - INFO - Using default tokenizer.
2025-04-06 12:28:59,941 - INFO - [API] Starting reconstruction of text: 'Although , as you will have se...'
2025-04-06 12:28:59,949 - INFO - [API] Using KB reconstruction with confidence 0.97
2025-04-06 12:28:59,949 - INFO - [API] Completed in 0.008s using method: kb
2025-04-06 12:28:59,950 - INFO - Using default tokenizer.
2025-04-06 12:28:59,963 - INFO - [PIPELINE] Sample 1/50 (processed in 1.60s)
2025-04-06 12:28:59,963 - INFO - [PIPELINE] Original: Although , as you will have seen , the dreaded ' millennium bug ' failed to materialise , still the people in a number of countries suffered a series of natural disasters that truly were dreadful .
2025-04-06 12:28:59,963 - INFO - [PIPELINE] Semantic noisy: Although , as you will have seen , the dreaded ' millennium bug ' failed to materialise , still the people in a number of countries suffered a srrieh of natural disasters that truly were dreadful .
2025-04-06 12:28:59,963 - INFO - [PIPELINE] Semantic reconstructed: Although , as you will have seen , the dreaded ' millennium bug ' failed to materialise , still the people in a number of countries suffered a srrieh of natural disasters the truly were dreadful .
2025-04-06 12:28:59,963 - INFO - [PIPELINE] Direct noisy: Although , as you will have seen , the dreaded ' millennium bug ' failed to materialise , still the people in a number of countries suffered a series of natural disasters that truly were dreadful .
2025-04-06 12:28:59,963 - INFO - [PIPELINE] Direct reconstructed: Although , as you will have seen , the dreaded ' millennium bug ' failed to materialise , still the people in a number of countries suffered a series of natural disasters the truly were dreadful .
2025-04-06 12:28:59,963 - INFO - [PIPELINE] Semantic BLEU: 0.8543, ROUGE-L: 0.9355, SEMANTIC: 0.9600
2025-04-06 12:28:59,963 - INFO - [PIPELINE] Direct BLEU: 0.9279, ROUGE-L: 0.9677, SEMANTIC: 0.9882
2025-04-06 12:28:59,963 - INFO - [PIPELINE] Current cost: $0.0004 of $2.00
2025-04-06 12:28:59,963 - INFO - [PIPELINE] Progress: 1/50 samples. Est. remaining: 186.6s (3.1m)
2025-04-06 12:28:59,963 - INFO - ---
Processing samples:   2%|▍                       | 1/50 [00:01<01:18,  1.60s/it]2025-04-06 12:29:00,019 - INFO - [API] Starting reconstruction of text: 'You have requested a debate on...'
2025-04-06 12:29:00,025 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:00,605 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:00,608 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:00,841 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:00,841 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:00,841 - INFO - [API] Completed in 0.822s using api_gpt-3.5-turbo
2025-04-06 12:29:00,842 - INFO - Using default tokenizer.
2025-04-06 12:29:00,919 - INFO - [API] Starting reconstruction of text: 'You have requested a debate on...'
2025-04-06 12:29:00,924 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:01,495 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:01,499 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:01,728 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:01,728 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:01,728 - INFO - [API] Completed in 0.809s using api_gpt-3.5-turbo
2025-04-06 12:29:01,729 - INFO - Using default tokenizer.
2025-04-06 12:29:01,975 - INFO - [PIPELINE] Sample 2/50 (processed in 2.01s)
2025-04-06 12:29:01,975 - INFO - [PIPELINE] Original: You have requested a debate on this subject in the course of the next few days , during this part-session .
2025-04-06 12:29:01,975 - INFO - [PIPELINE] Semantic noisy: You have requested a debate on this subject in the course of qae nxxj few days , ourong this part-session .
2025-04-06 12:29:01,975 - INFO - [PIPELINE] Semantic reconstructed: you will have requested a debate on this subject , the course , the next few days, during this part-session.
2025-04-06 12:29:01,975 - INFO - [PIPELINE] Direct noisy: You have requested a debate on this subject in the course of the xext fvw days , during this part-session .
2025-04-06 12:29:01,975 - INFO - [PIPELINE] Direct reconstructed: you will have requested a debate on this subject , the course , the next few days, during this part-session.
2025-04-06 12:29:01,975 - INFO - [PIPELINE] Semantic BLEU: 0.3990, ROUGE-L: 0.9231, SEMANTIC: 0.9453
2025-04-06 12:29:01,975 - INFO - [PIPELINE] Direct BLEU: 0.3990, ROUGE-L: 0.9231, SEMANTIC: 0.9453
2025-04-06 12:29:01,975 - INFO - [PIPELINE] Current cost: $0.0008 of $2.00
2025-04-06 12:29:01,975 - INFO - [PIPELINE] Progress: 2/50 samples. Est. remaining: 139.7s (2.3m)
2025-04-06 12:29:01,975 - INFO - ---
Processing samples:   4%|▉                       | 2/50 [00:03<01:28,  1.84s/it]2025-04-06 12:29:02,035 - INFO - [API] Starting reconstruction of text: 'Please rise , then , for this ...'
2025-04-06 12:29:02,040 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:02,792 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:02,808 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:02,857 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:02,857 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:02,857 - INFO - [API] Completed in 0.822s using api_gpt-3.5-turbo
2025-04-06 12:29:02,857 - INFO - Using default tokenizer.
2025-04-06 12:29:02,874 - INFO - [API] Starting reconstruction of text: 'Please rise , then , for tcis ...'
2025-04-06 12:29:02,879 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:03,608 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:03,611 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:03,658 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:03,658 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:03,658 - INFO - [API] Completed in 0.784s using api_gpt-3.5-turbo
2025-04-06 12:29:03,658 - INFO - Using default tokenizer.
Processing samples:   6%|█▍                      | 3/50 [00:05<01:23,  1.77s/it]2025-04-06 12:29:03,729 - INFO - [API] Starting reconstruction of text: '( The poxse rose and observed ...'
2025-04-06 12:29:03,737 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:04,448 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:04,451 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:04,534 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:04,534 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:04,534 - INFO - [API] Completed in 0.805s using api_gpt-3.5-turbo
2025-04-06 12:29:04,535 - INFO - Using default tokenizer.
2025-04-06 12:29:04,552 - INFO - [API] Starting reconstruction of text: '( The Hoysn rose and observed ...'
2025-04-06 12:29:04,559 - INFO - [API] Using KB reconstruction with confidence 0.85
2025-04-06 12:29:04,559 - INFO - [API] Completed in 0.007s using method: kb
2025-04-06 12:29:04,559 - INFO - Using default tokenizer.
Processing samples:   8%|█▉                      | 4/50 [00:06<01:05,  1.43s/it]2025-04-06 12:29:04,629 - INFO - [API] Starting reconstruction of text: 'You will be aware from the gre...'
2025-04-06 12:29:04,636 - INFO - [API] Using KB reconstruction with confidence 0.95
2025-04-06 12:29:04,636 - INFO - [API] Completed in 0.007s using method: kb
2025-04-06 12:29:04,637 - INFO - Using default tokenizer.
2025-04-06 12:29:04,650 - INFO - [API] Starting reconstruction of text: 'You will be aware from the pre...'
2025-04-06 12:29:04,656 - INFO - [API] Using KB reconstruction with confidence 0.95
2025-04-06 12:29:04,656 - INFO - [API] Completed in 0.007s using method: kb
2025-04-06 12:29:04,656 - INFO - Using default tokenizer.
2025-04-06 12:29:04,719 - INFO - [API] Starting reconstruction of text: 'One of the people assassinated...'
2025-04-06 12:29:04,726 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:05,499 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:05,512 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:05,722 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:05,723 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:05,723 - INFO - [API] Completed in 1.004s using api_gpt-3.5-turbo
2025-04-06 12:29:05,723 - INFO - Using default tokenizer.
2025-04-06 12:29:05,737 - INFO - [API] Starting reconstruction of text: 'One of nho people assassinated...'
2025-04-06 12:29:05,744 - INFO - [API] Using KB reconstruction with confidence 0.95
2025-04-06 12:29:05,744 - INFO - [API] Completed in 0.008s using method: kb
2025-04-06 12:29:05,745 - INFO - Using default tokenizer.
Processing samples:  12%|██▉                     | 6/50 [00:07<00:43,  1.01it/s]2025-04-06 12:29:05,810 - INFO - [API] Starting reconstruction of text: 'Yes , Mr Evans , I feih an ini...'
2025-04-06 12:29:05,816 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:06,392 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:06,404 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:06,567 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:06,567 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:06,567 - INFO - [API] Completed in 0.757s using api_gpt-3.5-turbo
2025-04-06 12:29:06,568 - INFO - Using default tokenizer.
2025-04-06 12:29:06,581 - INFO - [API] Starting reconstruction of text: 'Yes , Mr Evans , I weez an ini...'
2025-04-06 12:29:06,585 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:07,284 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:07,290 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:07,458 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:07,458 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:07,458 - INFO - [API] Completed in 0.877s using api_gpt-3.5-turbo
2025-04-06 12:29:07,458 - INFO - Using default tokenizer.
Processing samples:  14%|███▎                    | 7/50 [00:09<00:50,  1.19s/it]2025-04-06 12:29:07,530 - INFO - [API] Starting reconstruction of text: 'If the House agrees , I shawl ...'
2025-04-06 12:29:07,533 - INFO - [API] Using KB reconstruction with confidence 0.91
2025-04-06 12:29:07,533 - INFO - [API] Completed in 0.003s using method: kb
2025-04-06 12:29:07,534 - INFO - Using default tokenizer.
2025-04-06 12:29:07,545 - INFO - [API] Starting reconstruction of text: 'If the House agrees , I shall ...'
2025-04-06 12:29:07,547 - INFO - [API] Using KB reconstruction with confidence 0.91
2025-04-06 12:29:07,548 - INFO - [API] Completed in 0.002s using method: kb
2025-04-06 12:29:07,548 - INFO - Using default tokenizer.
2025-04-06 12:29:07,611 - INFO - [API] Starting reconstruction of text: 'daxam President , on a point o...'
2025-04-06 12:29:07,636 - ERROR - [PIPELINE] Error processing sample 8: Boolean value of Tensor with more than one value is ambiguous
2025-04-06 12:29:07,636 - ERROR - Traceback (most recent call last):
  File "/tmp/pycharm_project_908/Europearl/SD5.py", line 1790, in run_enhanced_pipeline
    semantic_reconstructed, api_cost, action = api_reconstruct_with_semantic_features(
  File "/tmp/pycharm_project_908/Europearl/SD5.py", line 125, in wrapper
    result = func(*args, **kwargs)
  File "/tmp/pycharm_project_908/Europearl/SD5.py", line 926, in api_reconstruct_with_semantic_features
    adjusted_state = max(0, state - 1)  # Move state toward cheaper options
RuntimeError: Boolean value of Tensor with more than one value is ambiguous

Processing samples:  18%|████▎                   | 9/50 [00:09<00:28,  1.43it/s]2025-04-06 12:29:07,688 - INFO - [API] Starting reconstruction of text: 'I would like zour advice about...'
2025-04-06 12:29:07,692 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:08,204 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:08,207 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:08,225 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:08,225 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:08,225 - INFO - [API] Completed in 0.538s using api_gpt-3.5-turbo
2025-04-06 12:29:08,226 - INFO - Using default tokenizer.
2025-04-06 12:29:08,245 - INFO - [API] Starting reconstruction of text: 'I would like your advice about...'
2025-04-06 12:29:08,248 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:08,900 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:08,914 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:08,934 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:08,934 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:08,934 - INFO - [API] Completed in 0.689s using api_gpt-3.5-turbo
2025-04-06 12:29:08,934 - INFO - Using default tokenizer.
2025-04-06 12:29:08,950 - INFO - [PIPELINE] Sample 10/50 (processed in 1.31s)
2025-04-06 12:29:08,950 - INFO - [PIPELINE] Original: I would like your advice about Rule 143 concerning inadmissibility .
2025-04-06 12:29:08,950 - INFO - [PIPELINE] Semantic noisy: I would like zour advice about Rule 143 concerning inadmlssibilito .
2025-04-06 12:29:08,950 - INFO - [PIPELINE] Semantic reconstructed: Madam President , , on on a a a a point point order . . .
2025-04-06 12:29:08,950 - INFO - [PIPELINE] Direct noisy: I would like your advice about Rule 143 concerning inadmissibility .
2025-04-06 12:29:08,950 - INFO - [PIPELINE] Direct reconstructed: Madam President , , on on a a a a point point order . . .
2025-04-06 12:29:08,950 - INFO - [PIPELINE] Semantic BLEU: 0.0157, ROUGE-L: 0.0000, SEMANTIC: 0.6009
2025-04-06 12:29:08,950 - INFO - [PIPELINE] Direct BLEU: 0.0157, ROUGE-L: 0.0000, SEMANTIC: 0.6009
2025-04-06 12:29:08,950 - INFO - [PIPELINE] Current cost: $0.0022 of $2.00
2025-04-06 12:29:08,950 - INFO - [PIPELINE] Progress: 10/50 samples. Est. remaining: 51.2s (0.9m)
2025-04-06 12:29:08,950 - INFO - ---
Processing samples:  20%|████▌                  | 10/50 [00:10<00:33,  1.18it/s]2025-04-06 12:29:09,008 - INFO - [API] Starting reconstruction of text: 'My question relates to somethi...'
2025-04-06 12:29:09,011 - INFO - [API] Using KB reconstruction with confidence 0.93
2025-04-06 12:29:09,011 - INFO - [API] Completed in 0.003s using method: kb
2025-04-06 12:29:09,012 - INFO - Using default tokenizer.
2025-04-06 12:29:09,025 - INFO - [API] Starting reconstruction of text: 'My question relates to somethi...'
2025-04-06 12:29:09,028 - INFO - [API] Using KB reconstruction with confidence 0.93
2025-04-06 12:29:09,028 - INFO - [API] Completed in 0.003s using method: kb
2025-04-06 12:29:09,028 - INFO - Using default tokenizer.
2025-04-06 12:29:09,091 - INFO - [API] Starting reconstruction of text: 'The Cunha report on multiannua...'
2025-04-06 12:29:09,102 - INFO - [API] Using KB reconstruction with confidence 0.93
2025-04-06 12:29:09,102 - INFO - [API] Completed in 0.011s using method: kb
2025-04-06 12:29:09,102 - INFO - Using default tokenizer.
2025-04-06 12:29:09,117 - INFO - [API] Starting reconstruction of text: 'The Cunha report on multiannua...'
2025-04-06 12:29:09,128 - INFO - [API] Using KB reconstruction with confidence 0.97
2025-04-06 12:29:09,128 - INFO - [API] Completed in 0.011s using method: kb
2025-04-06 12:29:09,129 - INFO - Using default tokenizer.
Processing samples:  24%|█████▌                 | 12/50 [00:10<00:20,  1.84it/s]2025-04-06 12:29:09,194 - INFO - [API] Starting reconstruction of text: 'It says that this should be do...'
2025-04-06 12:29:09,196 - INFO - [API] Using KB reconstruction with confidence 0.74
2025-04-06 12:29:09,196 - INFO - [API] Completed in 0.003s using method: kb
2025-04-06 12:29:09,197 - INFO - Using default tokenizer.
2025-04-06 12:29:09,209 - INFO - [API] Starting reconstruction of text: 'It says that thig should be dc...'
2025-04-06 12:29:09,211 - INFO - [API] Using KB reconstruction with confidence 0.74
2025-04-06 12:29:09,211 - INFO - [API] Completed in 0.003s using method: kb
2025-04-06 12:29:09,211 - INFO - Using default tokenizer.
2025-04-06 12:29:09,273 - INFO - [API] Starting reconstruction of text: 'I believe that the principle o...'
2025-04-06 12:29:09,281 - INFO - [API] Using KB reconstruction with confidence 0.88
2025-04-06 12:29:09,281 - INFO - [API] Completed in 0.007s using method: kb
2025-04-06 12:29:09,281 - INFO - Using default tokenizer.
2025-04-06 12:29:09,295 - INFO - [API] Starting reconstruction of text: 'I believe that the principle o...'
2025-04-06 12:29:09,302 - INFO - [API] Using KB reconstruction with confidence 0.88
2025-04-06 12:29:09,302 - INFO - [API] Completed in 0.007s using method: kb
2025-04-06 12:29:09,303 - INFO - Using default tokenizer.
Processing samples:  28%|██████▍                | 14/50 [00:10<00:13,  2.67it/s]2025-04-06 12:29:09,366 - INFO - [API] Starting reconstruction of text: 'I want to know whether oku can...'
2025-04-06 12:29:09,374 - INFO - [API] Using KB reconstruction with confidence 0.89
2025-04-06 12:29:09,374 - INFO - [API] Completed in 0.007s using method: kb
2025-04-06 12:29:09,374 - INFO - Using default tokenizer.
2025-04-06 12:29:09,388 - INFO - [API] Starting reconstruction of text: 'I want to mnow whether one can...'
2025-04-06 12:29:09,395 - INFO - [API] Using KB reconstruction with confidence 0.89
2025-04-06 12:29:09,395 - INFO - [API] Completed in 0.007s using method: kb
2025-04-06 12:29:09,395 - INFO - Using default tokenizer.
2025-04-06 12:29:09,460 - INFO - [API] Starting reconstruction of text: 'That is precisely cxe time whe...'
2025-04-06 12:29:09,464 - INFO - [API] Using KB reconstruction with confidence 0.93
2025-04-06 12:29:09,464 - INFO - [API] Completed in 0.004s using method: kb
2025-04-06 12:29:09,464 - INFO - Using default tokenizer.
2025-04-06 12:29:09,476 - INFO - [API] Starting reconstruction of text: 'That is precisely the yige whe...'
2025-04-06 12:29:09,480 - INFO - [API] Using KB reconstruction with confidence 0.93
2025-04-06 12:29:09,480 - INFO - [API] Completed in 0.003s using method: kb
2025-04-06 12:29:09,480 - INFO - Using default tokenizer.
Processing samples:  32%|███████▎               | 16/50 [00:11<00:09,  3.62it/s]2025-04-06 12:29:09,542 - INFO - [API] Starting reconstruction of text: 'on Thursday prior to the start...'
2025-04-06 12:29:09,545 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:10,258 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:10,261 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:10,398 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:10,399 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:10,399 - INFO - [API] Completed in 0.856s using api_gpt-3.5-turbo
2025-04-06 12:29:10,399 - INFO - Using default tokenizer.
2025-04-06 12:29:10,415 - INFO - [API] Starting reconstruction of text: 'on Thursday prior to the start...'
2025-04-06 12:29:10,418 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:11,083 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:11,087 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:11,221 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:11,221 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:11,221 - INFO - [API] Completed in 0.806s using api_gpt-3.5-turbo
2025-04-06 12:29:11,221 - INFO - Using default tokenizer.
Processing samples:  34%|███████▊               | 17/50 [00:12<00:18,  1.77it/s]2025-04-06 12:29:11,287 - INFO - [API] Starting reconstruction of text: 'We shall call him Mr Hicks ....'
2025-04-06 12:29:11,289 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:11,767 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:11,773 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:11,801 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:11,801 - INFO - [API] Completed in 0.515s using api_gpt-3.5-turbo
2025-04-06 12:29:11,802 - INFO - Using default tokenizer.
2025-04-06 12:29:11,814 - INFO - [API] Starting reconstruction of text: 'We shall call him Mr Hicks ....'
2025-04-06 12:29:11,817 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:12,324 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:12,333 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:12,359 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:12,359 - INFO - [API] Completed in 0.545s using api_gpt-3.5-turbo
2025-04-06 12:29:12,359 - INFO - Using default tokenizer.
Processing samples:  36%|████████▎              | 18/50 [00:14<00:22,  1.45it/s]2025-04-06 12:29:12,430 - INFO - [API] Starting reconstruction of text: 'At the request of a Frenui Mem...'
2025-04-06 12:29:12,443 - INFO - [API] Using KB reconstruction with confidence 0.94
2025-04-06 12:29:12,443 - INFO - [API] Completed in 0.013s using method: kb
2025-04-06 12:29:12,443 - INFO - Using default tokenizer.
2025-04-06 12:29:12,456 - INFO - [API] Starting reconstruction of text: 'At ehi request of a French Mem...'
2025-04-06 12:29:12,469 - INFO - [API] Using KB reconstruction with confidence 0.87
2025-04-06 12:29:12,469 - INFO - [API] Completed in 0.013s using method: kb
2025-04-06 12:29:12,469 - INFO - Using default tokenizer.
Processing samples:  38%|████████▋              | 19/50 [00:14<00:17,  1.81it/s]2025-04-06 12:29:12,534 - INFO - [API] Starting reconstruction of text: 'This is all in accordance wido...'
2025-04-06 12:29:12,537 - INFO - [API] Using KB reconstruction with confidence 0.91
2025-04-06 12:29:12,537 - INFO - [API] Completed in 0.003s using method: kb
2025-04-06 12:29:12,538 - INFO - Using default tokenizer.
2025-04-06 12:29:12,550 - INFO - [API] Starting reconstruction of text: 'This is all in accordance with...'
2025-04-06 12:29:12,554 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:13,206 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:13,209 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:13,387 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:13,388 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:13,388 - INFO - [API] Completed in 0.838s using api_gpt-3.5-turbo
2025-04-06 12:29:13,388 - INFO - Using default tokenizer.
2025-04-06 12:29:13,405 - INFO - [PIPELINE] Sample 20/50 (processed in 0.92s)
2025-04-06 12:29:13,405 - INFO - [PIPELINE] Original: This is all in accordance with the principles that we have always upheld .
2025-04-06 12:29:13,405 - INFO - [PIPELINE] Semantic noisy: This is all in accordance wido the principles that we have always upheld .
2025-04-06 12:29:13,405 - INFO - [PIPELINE] Semantic reconstructed: This is all in accordance wido the principles the we have always upheld .
2025-04-06 12:29:13,405 - INFO - [PIPELINE] Direct noisy: This is all in accordance with thf principles thcc we haae aewass upheld .
2025-04-06 12:29:13,405 - INFO - [PIPELINE] Direct reconstructed: At the request of a French Member , , , Mr Zimeray Mr Mr Zimeray Zimeray Zimeray , Zimeray , petition a a petition has petition petition has already been presented , which , which which which which many people many many people people , including , including myself including including myself including myself . .
2025-04-06 12:29:13,406 - INFO - [PIPELINE] Semantic BLEU: 0.5731, ROUGE-L: 0.8462, SEMANTIC: 0.9280
2025-04-06 12:29:13,406 - INFO - [PIPELINE] Direct BLEU: 0.0066, ROUGE-L: 0.0345, SEMANTIC: 0.5610
2025-04-06 12:29:13,406 - INFO - [PIPELINE] Current cost: $0.0031 of $2.00
2025-04-06 12:29:13,406 - INFO - [PIPELINE] Progress: 20/50 samples. Est. remaining: 25.9s (0.4m)
2025-04-06 12:29:13,406 - INFO - ---
Processing samples:  40%|█████████▏             | 20/50 [00:15<00:19,  1.55it/s]2025-04-06 12:29:13,464 - INFO - [API] Starting reconstruction of text: 'Thank you , Mr Segni , I shall...'
2025-04-06 12:29:13,466 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:14,092 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:14,095 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:14,136 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:14,136 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:14,136 - INFO - [API] Completed in 0.672s using api_gpt-3.5-turbo
2025-04-06 12:29:14,136 - INFO - Using default tokenizer.
2025-04-06 12:29:14,149 - INFO - [API] Starting reconstruction of text: 'Thank iou , Mr Segni , I shall...'
2025-04-06 12:29:14,151 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:14,689 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:14,694 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:14,734 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:14,734 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:14,734 - INFO - [API] Completed in 0.585s using api_gpt-3.5-turbo
2025-04-06 12:29:14,734 - INFO - Using default tokenizer.
Processing samples:  42%|█████████▋             | 21/50 [00:16<00:24,  1.20it/s]2025-04-06 12:29:14,804 - INFO - [API] Starting reconstruction of text: 'dnjeed , it is quite in keepin...'
2025-04-06 12:29:14,811 - INFO - [API] Using KB reconstruction with confidence 0.73
2025-04-06 12:29:14,811 - INFO - [API] Completed in 0.007s using method: kb
2025-04-06 12:29:14,812 - INFO - Using default tokenizer.
2025-04-06 12:29:14,824 - INFO - [API] Starting reconstruction of text: 'Indeed , it is quite in keepin...'
2025-04-06 12:29:14,832 - INFO - [API] Using KB reconstruction with confidence 0.83
2025-04-06 12:29:14,832 - INFO - [API] Completed in 0.008s using method: kb
2025-04-06 12:29:14,833 - INFO - Using default tokenizer.
2025-04-06 12:29:14,895 - INFO - [API] Starting reconstruction of text: 'Madam Prjsideny , I should lik...'
2025-04-06 12:29:14,899 - INFO - [API] Using KB reconstruction with confidence 0.95
2025-04-06 12:29:14,900 - INFO - [API] Completed in 0.005s using method: kb
2025-04-06 12:29:14,900 - INFO - Using default tokenizer.
2025-04-06 12:29:14,913 - INFO - [API] Starting reconstruction of text: 'Madao President , I should lik...'
2025-04-06 12:29:14,922 - INFO - [API] Using KB reconstruction with confidence 0.87
2025-04-06 12:29:14,922 - INFO - [API] Completed in 0.009s using method: kb
2025-04-06 12:29:14,922 - INFO - Using default tokenizer.
Processing samples:  46%|██████████▌            | 23/50 [00:16<00:13,  1.95it/s]2025-04-06 12:29:14,987 - INFO - [API] Starting reconstruction of text: 'It is the case of Alexdyder Ni...'
2025-04-06 12:29:14,990 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:15,740 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:15,747 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:15,949 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:15,949 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:15,949 - INFO - [API] Completed in 0.963s using api_gpt-3.5-turbo
2025-04-06 12:29:15,950 - INFO - Using default tokenizer.
2025-04-06 12:29:15,968 - INFO - [API] Starting reconstruction of text: 'It is the cisl of Alexander Ni...'
2025-04-06 12:29:15,971 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:16,665 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:16,670 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:16,819 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:16,819 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:16,819 - INFO - [API] Completed in 0.851s using api_gpt-3.5-turbo
2025-04-06 12:29:16,819 - INFO - Using default tokenizer.
Processing samples:  48%|███████████            | 24/50 [00:18<00:21,  1.19it/s]2025-04-06 12:29:16,884 - INFO - [API] Starting reconstruction of text: 'All of us here aud pleased tha...'
2025-04-06 12:29:16,892 - INFO - [API] Using KB reconstruction with confidence 0.92
2025-04-06 12:29:16,892 - INFO - [API] Completed in 0.008s using method: kb
2025-04-06 12:29:16,892 - INFO - Using default tokenizer.
2025-04-06 12:29:16,906 - INFO - [API] Starting reconstruction of text: 'All of us here are pleased tha...'
2025-04-06 12:29:16,913 - INFO - [API] Using KB reconstruction with confidence 0.92
2025-04-06 12:29:16,913 - INFO - [API] Completed in 0.007s using method: kb
2025-04-06 12:29:16,913 - INFO - Using default tokenizer.
2025-04-06 12:29:16,977 - INFO - [API] Starting reconstruction of text: 'Now , however , he is to go be...'
2025-04-06 12:29:16,987 - INFO - [API] Using KB reconstruction with confidence 0.86
2025-04-06 12:29:16,987 - INFO - [API] Completed in 0.010s using method: kb
2025-04-06 12:29:16,988 - INFO - Using default tokenizer.
2025-04-06 12:29:17,000 - INFO - [API] Starting reconstruction of text: 'Now , however , he is to go be...'
2025-04-06 12:29:17,010 - INFO - [API] Using KB reconstruction with confidence 0.86
2025-04-06 12:29:17,010 - INFO - [API] Completed in 0.010s using method: kb
2025-04-06 12:29:17,010 - INFO - Using default tokenizer.
Processing samples:  52%|███████████▉           | 26/50 [00:18<00:12,  1.85it/s]2025-04-06 12:29:17,075 - INFO - [API] Starting reconstruction of text: 'Yes , Mrs Schroedter , I shall...'
2025-04-06 12:29:17,080 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:17,723 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:17,727 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:17,860 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:17,860 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:17,860 - INFO - [API] Completed in 0.786s using api_gpt-3.5-turbo
2025-04-06 12:29:17,861 - INFO - Using default tokenizer.
2025-04-06 12:29:17,875 - INFO - [API] Starting reconstruction of text: 'Yes , Mrs Schroedter , I shall...'
2025-04-06 12:29:17,880 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:18,536 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:18,540 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:18,672 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:18,672 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:18,672 - INFO - [API] Completed in 0.797s using api_gpt-3.5-turbo
2025-04-06 12:29:18,672 - INFO - Using default tokenizer.
Processing samples:  54%|████████████▍          | 27/50 [00:20<00:18,  1.26it/s]2025-04-06 12:29:18,750 - INFO - [API] Starting reconstruction of text: 'But , Madam President , my per...'
2025-04-06 12:29:18,842 - ERROR - [PIPELINE] Error processing sample 27: Boolean value of Tensor with more than one value is ambiguous
2025-04-06 12:29:18,842 - ERROR - Traceback (most recent call last):
  File "/tmp/pycharm_project_908/Europearl/SD5.py", line 1790, in run_enhanced_pipeline
    semantic_reconstructed, api_cost, action = api_reconstruct_with_semantic_features(
  File "/tmp/pycharm_project_908/Europearl/SD5.py", line 125, in wrapper
    result = func(*args, **kwargs)
  File "/tmp/pycharm_project_908/Europearl/SD5.py", line 926, in api_reconstruct_with_semantic_features
    adjusted_state = max(0, state - 1)  # Move state toward cheaper options
RuntimeError: Boolean value of Tensor with more than one value is ambiguous

Processing samples:  56%|████████████▉          | 28/50 [00:20<00:14,  1.57it/s]2025-04-06 12:29:18,895 - INFO - [API] Starting reconstruction of text: 'I would therefore once more as...'
2025-04-06 12:29:18,898 - INFO - [API] Using KB reconstruction with confidence 0.93
2025-04-06 12:29:18,898 - INFO - [API] Completed in 0.003s using method: kb
2025-04-06 12:29:18,899 - INFO - Using default tokenizer.
2025-04-06 12:29:18,912 - INFO - [API] Starting reconstruction of text: 'I would tasrefore once more as...'
2025-04-06 12:29:18,915 - INFO - [API] Using KB reconstruction with confidence 0.93
2025-04-06 12:29:18,915 - INFO - [API] Completed in 0.004s using method: kb
2025-04-06 12:29:18,915 - INFO - Using default tokenizer.
2025-04-06 12:29:18,979 - INFO - [API] Starting reconstruction of text: 'Mrs Plooij-van Gorsel , I can ...'
2025-04-06 12:29:18,983 - INFO - [API] Using KB reconstruction with confidence 0.94
2025-04-06 12:29:18,984 - INFO - [API] Completed in 0.005s using method: kb
2025-04-06 12:29:18,984 - INFO - Using default tokenizer.
2025-04-06 12:29:18,997 - INFO - [API] Starting reconstruction of text: 'Mrs nlooiq-van Gorsel , I can ...'
2025-04-06 12:29:19,002 - INFO - [API] Using KB reconstruction with confidence 0.94
2025-04-06 12:29:19,003 - INFO - [API] Completed in 0.006s using method: kb
2025-04-06 12:29:19,003 - INFO - Using default tokenizer.
2025-04-06 12:29:19,015 - INFO - [PIPELINE] Sample 30/50 (processed in 0.09s)
2025-04-06 12:29:19,015 - INFO - [PIPELINE] Original: Mrs Plooij-van Gorsel , I can tell you that this matter is on the agenda for the Quaestors ' meeting on Wednesday .
2025-04-06 12:29:19,015 - INFO - [PIPELINE] Semantic noisy: Mrs Plooij-van Gorsel , I can mell you that this matter is on the agenda for the Quaestors ' meeting on Wednesday .
2025-04-06 12:29:19,015 - INFO - [PIPELINE] Semantic reconstructed: Mrs Plooij-van Gorsel , I can mell you the this matter is on the agenda for the Quaestors ' meeting on Wednesday .
2025-04-06 12:29:19,015 - INFO - [PIPELINE] Direct noisy: Mrs nlooiq-van Gorsel , I can tell you that this matter is on the agunda for the Quaestors ' oeeting on Wednesday .
2025-04-06 12:29:19,015 - INFO - [PIPELINE] Direct reconstructed: Mrs nlooiq-van Gorsel , I can tell you the this matter is on the agunda for the Quaestors ' oeeting on Wednesday .
2025-04-06 12:29:19,015 - INFO - [PIPELINE] Semantic BLEU: 0.7945, ROUGE-L: 0.9048, SEMANTIC: 0.9789
2025-04-06 12:29:19,015 - INFO - [PIPELINE] Direct BLEU: 0.5235, ROUGE-L: 0.8095, SEMANTIC: 0.9029
2025-04-06 12:29:19,015 - INFO - [PIPELINE] Current cost: $0.0042 of $2.00
2025-04-06 12:29:19,015 - INFO - [PIPELINE] Progress: 30/50 samples. Est. remaining: 15.2s (0.3m)
2025-04-06 12:29:19,015 - INFO - ---
Processing samples:  60%|█████████████▊         | 30/50 [00:20<00:08,  2.43it/s]2025-04-06 12:29:19,067 - INFO - [API] Starting reconstruction of text: 'It will , I hope , be examined...'
2025-04-06 12:29:19,071 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:19,629 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:19,635 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:19,706 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:19,707 - INFO - [API] Completed in 0.640s using api_gpt-3.5-turbo
2025-04-06 12:29:19,707 - INFO - Using default tokenizer.
2025-04-06 12:29:19,719 - INFO - [API] Starting reconstruction of text: 'It will , I hope , be exkmined...'
2025-04-06 12:29:19,723 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:20,288 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:20,293 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:20,364 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:20,364 - INFO - [API] Completed in 0.645s using api_gpt-3.5-turbo
2025-04-06 12:29:20,364 - INFO - Using default tokenizer.
Processing samples:  62%|██████████████▎        | 31/50 [00:22<00:11,  1.60it/s]2025-04-06 12:29:20,434 - INFO - [API] Starting reconstruction of text: 'Mudjm President , can you tell...'
2025-04-06 12:29:20,441 - INFO - [API] Using KB reconstruction with confidence 0.95
2025-04-06 12:29:20,441 - INFO - [API] Completed in 0.006s using method: kb
2025-04-06 12:29:20,441 - INFO - Using default tokenizer.
2025-04-06 12:29:20,455 - INFO - [API] Starting reconstruction of text: 'Madam President , can you tell...'
2025-04-06 12:29:20,460 - INFO - [API] Using KB reconstruction with confidence 0.95
2025-04-06 12:29:20,460 - INFO - [API] Completed in 0.005s using method: kb
2025-04-06 12:29:20,460 - INFO - Using default tokenizer.
2025-04-06 12:29:20,524 - INFO - [API] Starting reconstruction of text: 'Why has no nir quality test be...'
2025-04-06 12:29:20,533 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:21,287 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:21,301 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:21,591 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:21,591 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:21,591 - INFO - [API] Completed in 1.067s using api_gpt-3.5-turbo
2025-04-06 12:29:21,592 - INFO - Using default tokenizer.
2025-04-06 12:29:21,609 - INFO - [API] Starting reconstruction of text: 'Why has no air quality test be...'
2025-04-06 12:29:21,613 - INFO - [API] Using KB reconstruction with confidence 0.93
2025-04-06 12:29:21,613 - INFO - [API] Completed in 0.004s using method: kb
2025-04-06 12:29:21,613 - INFO - Using default tokenizer.
Processing samples:  66%|███████████████▏       | 33/50 [00:23<00:10,  1.60it/s]2025-04-06 12:29:21,683 - INFO - [API] Starting reconstruction of text: 'Why has there been no Health a...'
2025-04-06 12:29:21,690 - INFO - [API] Using KB reconstruction with confidence 0.90
2025-04-06 12:29:21,690 - INFO - [API] Completed in 0.007s using method: kb
2025-04-06 12:29:21,691 - INFO - Using default tokenizer.
2025-04-06 12:29:21,703 - INFO - [API] Starting reconstruction of text: 'Why has there been no Health a...'
2025-04-06 12:29:21,711 - INFO - [API] Using KB reconstruction with confidence 0.90
2025-04-06 12:29:21,711 - INFO - [API] Completed in 0.008s using method: kb
2025-04-06 12:29:21,711 - INFO - Using default tokenizer.
2025-04-06 12:29:21,774 - INFO - [API] Starting reconstruction of text: 'Why has there bxen no fire dri...'
2025-04-06 12:29:21,780 - INFO - [API] Using KB reconstruction with confidence 0.95
2025-04-06 12:29:21,780 - INFO - [API] Completed in 0.006s using method: kb
2025-04-06 12:29:21,781 - INFO - Using default tokenizer.
2025-04-06 12:29:21,793 - INFO - [API] Starting reconstruction of text: 'Why has there been no fire dri...'
2025-04-06 12:29:21,800 - INFO - [API] Using KB reconstruction with confidence 0.89
2025-04-06 12:29:21,800 - INFO - [API] Completed in 0.006s using method: kb
2025-04-06 12:29:21,800 - INFO - Using default tokenizer.
Processing samples:  70%|████████████████       | 35/50 [00:23<00:06,  2.30it/s]2025-04-06 12:29:21,864 - INFO - [API] Starting reconstruction of text: 'Why are there no fire instruct...'
2025-04-06 12:29:21,867 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:22,452 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:22,457 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:22,599 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:22,599 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:22,599 - INFO - [API] Completed in 0.735s using api_gpt-3.5-turbo
2025-04-06 12:29:22,599 - INFO - Using default tokenizer.
2025-04-06 12:29:22,613 - INFO - [API] Starting reconstruction of text: 'Why are there no fire instruct...'
2025-04-06 12:29:22,616 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:23,237 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:23,241 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:23,352 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:23,352 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:23,352 - INFO - [API] Completed in 0.739s using api_gpt-3.5-turbo
2025-04-06 12:29:23,352 - INFO - Using default tokenizer.
Processing samples:  72%|████████████████▌      | 36/50 [00:24<00:09,  1.51it/s]2025-04-06 12:29:23,422 - INFO - [API] Starting reconstruction of text: 'Wrv have the staqrcages not be...'
2025-04-06 12:29:23,429 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:24,131 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:24,149 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:24,186 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:24,186 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:24,186 - INFO - [API] Completed in 0.764s using api_gpt-3.5-turbo
2025-04-06 12:29:24,186 - INFO - Using default tokenizer.
2025-04-06 12:29:24,200 - INFO - [API] Starting reconstruction of text: 'hhj have the staircases not be...'
2025-04-06 12:29:24,207 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:24,753 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:24,758 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:24,794 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:24,794 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:24,794 - INFO - [API] Completed in 0.594s using api_gpt-3.5-turbo
2025-04-06 12:29:24,795 - INFO - Using default tokenizer.
Processing samples:  74%|█████████████████      | 37/50 [00:26<00:10,  1.19it/s]2025-04-06 12:29:24,865 - INFO - [API] Starting reconstruction of text: 'Why are no-smoking kreas not e...'
2025-04-06 12:29:24,868 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:25,532 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:25,535 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:25,571 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:25,571 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:25,571 - INFO - [API] Completed in 0.706s using api_gpt-3.5-turbo
2025-04-06 12:29:25,572 - INFO - Using default tokenizer.
2025-04-06 12:29:25,585 - INFO - [API] Starting reconstruction of text: 'Why bae no-smoking cleas not e...'
2025-04-06 12:29:25,591 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:26,115 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:26,123 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:26,156 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:26,157 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:26,157 - INFO - [API] Completed in 0.571s using api_gpt-3.5-turbo
2025-04-06 12:29:26,157 - INFO - Using default tokenizer.
Processing samples:  76%|█████████████████▍     | 38/50 [00:27<00:11,  1.03it/s]2025-04-06 12:29:26,227 - INFO - [API] Starting reconstruction of text: 'It seems absolutely disgracefu...'
2025-04-06 12:29:26,230 - INFO - [API] Using KB reconstruction with confidence 0.92
2025-04-06 12:29:26,230 - INFO - [API] Completed in 0.004s using method: kb
2025-04-06 12:29:26,231 - INFO - Using default tokenizer.
2025-04-06 12:29:26,243 - INFO - [API] Starting reconstruction of text: 'It seems absolutely disgracefu...'
2025-04-06 12:29:26,246 - INFO - [API] Using KB reconstruction with confidence 0.92
2025-04-06 12:29:26,247 - INFO - [API] Completed in 0.003s using method: kb
2025-04-06 12:29:26,247 - INFO - Using default tokenizer.
2025-04-06 12:29:26,310 - INFO - [API] Starting reconstruction of text: 'Mrs vynnq , roz are quite righ...'
2025-04-06 12:29:26,315 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:26,918 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:26,921 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:27,021 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:27,021 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:27,021 - INFO - [API] Completed in 0.711s using api_gpt-3.5-turbo
2025-04-06 12:29:27,022 - INFO - Using default tokenizer.
2025-04-06 12:29:27,035 - INFO - [API] Starting reconstruction of text: 'Mrs Lynne , you are quite righ...'
2025-04-06 12:29:27,040 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:27,579 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:27,583 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:27,677 - INFO - [API] Further enhanced API result with context
2025-04-06 12:29:27,677 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:27,677 - INFO - [API] Completed in 0.641s using api_gpt-3.5-turbo
2025-04-06 12:29:27,677 - INFO - Using default tokenizer.
2025-04-06 12:29:27,690 - INFO - [PIPELINE] Sample 40/50 (processed in 1.43s)
2025-04-06 12:29:27,690 - INFO - [PIPELINE] Original: Mrs Lynne , you are quite right and I shall check whether this has actually not been done .
2025-04-06 12:29:27,690 - INFO - [PIPELINE] Semantic noisy: Mrs vynnq , roz are quite right aed I shall check whether this has actually kox been done .
2025-04-06 12:29:27,690 - INFO - [PIPELINE] Semantic reconstructed: Mrs. Plooij-van Gorsel, you are quite right and do shall check whether this has actually been done.
2025-04-06 12:29:27,690 - INFO - [PIPELINE] Direct noisy: Mrs Lynne , you are quite right and I shall check whether this has actually not been done .
2025-04-06 12:29:27,690 - INFO - [PIPELINE] Direct reconstructed: Mrs. Lynne, you are quite right, and do shall check whether this has actually not been done.
2025-04-06 12:29:27,690 - INFO - [PIPELINE] Semantic BLEU: 0.4509, ROUGE-L: 0.8000, SEMANTIC: 0.8746
2025-04-06 12:29:27,690 - INFO - [PIPELINE] Direct BLEU: 0.4509, ROUGE-L: 0.9412, SEMANTIC: 0.9578
2025-04-06 12:29:27,690 - INFO - [PIPELINE] Current cost: $0.0061 of $2.00
2025-04-06 12:29:27,690 - INFO - [PIPELINE] Progress: 40/50 samples. Est. remaining: 7.9s (0.1m)
2025-04-06 12:29:27,690 - INFO - ---
Processing samples:  80%|██████████████████▍    | 40/50 [00:29<00:08,  1.13it/s]2025-04-06 12:29:27,741 - INFO - [API] Starting reconstruction of text: 'I shall dlss refer the matter ...'
2025-04-06 12:29:27,747 - INFO - [API] Using KB reconstruction with confidence 0.89
2025-04-06 12:29:27,747 - INFO - [API] Completed in 0.006s using method: kb
2025-04-06 12:29:27,748 - INFO - Using default tokenizer.
2025-04-06 12:29:27,761 - INFO - [API] Starting reconstruction of text: 'I seaul also refer the matter ...'
2025-04-06 12:29:27,768 - INFO - [API] Using KB reconstruction with confidence 0.89
2025-04-06 12:29:27,768 - INFO - [API] Completed in 0.006s using method: kb
2025-04-06 12:29:27,768 - INFO - Using default tokenizer.
2025-04-06 12:29:27,834 - INFO - [API] Starting reconstruction of text: 'Madam President , Mrs Díez Gon...'
2025-04-06 12:29:27,841 - INFO - [API] Using KB reconstruction with confidence 0.96
2025-04-06 12:29:27,841 - INFO - [API] Completed in 0.007s using method: kb
2025-04-06 12:29:27,841 - INFO - Using default tokenizer.
2025-04-06 12:29:27,854 - INFO - [API] Starting reconstruction of text: 'Madam President , Myi Díez Gon...'
2025-04-06 12:29:27,861 - INFO - [API] Using KB reconstruction with confidence 0.96
2025-04-06 12:29:27,861 - INFO - [API] Completed in 0.007s using method: kb
2025-04-06 12:29:27,862 - INFO - Using default tokenizer.
Processing samples:  84%|███████████████████▎   | 42/50 [00:29<00:04,  1.70it/s]2025-04-06 12:29:27,925 - INFO - [API] Starting reconstruction of text: 'The competent services have no...'
2025-04-06 12:29:27,932 - INFO - [API] Using KB reconstruction with confidence 0.95
2025-04-06 12:29:27,932 - INFO - [API] Completed in 0.007s using method: kb
2025-04-06 12:29:27,933 - INFO - Using default tokenizer.
2025-04-06 12:29:27,946 - INFO - [API] Starting reconstruction of text: 'The competent services have no...'
2025-04-06 12:29:27,952 - INFO - [API] Using KB reconstruction with confidence 0.95
2025-04-06 12:29:27,952 - INFO - [API] Completed in 0.007s using method: kb
2025-04-06 12:29:27,953 - INFO - Using default tokenizer.
2025-04-06 12:29:28,016 - INFO - [API] Starting reconstruction of text: 'I bojld rsk that they reconsid...'
2025-04-06 12:29:28,019 - INFO - [API] Using KB reconstruction with confidence 0.91
2025-04-06 12:29:28,019 - INFO - [API] Completed in 0.003s using method: kb
2025-04-06 12:29:28,019 - INFO - Using default tokenizer.
2025-04-06 12:29:28,031 - INFO - [API] Starting reconstruction of text: 'I would ask that they reconsid...'
2025-04-06 12:29:28,034 - INFO - [API] Using KB reconstruction with confidence 0.91
2025-04-06 12:29:28,034 - INFO - [API] Completed in 0.003s using method: kb
2025-04-06 12:29:28,034 - INFO - Using default tokenizer.
Processing samples:  88%|████████████████████▏  | 44/50 [00:29<00:02,  2.41it/s]2025-04-06 12:29:28,097 - INFO - [API] Starting reconstruction of text: 'The questions answered previou...'
2025-04-06 12:29:28,105 - INFO - [API] Using KB reconstruction with confidence 0.97
2025-04-06 12:29:28,105 - INFO - [API] Completed in 0.008s using method: kb
2025-04-06 12:29:28,106 - INFO - Using default tokenizer.
2025-04-06 12:29:28,119 - INFO - [API] Starting reconstruction of text: 'The questions answered previou...'
2025-04-06 12:29:28,127 - INFO - [API] Using KB reconstruction with confidence 0.97
2025-04-06 12:29:28,127 - INFO - [API] Completed in 0.008s using method: kb
2025-04-06 12:29:28,127 - INFO - Using default tokenizer.
2025-04-06 12:29:28,191 - INFO - [API] Starting reconstruction of text: 'Mr Berenguer Fuster , we shall...'
2025-04-06 12:29:28,194 - INFO - [API] Making API call with model gpt-3.5-turbo...
2025-04-06 12:29:28,711 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:28,714 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-04-06 12:29:28,803 - INFO - [API] API reconstruction successful using model gpt-3.5-turbo
2025-04-06 12:29:28,803 - INFO - [API] Completed in 0.612s using api_gpt-3.5-turbo
2025-04-06 12:29:28,803 - INFO - Using default tokenizer.
2025-04-06 12:29:28,815 - INFO - [API] Starting reconstruction of text: 'Mr Berenguer Fasteb , we shslr...'
2025-04-06 12:29:28,820 - INFO - [API] Using KB reconstruction with confidence 0.86
2025-04-06 12:29:28,820 - INFO - [API] Completed in 0.005s using method: kb
2025-04-06 12:29:28,820 - INFO - Using default tokenizer.
Processing samples:  92%|█████████████████████▏ | 46/50 [00:30<00:01,  2.45it/s]2025-04-06 12:29:28,885 - INFO - [API] Starting reconstruction of text: 'I admit that , at present , th...'
2025-04-06 12:29:28,887 - INFO - [API] Using KB reconstruction with confidence 0.91
2025-04-06 12:29:28,887 - INFO - [API] Completed in 0.002s using method: kb
2025-04-06 12:29:28,888 - INFO - Using default tokenizer.
2025-04-06 12:29:28,900 - INFO - [API] Starting reconstruction of text: 'I admit that , at presink , th...'
2025-04-06 12:29:28,902 - INFO - [API] Using KB reconstruction with confidence 0.91
2025-04-06 12:29:28,902 - INFO - [API] Completed in 0.002s using method: kb
2025-04-06 12:29:28,902 - INFO - Using default tokenizer.
2025-04-06 12:29:28,965 - INFO - [API] Starting reconstruction of text: 'We shall thyreaore look hngo i...'
2025-04-06 12:29:28,968 - INFO - [API] Using KB reconstruction with confidence 0.84
2025-04-06 12:29:28,968 - INFO - [API] Completed in 0.003s using method: kb
2025-04-06 12:29:28,968 - INFO - Using default tokenizer.
2025-04-06 12:29:28,980 - INFO - [API] Starting reconstruction of text: 'We shall therefore look into i...'
2025-04-06 12:29:28,983 - INFO - [API] Using KB reconstruction with confidence 0.92
2025-04-06 12:29:28,983 - INFO - [API] Completed in 0.003s using method: kb
2025-04-06 12:29:28,983 - INFO - Using default tokenizer.
Processing samples:  96%|██████████████████████ | 48/50 [00:30<00:00,  3.30it/s]2025-04-06 12:29:29,046 - INFO - [API] Starting reconstruction of text: 'Today 's decision not to renew...'
2025-04-06 12:29:29,052 - INFO - [API] Using KB reconstruction with confidence 0.75
2025-04-06 12:29:29,053 - INFO - [API] Completed in 0.007s using method: kb
2025-04-06 12:29:29,053 - INFO - Using default tokenizer.
2025-04-06 12:29:29,066 - INFO - [API] Starting reconstruction of text: 'Today 's decision not to renew...'
2025-04-06 12:29:29,074 - INFO - [API] Using KB reconstruction with confidence 0.75
2025-04-06 12:29:29,074 - INFO - [API] Completed in 0.007s using method: kb
2025-04-06 12:29:29,074 - INFO - Using default tokenizer.
2025-04-06 12:29:29,138 - INFO - [API] Starting reconstruction of text: 'So Parliament hhoult send a me...'
2025-04-06 12:29:29,141 - INFO - [API] Using KB reconstruction with confidence 0.92
2025-04-06 12:29:29,141 - INFO - [API] Completed in 0.003s using method: kb
2025-04-06 12:29:29,142 - INFO - Using default tokenizer.
2025-04-06 12:29:29,154 - INFO - [API] Starting reconstruction of text: 'So Parliament shrulm send a me...'
2025-04-06 12:29:29,157 - INFO - [API] Using KB reconstruction with confidence 0.92
2025-04-06 12:29:29,157 - INFO - [API] Completed in 0.003s using method: kb
2025-04-06 12:29:29,157 - INFO - Using default tokenizer.
2025-04-06 12:29:29,168 - INFO - [PIPELINE] Sample 50/50 (processed in 0.08s)
2025-04-06 12:29:29,169 - INFO - [PIPELINE] Original: So Parliament should send a message , since that is the wish of the vast majority .
2025-04-06 12:29:29,169 - INFO - [PIPELINE] Semantic noisy: So Parliament hhoult send a message , since that is the wish of the vast majority .
2025-04-06 12:29:29,169 - INFO - [PIPELINE] Semantic reconstructed: So Parliament hhoult send a message , since the is the wish of the vast majority .
2025-04-06 12:29:29,169 - INFO - [PIPELINE] Direct noisy: So Parliament shrulm send a message , since that is the wegh of thp vast majority .
2025-04-06 12:29:29,169 - INFO - [PIPELINE] Direct reconstructed: So Parliament shrulm send a message , since the is the wegh of thp vast majority .
2025-04-06 12:29:29,169 - INFO - [PIPELINE] Semantic BLEU: 0.6675, ROUGE-L: 0.8667, SEMANTIC: 0.8614
2025-04-06 12:29:29,169 - INFO - [PIPELINE] Direct BLEU: 0.3539, ROUGE-L: 0.7333, SEMANTIC: 0.7283
2025-04-06 12:29:29,169 - INFO - [PIPELINE] Current cost: $0.0063 of $2.00
2025-04-06 12:29:29,169 - INFO - [PIPELINE] Progress: 50/50 samples. Est. remaining: 0.0s (0.0m)
2025-04-06 12:29:29,169 - INFO - ---
Processing samples: 100%|███████████████████████| 50/50 [00:30<00:00,  1.62it/s]
2025-04-06 12:29:29,170 - INFO - Saved advanced RL agent state
2025-04-06 12:29:29,170 - INFO - [PIPELINE] Saved enhanced RL agent state
2025-04-06 12:29:29,171 - INFO - Using default tokenizer.
2025-04-06 12:29:29,171 - INFO - Initialized knowledge base for evaluation
2025-04-06 12:29:29,208 - WARNING - [PIPELINE] Enhanced evaluation failed: dictionary changed size during iteration
2025-04-06 12:29:29,208 - WARNING - Continuing with standard metrics only
2025-04-06 12:29:29,331 - INFO - Total API cost: $0.0063 of $2.00 budget
2025-04-06 12:29:29,331 - INFO - 
=== Overall Results ===
2025-04-06 12:29:29,331 - INFO - [PIPELINE] Total time: 33.02s, Avg: 0.66s per sample
2025-04-06 12:29:29,331 - INFO - [PIPELINE] System dimensions: input=768, compressed=460
2025-04-06 12:29:29,331 - INFO - [PIPELINE] Semantic Reconstruction:
2025-04-06 12:29:29,331 - INFO - [PIPELINE] Semantic Average BLEU: 0.4653
2025-04-06 12:29:29,331 - INFO - [PIPELINE] Semantic Average ROUGE1: 0.7627
2025-04-06 12:29:29,331 - INFO - [PIPELINE] Semantic Average ROUGEL: 0.7605
2025-04-06 12:29:29,331 - INFO - [PIPELINE] Semantic Average METEOR: 0.6985
2025-04-06 12:29:29,331 - INFO - [PIPELINE] Semantic Average SEMANTIC: 0.8657
2025-04-06 12:29:29,331 - INFO - 
[PIPELINE] Direct Reconstruction:
2025-04-06 12:29:29,331 - INFO - [PIPELINE] Direct Average BLEU: 0.4730
2025-04-06 12:29:29,331 - INFO - [PIPELINE] Direct Average ROUGE1: 0.7589
2025-04-06 12:29:29,331 - INFO - [PIPELINE] Direct Average ROUGEL: 0.7559
2025-04-06 12:29:29,331 - INFO - [PIPELINE] Direct Average METEOR: 0.7018
2025-04-06 12:29:29,331 - INFO - [PIPELINE] Direct Average SEMANTIC: 0.8653
2025-04-06 12:29:29,331 - INFO - 
[PIPELINE] Total Cost: $0.0063 of $2.00 budget
2025-04-06 12:29:29,331 - INFO - [PIPELINE] Results saved to C:\Users\Daud\SemanticCommTransmission\pythonProject/sem_com_results/enhanced_run_20250406-122856
2025-04-06 12:29:29,331 - INFO - 
[PIPELINE] RL Agent Performance:
2025-04-06 12:29:29,331 - INFO - Total episodes: 0
2025-04-06 12:29:29,331 - INFO - Total reward: 0.00
2025-04-06 12:29:29,331 - INFO - Final exploration rate: 0.10
2025-04-06 12:29:29,331 - INFO - API efficiency: N/A
2025-04-06 12:29:29,331 - INFO - [PIPELINE] Visualizations saved to C:\Users\Daud\SemanticCommTransmission\pythonProject/sem_com_results/enhanced_run_20250406-122856

===== KNOWLEDGE BASE FUNCTIONALITY CHECK =====
✓ KB initialized successfully with 41 terms

Test 1:
  Input:      The Parliamemt will now vote on the propofal from the Commissiob.
  Corrected:  The Parliament will now vote on the proposal from the Commission
  Corrections: 3/3 expected terms
  Result:     ✓ KB applied corrections

Test 2:
  Input:      In accordancg with Rule 143, I wkulz like your acvioe.
  Corrected:  In accordance with Rule 143, I would like your advice
  Corrections: 3/3 expected terms
  Result:     ✓ KB applied corrections

Test 3:
  Input:      The Coupcil and Directave on environmentsl protrction.
  Corrected:  The Council and Directive on environmental protection
  Corrections: 4/4 expected terms
  Result:     ✓ KB applied corrections

===== SUMMARY =====
Tests passed: 3/3
Total corrections made: 10
KB Status: FUNCTIONING

====== Enhanced Semantic Communication Pipeline Complete ======
Overall improvements:
- Advanced Compression: Implemented VAE-based non-linear compression
- Content-Adaptive Coding: Implemented content-aware protection strategies
- Semantic Perceptual Loss: Added semantic similarity metrics and training
- Enhanced RL Agent: Improved state representation with semantic features

Final metrics:
  semantic_avg_BLEU: 0.4653
  semantic_avg_METEOR: 0.6985
  semantic_avg_ROUGE1: 0.7627
  semantic_avg_ROUGEL: 0.7605
  semantic_avg_SEMANTIC: 0.8657

Process finished with exit code 0
